<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Unit 6 - Clustering</title>
<!-- 2015-07-18 Sat 09:24 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Sergio-Feliciano Mendoza-Barrera" />
<meta  name="description" content="Clustering methods in Machine Learning"
 />
<meta  name="keywords" content="R, data science, emacs, ESS, org-mode, machine learning, clustering" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/hideshow.css"/>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/bigblow.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/hideshow.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Unit 6 - Clustering</h1>
<div class="abstract">
<p>
This document concentrate the work of clustering in the TEA course.
</p>

</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
This week we'll discuss how analytics can be used to make
recommendations for movies and for health. In the first lecture, we
discuss how Netflix offered the million dollar prize to improve their
movie recommendation system.
</p>

<p>
In the second lecture, we discuss how health care claims data can be
used to predict the occurrence of a heart attack Through these
examples, we'll discuss the method of clustering, which is used to
find similarities and patterns in data.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Recommendations Worth a Million: An Introduction to Clustering</h2>
<div class="outline-text-2" id="text-2">

<div class="figure">
<p><img src="../graphs/Netflix.png" alt="Netflix.png" />
</p>
</div>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> What is Netflix?</h3>
<div class="outline-text-3" id="text-2-1">

<div class="figure">
<p><img src="../graphs/Netflix02.png" alt="Netflix02.png" />
</p>
</div>

<p>
The recommendation systems in the Netflix business permit to the
executives take some decisions about the tendencies of the market. The
operating people is able to decide what kind of movies are potentially
more interesting to their customers.
</p>

<p>
Have a movie theater for each customer. In order to manage the big
volume of customers, Netflix needs an automated recommendation
system. This system allow the company to select and propose the best
titles for an specific customer.
</p>

<p>
The initial algorithm proposed could be improved, then the Netflix
price was open in order to develop a better algorithm.
</p>


<div class="figure">
<p><img src="../graphs/NetflixPrize.png" alt="NetflixPrize.png" />
</p>
</div>

<p>
The contest rules:
</p>


<div class="figure">
<p><img src="../graphs/NetflixPrize02.png" alt="NetflixPrize02.png" />
</p>
</div>

<p>
Some initial and early results.
</p>


<div class="figure">
<p><img src="../graphs/NF-InitialResults.png" alt="NF-InitialResults.png" />
</p>
</div>

<p>
Then the history of the contest.
</p>


<div class="figure">
<p><img src="../graphs/NF-Progress.png" alt="NF-Progress.png" />
</p>
</div>

<p>
One of the best teams.
</p>


<div class="figure">
<p><img src="../graphs/NF-Progress02.png" alt="NF-Progress02.png" />
</p>
</div>

<p>
The winner!
</p>


<div class="figure">
<p><img src="../graphs/NF-LastCall.png" alt="NF-LastCall.png" />
</p>
</div>

<p>
Netflix was willing to pay over one million dollars for the best user
rating algorithm, which shows how critical the recommendation system
is to their business.
</p>

<p>
We will discuss how recommendation systems work. Let's start by
thinking about the data. When predicting user ratings, what data could
be useful? There are two main types of data that we could use. The
first is that for every movie in Netflix's database, we have a ranking
from all users who have ranked that movie. The second is that we know
facts about the movie itself&#x2013; the actors in the movie, the director,
the genre classifications of the movie, the year it was released,
etc.
</p>


<div class="figure">
<p><img src="../graphs/NF-PredictingBestUserRatings.png" alt="NF-PredictingBestUserRatings.png" />
</p>
</div>

<p>
As an example, suppose we have the following user ratings for four
users and four movies.
</p>

<p>
The ratings are on a one to five scale, where one is the lowest rating
and five is the highest rating. The blank entries mean that the user
has not rated the movie. We could suggest to Carl that he watch Men in
Black, since Amy rated it highly. She gave it a rating of five, and
<b>Amy and Carl seem to have similar ratings for the other movies</b>.
</p>

<p>
This technique of using other user's ratings to make predictions is
called collaborative filtering.
</p>


<div class="figure">
<p><img src="../graphs/NF-CollaborativeFiltering.png" alt="NF-CollaborativeFiltering.png" />
</p>
</div>

<p>
Note that we're not using any information about the movie itself here,
just the similarity between users.
</p>

<p>
We saw in the table that Amy liked Men in Black. She gave it a rating
of five. We know that this movie was directed by Barry Sonnenfeld, is
classified in the genres of action, adventure, sci-fi, and comedy, and
it stars actor Will Smith. Based on this information, we could make
recommendations to Amy.
</p>

<p>
We could recommend to Amy another movie by the same director, Barry
Sonnenfeld's movie, Get Shorty. We can instead recommend the movie
Jurassic Park, which is also classified in the genres of action,
adventure, and sci-fi. Or we could recommend to Amy another movie
starring Will Smith&#x2013; Hitch.
</p>

<p>
Note that we're not using the ratings of other users at all here, just
information about the movie. This technique is called content
filtering.
</p>


<div class="figure">
<p><img src="../graphs/NF-ContentFiltering.png" alt="NF-ContentFiltering.png" />
</p>
</div>

<p>
There are strengths and weaknesses to both types of recommendation
systems.
</p>

<p>
Collaborative filtering can accurately suggest complex items without
understanding the nature of the items. It didn't matter at all that
our items were movies in the collaborative filtering example.
</p>

<p>
We were just comparing user ratings. However, this requires a lot of
data about the user to make accurate recommendations. Also, when there
are millions of items, it needs a lot of computing power to compute
the user similarities.
</p>


<div class="figure">
<p><img src="../graphs/NF-StrengthsWeaknesses.png" alt="NF-StrengthsWeaknesses.png" />
</p>
</div>

<p>
On the other hand, content filtering requires very little data to get
started. But the major weakness of content filtering is that it can be
limited in scope.
</p>

<p>
You're only recommending similar things to what the user has already
liked. So the recommendations are often not surprising or particularly
insightful.
</p>

<p>
Netflix actually uses what's called a hybrid recommendation
system. They use both collaborative and content filtering.
</p>


<div class="figure">
<p><img src="../graphs/NF-HybridRecommendationSystems.png" alt="NF-HybridRecommendationSystems.png" />
</p>
</div>

<p>
If we were only doing collaborative filtering, one of them would have
had to have seen it before. And if we were only doing content
filtering, we would only be recommending to one user at a time.
</p>

<p>
So by combining the two methods, the algorithm can be much more
efficient and accurate. In the next video, we'll see how we can do
content filtering by using a method called clustering.
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Quick Question (2/2 points)</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Let's consider a recommendation system on Amazon.com, an online retail
site.
</p>
</div>

<div id="outline-container-sec-2-2-1" class="outline-4">
<h4 id="sec-2-2-1"><span class="section-number-4">2.2.1</span> Question a</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
If Amazon.com constructs a recommendation system for books, and would
like to use the same exact algorithm for shoes, what type would it
have to be?
</p>
</div>

<div id="outline-container-sec-2-2-1-1" class="outline-5">
<h5 id="sec-2-2-1-1"><span class="section-number-5">2.2.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-2-1-1">
<p>
Collaborative Filtering.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-2-2" class="outline-4">
<h4 id="sec-2-2-2"><span class="section-number-4">2.2.2</span> Question b</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
If Amazon.com would like to suggest books to users based on the
previous books they have purchased, what type of recommendation system
would it be?
</p>
</div>

<div id="outline-container-sec-2-2-2-1" class="outline-5">
<h5 id="sec-2-2-2-1"><span class="section-number-5">2.2.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-2-2-1">
<p>
Content Filtering.
</p>

<p>
<b>Explanation</b>
</p>

<p>
In the first case, the recommendation system would have to be
collaborative filtering, since it can't use information about the
items. In the second case, the recommendation system would be content
filtering since other users are not involved.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> Video 3: Movie Data and Clustering</h3>
<div class="outline-text-3" id="text-2-3">
<p>
We will be using data from <b>MovieLens</b> to explain clustering and
perform content filtering.
</p>

<p>
<b>Movielens.org</b> is a movie recommendation website run by the GroupLens
research lab at the University of Minnesota. They collect user
preferences about movies and do collaborative filtering to make
recommendations to users, based on the similarities between users.
</p>

<p>
We'll use their movie database to do content filtering using a
technique called clustering.
</p>


<div class="figure">
<p><img src="../graphs/MovieLens-Data.png" alt="MovieLens-Data.png" />
</p>
</div>

<p>
First, let's discuss what data we have. Movies in the MovieLens data
set are categorized as belonging to different genres.
</p>

<p>
There are 18 different genres as well as an unknown category. The
genres include crime, musical, mystery, and children's. Each movie may
belong to many different genres. So a movie could be classified as
drama, adventure, and sci-fi.
</p>

<p>
The question we want to answer is, can we systematically find groups
of movies with similar sets of genres? To answer this question, we'll
use a method called clustering.
</p>


<div class="figure">
<p><img src="../graphs/MovieLens-ItemDataset.png" alt="MovieLens-ItemDataset.png" />
</p>
</div>

<p>
To answer this question, we'll use a method called
clustering. Clustering is different from the other analytics methods
we've covered so far. It's called an unsupervised learning
method. This means that we're just trying to segment the data into
similar groups, instead of trying to predict an outcome. In this image
on the slide, based on the locations of points, we've divided them
into three clusters&#x2013; a blue cluster, a red cluster, and a yellow
cluster.
</p>


<div class="figure">
<p><img src="../graphs/ML-WhyClustering.png" alt="ML-WhyClustering.png" />
</p>
</div>

<p>
This is the goal of clustering&#x2013; to put each data point into a group
with similar values in the data. A clustering algorithm does not
predict anything. However, clustering can be used to improve
predictive methods.
</p>

<p>
You can cluster the data into similar groups and then build a
predictive model for each group. This can often improve the accuracy
of predictive methods. But as a warning, be careful not to over-fit
your model to the training set. This works best for large data sets.
</p>

<p>
There are many different algorithms for clustering. They differ in
what makes a cluster and how the clusters are found.
</p>


<div class="figure">
<p><img src="../graphs/ML-ClusteringMethods.png" alt="ML-ClusteringMethods.png" />
</p>
</div>

<p>
You'll learn how to create clusters using either method in R. There
are other clustering methods also, but hierarchical and K-means are
two of the most popular methods. To cluster data points, we need to
compute how similar the points are. This is done by computing the
distance between points.
</p>
</div>
</div>

<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4"><span class="section-number-3">2.4</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-4">
<p>
In the previous video, we discussed how clustering is used to split
the data into similar groups. Which of the following tasks do you
think are appropriate for clustering? Select all that apply.
</p>
</div>

<div id="outline-container-sec-2-4-1" class="outline-4">
<h4 id="sec-2-4-1"><span class="section-number-4">2.4.1</span> Answer <code>[2/3]</code></h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li><code>[X]</code> Dividing search results on Google into categories based on the
topic.
</li>

<li><code>[X]</code> Grouping players into different "types" of basketball players
that make it to the NBA.
</li>

<li><code>[&#xa0;]</code> Predicting the winner of the Major League Baseball World
Series.
</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The first two options are appropriate tasks for clustering. Clustering
probably wouldn't help us predict the winner of the World Series.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-5" class="outline-3">
<h3 id="sec-2-5"><span class="section-number-3">2.5</span> Video 4: Computing Distances</h3>
<div class="outline-text-3" id="text-2-5">
<p>
<b>So how does clustering work?</b> The first step in clustering is to
define the distance between two data points. The most popular way to
compute the distance is what's called Euclidean distance. This is the
standard way to compute distance that you might have seen before.
</p>


<div class="figure">
<p><img src="../graphs/ML-Distance.png" alt="ML-Distance.png" />
</p>
</div>

<p>
The distance between the two points, which we'll call dij, is equal to
the square root of the difference between the two points in the first
component, squared, plus the difference between the two points in the
second component, squared, all the way up to the difference between
the two points in the k-th component, squared, where k here is the
number of attributes or independent variables.
</p>

<p>
Let's see how this works by looking at an example. In our movie lens
dataset, we have binary vectors for each movie, classifying that movie
into genres. The movie Toy Story is categorized as an animation,
comedy, and children's movie.
</p>

<p>
So the data for Toy Story has a 1 in the spot for these three genres
and a 0 everywhere else.
</p>


<div class="figure">
<p><img src="../graphs/ML-DistanceExample.png" alt="ML-DistanceExample.png" />
</p>
</div>

<p>
The movie Batman Forever is categorized as an action, adventure,
comedy, and crime movie. So Batman Forever has a 1 in the spot for
these four genres and a 0 everywhere else.
</p>

<p>
So given these two data observations, let's compute the distance
between them.
</p>


<div class="figure">
<p><img src="../graphs/ML-DistanceExample02.png" alt="ML-DistanceExample02.png" />
</p>
</div>

<p>
In addition to Euclidean distance, there are many other popular
distance metrics that could be used. One is called Manhattan distance,
where the distance is computed to be the sum of the absolute values
instead of the sum of squares.
</p>

<p>
Another is called maximum coordinate distance, where we only consider
the measurement for which the data points deviate the most.
</p>

<p>
Another important distance that we have to calculate for clustering is
the distance between clusters, when a cluster is a group of data
points.
</p>

<p>
We just discussed how to compute the distance between two individual
points, but how do we compute the distance between groups of points?
</p>

<p>
One way of doing this is by using what's called the <b>minimum
distance</b>. This defines the <b>distance between clusters</b> as the
distance between the two data points in the clusters that are closest
together.
</p>


<div class="figure">
<p><img src="../graphs/NF-DistanceBetweenClusters.png" alt="NF-DistanceBetweenClusters.png" />
</p>
</div>

<p>
For example, we would define the distance between the yellow and red
clusters by computing the Euclidean distance between these two
(marked) points.
</p>

<p>
The other points in the clusters could be really far away, but it
doesn't matter if we use minimum distance. The only thing we care
about is how close together the closest points are.
</p>

<p>
Alternatively, we could use maximum distance. This one computes the
distance between the two clusters as the distance between the two
points that are the farthest apart.
</p>

<p>
So for example, we would compute the distance between the yellow and
red clusters by looking at these two points. Here, it doesn't matter
how close together the other points are. All we care about is how
close together the furthest points are.
</p>


<div class="figure">
<p><img src="../graphs/NF-DistanceBetweenClusters02.png" alt="NF-DistanceBetweenClusters02.png" />
</p>
</div>

<p>
The most common distance metric between clusters is called centroid
distance. And this is what we'll use. It defines the distance between
clusters by computing the centroid of the clusters.
</p>


<div class="figure">
<p><img src="../graphs/NF-DistanceBetweenClusters03.png" alt="NF-DistanceBetweenClusters03.png" />
</p>
</div>

<p>
The centroid is just the data point that takes the average of all data
points in each component. This takes all data points in each cluster
into account and can be thought of as the middle data point.
</p>

<p>
In our example, the centroids between yellow and red are here, and we
would compute the distance between the clusters by computing the
Euclidean distance between those two points.
</p>

<p>
When we are computing distances, it's highly influenced by the scale
of the variables.
</p>


<div class="figure">
<p><img src="../graphs/NF-NormalizeData.png" alt="NF-NormalizeData.png" />
</p>
</div>

<p>
As an example, suppose you're computing the distance between two data
points, where one variable is the revenue of a company in thousands of
dollars, and another is the age of the company in years. The revenue
variable would really dominate in the distance calculation.
</p>

<p>
The differences between the data points for revenue would be in the
thousands. Whereas the differences between the year variable would
probably be less than 10.
</p>

<p>
To handle this, it's <b>customary to normalize the data first</b>. We can
normalize by subtracting the mean of the data and dividing by the
standard deviation.
</p>

<p>
In our movie data set, all of our genre variables are on the same
scale. So we don't have to worry about normalizing. But if we wanted
to add a variable, like box office revenue, we would need to normalize
so that this variable didn't dominate all of the others.
</p>

<p>
Now that we've defined how we'll compute the distances, we'll talk
about a specific clustering algorithm: <b>hierarchical clustering</b>.
</p>
</div>
</div>

<div id="outline-container-sec-2-6" class="outline-3">
<h3 id="sec-2-6"><span class="section-number-3">2.6</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-6">
<p>
The movie "The Godfather" is in the genres action, crime, and drama,
and is defined by the vector: (0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0)
</p>

<p>
The movie "Titanic" is in the genres action, drama, and romance, and
is defined by the vector: (0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0)
</p>

<p>
What is the distance between "The Godfather" and "Titanic", using
euclidean distance?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Euclidean distance:"</span>)
v1 <span style="color: #db7093;">&lt;-</span> c(0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0)
v2 <span style="color: #db7093;">&lt;-</span> c(0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0)
d <span style="color: #db7093;">&lt;-</span> sqrt(sum((v1 - v2)^2))
d
</pre>
</div>

<pre class="example">
 :: Euclidean distance:
[1] 1.414214
</pre>
</div>

<div id="outline-container-sec-2-6-1" class="outline-4">
<h4 id="sec-2-6-1"><span class="section-number-4">2.6.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-6-1">
<p>
<b>Explanation</b>
</p>

<p>
The distance between these two movies is \(\sqrt{2}\). They have a
difference of 1 in two genres - crime and romance.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-7" class="outline-3">
<h3 id="sec-2-7"><span class="section-number-3">2.7</span> Video 5: Hierarchical Clustering</h3>
<div class="outline-text-3" id="text-2-7">
<p>
In hierarchical clustering, the clusters are formed by each data point
starting in its own cluster. As a small example, suppose we have five
data points. Each data point is labeled as belonging in its own
cluster. So this data point is in the red cluster, this one's in the
blue cluster, this one's in the purple cluster, this one's in the
green cluster, and this one's in the yellow cluster.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical.png" alt="NF-Hierarchical.png" />
</p>
</div>

<p>
Then hierarchical clustering combines the two nearest clusters into
one cluster. We'll use Euclidean and Centroid distances to decide
which two clusters are the closest. In our example, the green and
yellow clusters are closest together.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical02.png" alt="NF-Hierarchical02.png" />
</p>
</div>

<p>
So we would combine these two clusters into one cluster. So now the
green cluster has two points, and the yellow cluster is gone.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical03.png" alt="NF-Hierarchical03.png" />
</p>
</div>

<p>
Now this process repeats. We again find the two nearest clusters,
which this time are the green cluster and the purple cluster, and we
combine them into one cluster.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical04.png" alt="NF-Hierarchical04.png" />
</p>
</div>

<p>
Now the green cluster has three points, and the purple cluster is
gone.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical05.png" alt="NF-Hierarchical05.png" />
</p>
</div>

<p>
Now the two nearest clusters are the red and blue clusters. So we
would combine these two clusters into one cluster, the red cluster.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical06.png" alt="NF-Hierarchical06.png" />
</p>
</div>

<p>
So now we have just two clusters, the red one and the green one.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical07.png" alt="NF-Hierarchical07.png" />
</p>
</div>

<p>
So now the final step is to combine these two clusters into one
cluster.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical08.png" alt="NF-Hierarchical08.png" />
</p>
</div>

<p>
So at the end of hierarchical clustering, all of our data points are
in a single cluster.
</p>


<div class="figure">
<p><img src="../graphs/NF-Hierarchical09.png" alt="NF-Hierarchical09.png" />
</p>
</div>

<p>
The hierarchical cluster process can be displayed through what's
called a <b>dendrogram</b>. The data points are listed along the bottom, and
the lines show how the clusters were combined. The height of the lines
represents how far apart the clusters were when they were combined.
</p>

<p>
So points 1 and 4 were pretty close together when they were
combined. But when we combined the two clusters at the end, they were
significantly farther apart. We can use a dendrogram to decide how
many clusters we want for our final clustering model.
</p>


<div class="figure">
<p><img src="../graphs/NF-DisplayClusterProcess.png" alt="NF-DisplayClusterProcess.png" />
</p>
</div>

<p>
This dendrogram shows the clustering process with ten data points. The
easiest way to pick the number of clusters you want is to draw a
horizontal line across the dendrogram.
</p>

<p>
The number of vertical lines that line crosses is the number of
clusters there will be. In this case, our line crosses two vertical
lines, meaning that we will have two clusters&#x2013; one cluster with
points 5, 2, and 7, and one cluster with the remaining points.
</p>


<div class="figure">
<p><img src="../graphs/NF-SelectClusters.png" alt="NF-SelectClusters.png" />
</p>
</div>

<p>
The farthest this horizontal line can move up and down in the
dendrogram without hitting one of the horizontal lines of the
dendrogram, the better that choice of the number of clusters is.
</p>

<p>
If we instead selected three clusters, this line can't move as far up
and down without hitting horizontal lines in the dendrogram. This
probably means that the <b>two cluster choice is better</b>.
</p>

<p>
But when picking the number of clusters, <b>you should also consider how
many clusters make sense</b> for the particular <b>application you're
working with</b>.
</p>

<p>
After selecting the number of clusters you want, you should analyze
your clusters to see <b>if they're meaningful</b>.
</p>

<p>
You can also check to see if the clusters have a feature in common
that was not used in the clustering, like an outcome variable. This
often indicates that your clusters might help improve a predictive
model.
</p>


<div class="figure">
<p><img src="../graphs/NF-MeaningfulClusters.png" alt="NF-MeaningfulClusters.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-8" class="outline-3">
<h3 id="sec-2-8"><span class="section-number-3">2.8</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Suppose you are running the Hierarchical clustering algorithm with 212
observations.
</p>
</div>

<div id="outline-container-sec-2-8-1" class="outline-4">
<h4 id="sec-2-8-1"><span class="section-number-4">2.8.1</span> Question a</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
How many clusters will there be at the start of the algorithm?
</p>
</div>

<div id="outline-container-sec-2-8-1-1" class="outline-5">
<h5 id="sec-2-8-1-1"><span class="section-number-5">2.8.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-8-1-1">
<p>
212
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-8-2" class="outline-4">
<h4 id="sec-2-8-2"><span class="section-number-4">2.8.2</span> Question b</h4>
<div class="outline-text-4" id="text-2-8-2">
<p>
How many clusters will there be at the end of the algorithm?
</p>
</div>
</div>

<div id="outline-container-sec-2-8-3" class="outline-4">
<h4 id="sec-2-8-3"><span class="section-number-4">2.8.3</span> Answer</h4>
<div class="outline-text-4" id="text-2-8-3">
<p>
1
</p>

<p>
<b>Explanation</b>
</p>

<p>
The Hierarchical clustering algorithm always starts with each data
point in its own cluster, and ends with all data points in the same
cluster. So there will be 212 clusters at the beginning of the
algorithm, and 1 cluster at the end of the algorithm.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-9" class="outline-3">
<h3 id="sec-2-9"><span class="section-number-3">2.9</span> Video 6: Getting the Data</h3>
<div class="outline-text-3" id="text-2-9">
<p>
We'll be downloading our dataset from the MovieLens website. Please
open the following link in a new window or tab of your browser to
access the <a href="http://files.grouplens.org/datasets/movielens/ml-100k/u.item">data</a>:
</p>

<p>
This video will show you how to load the data into R.
</p>

<p>
An R script file with all of the commands used in this Lecture can be
downloaded <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/Unit6_Netflix.R">here</a>.
</p>

<p>
IMPORTANT NOTE: We'll be using a text editor in this video to get the
data into R. If you are on a Mac and are using TextEdit, the default
file type is .rtf, so you will need to change the file type to txt. To
do this, just go to Format &#x2013;&gt; Make Plain Text, and the file will
re-save as a txt file. Alternatively, depending on your operating
system and web browser, you might just be able to save the file
directly from the browser as a txt file.
</p>
</div>

<div id="outline-container-sec-2-9-1" class="outline-4">
<h4 id="sec-2-9-1"><span class="section-number-4">2.9.1</span> Download the data sets</h4>
<div class="outline-text-4" id="text-2-9-1">
<p>
In this part we can download the data
</p>

<div class="org-src-container">

<pre class="src src-R"><span style="color: #db7093;">library</span>(parallel)

<span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #fffacd;">"../data"</span>)) {
        dir.create(<span style="color: #fffacd;">"../data"</span>)
}

fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"http://files.grouplens.org/datasets/movielens/ml-100k/u.item"</span>

fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"movieLens.txt"</span>

dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"../data"</span>

filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #fffacd;">"/"</span>)

<span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = <span style="color: #fffacd;">"curl"</span>)
}

list.files(<span style="color: #fffacd;">"../data"</span>)
</pre>
</div>

<pre class="example">
 [1] "AnonymityPoll.csv"       "baseball.csv"
 [3] "BoeingStock.csv"         "boston.csv"
 [5] "ClaimsData.csv"          "ClaimsData.csv.zip"
 [7] "climate_change.csv"      "clinical_trial.csv"
 [9] "ClusterMeans.ods"        "CocaColaStock.csv"
[11] "CountryCodes.csv"        "CPSData.csv"
[13] "emails.csv"              "energy_bids.csv"
[15] "FluTest.csv"             "FluTrain.csv"
[17] "framingham.csv"          "gerber.csv"
[19] "GEStock.csv"             "IBMStock.csv"
[21] "loans_imputed.csv"       "loans.csv"
[23] "MetroAreaCodes.csv"      "movieLens.txt"
[25] "mvtWeek1.csv"            "NBA_test.csv"
[27] "NBA_train.csv"           "parole.csv"
[29] "pisa2009test.csv"        "pisa2009train.csv"
[31] "PollingData_Imputed.csv" "PollingData.csv"
[33] "ProcterGambleStock.csv"  "quality.csv"
[35] "README.md"               "songs.csv"
[37] "stevens.csv"             "stopwords.txt"
[39] "tweets.csv"              "USDA.csv"
[41] "WHO_Europe.csv"          "WHO.csv"
[43] "wiki.csv"                "wine_test.csv"
[45] "wine.csv"
</pre>
</div>
</div>

<div id="outline-container-sec-2-9-2" class="outline-4">
<h4 id="sec-2-9-2"><span class="section-number-4">2.9.2</span> Load the data set</h4>
<div class="outline-text-4" id="text-2-9-2">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"    Loading data into their data frames."</span>)
movies <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #fffacd;">"../data/movieLens.txt"</span>, header = <span style="color: #3cb371;">FALSE</span>,
                     sep = <span style="color: #fffacd;">"|"</span>, quote = <span style="color: #fffacd;">"\""</span>)
str(movies)
</pre>
</div>

<pre class="example">
    Loading data into their data frames.
'data.frame':	1682 obs. of  24 variables:
 $ V1 : int  1 2 3 4 5 6 7 8 9 10 ...
 $ V2 : Factor w/ 1664 levels "'Til There Was You (1997)",..: 1525 618 555 594 344 1318 1545 111 391 1240 ...
 $ V3 : Factor w/ 241 levels "","01-Aug-1997",..: 71 71 71 71 71 71 71 71 71 182 ...
 $ V4 : logi  NA NA NA NA NA NA ...
 $ V5 : Factor w/ 1661 levels "","http://us.imdb.com/M/title-exact?%22Langoliers,%20The%22%20(1995)%20(mini)",..: 1430 564 504 542 309 1661 1452 102 356 1182 ...
 $ V6 : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V7 : int  0 1 0 1 0 0 0 0 0 0 ...
 $ V8 : int  0 1 0 0 0 0 0 0 0 0 ...
 $ V9 : int  1 0 0 0 0 0 0 0 0 0 ...
 $ V10: int  1 0 0 0 0 0 0 1 0 0 ...
 $ V11: int  1 0 0 1 0 0 0 1 0 0 ...
 $ V12: int  0 0 0 0 1 0 0 0 0 0 ...
 $ V13: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V14: int  0 0 0 1 1 1 1 1 1 1 ...
 $ V15: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V16: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V17: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V18: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V19: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V20: int  0 0 0 0 0 0 0 0 0 0 ...
 $ V21: int  0 0 0 0 0 0 1 0 0 0 ...
 $ V22: int  0 1 1 0 1 0 0 0 0 0 ...
 $ V23: int  0 0 0 0 0 0 0 0 0 1 ...
 $ V24: int  0 0 0 0 0 0 0 0 0 0 ...
</pre>

<p>
We need one more argument, which is quote="\"". Close the parentheses,
and hit Enter. That last argument just made sure that our text was
read in properly.
</p>

<p>
Let's take a look at the structure of our data using the <code>str</code>
function. We have 1,682 observations of 24 different variables.
</p>

<p>
Since our variables didn't have names, header equaled false, R just
labeled them with V1, V2, V3, etc.
</p>

<p>
But from the Movie Lens documentation, we know what these variables
are. So we'll go ahead and add in the column names ourselves.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Add column names:"</span>)
colnames(movies) = c(<span style="color: #fffacd;">"ID"</span>, <span style="color: #fffacd;">"Title"</span>, <span style="color: #fffacd;">"ReleaseDate"</span>, <span style="color: #fffacd;">"VideoReleaseDate"</span>,
                     <span style="color: #fffacd;">"IMDB"</span>, <span style="color: #fffacd;">"Unknown"</span>, <span style="color: #fffacd;">"Action"</span>, <span style="color: #fffacd;">"Adventure"</span>,
                     <span style="color: #fffacd;">"Animation"</span>, <span style="color: #fffacd;">"Childrens"</span>, <span style="color: #fffacd;">"Comedy"</span>, <span style="color: #fffacd;">"Crime"</span>,
                     <span style="color: #fffacd;">"Documentary"</span>, <span style="color: #fffacd;">"Drama"</span>, <span style="color: #fffacd;">"Fantasy"</span>, <span style="color: #fffacd;">"FilmNoir"</span>,
                     <span style="color: #fffacd;">"Horror"</span>, <span style="color: #fffacd;">"Musical"</span>, <span style="color: #fffacd;">"Mystery"</span>, <span style="color: #fffacd;">"Romance"</span>,
                     <span style="color: #fffacd;">"SciFi"</span>, <span style="color: #fffacd;">"Thriller"</span>, <span style="color: #fffacd;">"War"</span>, <span style="color: #fffacd;">"Western"</span>)

names(movies)
</pre>
</div>

<pre class="example">
 :: Add column names:
 [1] "ID"               "Title"            "ReleaseDate"      "VideoReleaseDate"
 [5] "IMDB"             "Unknown"          "Action"           "Adventure"
 [9] "Animation"        "Childrens"        "Comedy"           "Crime"
[13] "Documentary"      "Drama"            "Fantasy"          "FilmNoir"
[17] "Horror"           "Musical"          "Mystery"          "Romance"
[21] "SciFi"            "Thriller"         "War"              "Western"
</pre>

<p>
We won't be using the ID, release date, video release date, or IMDB
variables, so let's go ahead and remove them.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Remove unnecessary variables:"</span>)
movies$ID = <span style="color: #3cb371;">NULL</span>
movies$ReleaseDate = <span style="color: #3cb371;">NULL</span>
movies$VideoReleaseDate = <span style="color: #3cb371;">NULL</span>
movies$IMDB = <span style="color: #3cb371;">NULL</span>

names(movies)
</pre>
</div>

<pre class="example">
 :: Remove unnecessary variables:
 [1] "Title"       "Unknown"     "Action"      "Adventure"   "Animation"
 [6] "Childrens"   "Comedy"      "Crime"       "Documentary" "Drama"
[11] "Fantasy"     "FilmNoir"    "Horror"      "Musical"     "Mystery"
[16] "Romance"     "SciFi"       "Thriller"    "War"         "Western"
</pre>

<p>
And there are a few duplicate entries in our data set, so we'll go
ahead and remove them with the <code>unique</code> function.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Remove duplicates:"</span>)
movies = unique(movies)

writeLines(<span style="color: #fffacd;">"\n :: Take a look at our data again:"</span>)
str(movies)
</pre>
</div>

<pre class="example">
 :: Remove duplicates:

 :: Take a look at our data again:
'data.frame':	1664 obs. of  20 variables:
 $ Title      : Factor w/ 1664 levels "'Til There Was You (1997)",..: 1525 618 555 594 344 1318 1545 111 391 1240 ...
 $ Unknown    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Action     : int  0 1 0 1 0 0 0 0 0 0 ...
 $ Adventure  : int  0 1 0 0 0 0 0 0 0 0 ...
 $ Animation  : int  1 0 0 0 0 0 0 0 0 0 ...
 $ Childrens  : int  1 0 0 0 0 0 0 1 0 0 ...
 $ Comedy     : int  1 0 0 1 0 0 0 1 0 0 ...
 $ Crime      : int  0 0 0 0 1 0 0 0 0 0 ...
 $ Documentary: int  0 0 0 0 0 0 0 0 0 0 ...
 $ Drama      : int  0 0 0 1 1 1 1 1 1 1 ...
 $ Fantasy    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ FilmNoir   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Horror     : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Musical    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Mystery    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ SciFi      : int  0 0 0 0 0 0 1 0 0 0 ...
 $ Thriller   : int  0 1 1 0 1 0 0 0 0 0 ...
 $ War        : int  0 0 0 0 0 0 0 0 0 1 ...
 $ Western    : int  0 0 0 0 0 0 0 0 0 0 ...
</pre>

<p>
Let's take a look at our data one more time. Now, we have 1,664
observations, a few less than before, and 20 variables&#x2013; the title of
the movie, the unknown genre label, and then the 18 other genre
labels.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-10" class="outline-3">
<h3 id="sec-2-10"><span class="section-number-3">2.10</span> Quick Question (3 points possible)</h3>
<div class="outline-text-3" id="text-2-10">
<p>
Using the table function in R, please answer the following questions
about the dataset <b>movies</b>.
</p>
</div>

<div id="outline-container-sec-2-10-1" class="outline-4">
<h4 id="sec-2-10-1"><span class="section-number-4">2.10.1</span> Question a</h4>
<div class="outline-text-4" id="text-2-10-1">
<p>
How many movies are classified as comedies?
</p>
</div>

<div id="outline-container-sec-2-10-1-1" class="outline-5">
<h5 id="sec-2-10-1-1"><span class="section-number-5">2.10.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-10-1-1">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Number of movies classified as comedy:"</span>)
nrow(subset(movies, movies$Comedy == 1))
</pre>
</div>

<pre class="example">
 :: Number of movies classified as comedy:
[1] 502
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-2-10-2" class="outline-4">
<h4 id="sec-2-10-2"><span class="section-number-4">2.10.2</span> Question b</h4>
<div class="outline-text-4" id="text-2-10-2">
<p>
How many movies are classified as westerns?
</p>
</div>

<div id="outline-container-sec-2-10-2-1" class="outline-5">
<h5 id="sec-2-10-2-1"><span class="section-number-5">2.10.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-10-2-1">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Number of movies classified as Western:"</span>)
nrow(subset(movies, movies$Western == 1))
</pre>
</div>

<pre class="example">
 :: Number of movies classified as Western:
[1] 27
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-2-10-3" class="outline-4">
<h4 id="sec-2-10-3"><span class="section-number-4">2.10.3</span> Question c</h4>
<div class="outline-text-4" id="text-2-10-3">
<p>
How many movies are classified as romance AND drama?
</p>
</div>

<div id="outline-container-sec-2-10-3-1" class="outline-5">
<h5 id="sec-2-10-3-1"><span class="section-number-5">2.10.3.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-10-3-1">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Number of movies classified as Romance and Drama:"</span>)
nrow(subset(movies, movies$Romance == 1 &amp; movies$Drama == 1))

writeLines(<span style="color: #fffacd;">"\n :: Other way to answer this question:"</span>)
nrow(movies[movies$Romance == 1 &amp; movies$Drama == 1, ])
</pre>
</div>

<pre class="example">
 :: Number of movies classified as Romance and Drama:
[1] 97

 :: Other way to answer this question:
[1] 97
</pre>

<p>
<b>Explanation</b>
</p>

<p>
You can answer these questions by using the following commands:
</p>

<p>
<code>table(movies$Comedy)</code>
</p>

<p>
<code>table(movies$Western)</code>
</p>

<p>
<code>table(movies$Romance, movies$Drama)</code>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-2-11" class="outline-3">
<h3 id="sec-2-11"><span class="section-number-3">2.11</span> Video 7: Hierarchical Clustering in R</h3>
<div class="outline-text-3" id="text-2-11">
<p>
<b>Important Note</b>
</p>

<p>
In this video, we use the "ward" method to do hierarchical
clustering. This method was recently renamed in R to "ward.D". If you
are following along in R while watching the video, you will need to
use the following command when doing the hierarchical clustering
("ward" is replaced with "ward.D"):
</p>

<p>
<code>clusterMovies = hclust(distances, method = "ward.D")</code>
</p>

<p>
We'll use hierarchical clustering to cluster the movies in the Movie
Lens data set by genre. After we make our clusters, we'll see how they
can be used to make recommendations.
</p>

<p>
There are two steps to hierarchical clustering. First we have to
compute the distances between all data points, and then we need to
cluster the points.
</p>

<p>
To compute the distances we can use the <code>dist</code> function. We only want to
cluster our movies on the genre variable, not on the title variable,
so we'll cluster on columns two through 20.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Compute distances..."</span>)
distances <span style="color: #db7093;">&lt;-</span> dist(movies[2:20], method = <span style="color: #fffacd;">"euclidean"</span>)
</pre>
</div>

<pre class="example">
:: Compute distances...
</pre>

<p>
Now let's cluster our movies using the <code>hclust</code> function for
hierarchical clustering.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Hierarchical clustering..."</span>)
clusterMovies <span style="color: #db7093;">&lt;-</span> hclust(distances, method = <span style="color: #fffacd;">"ward.D"</span>)
</pre>
</div>

<pre class="example">
:: Hierarchical clustering...
</pre>

<p>
The second argument is ~method="ward"~. The ward method cares about
the distance between clusters using centroid distance, and also the
variance in each of the clusters.
</p>

<p>
Now let's plot the dendrogram of our clustering algorithm:
</p>


<div id="fig:MoviesDendrogram" class="figure">
<p><img src="../graphs/MoviesDendrogram.png" alt="MoviesDendrogram.png" />
</p>
<p><span class="figure-number">Figure 37:</span> Movies dendrogram of clustering method</p>
</div>

<p>
This dendrogram might look a little strange. We have all this black
along the bottom. Remember that the dendrogram lists all of the data
points along the bottom. But when there are over 1,000 data points
it's impossible to read.
</p>

<p>
We'll see later how to assign our clusters to groups so that we can
analyze which data points are in which cluster.
</p>

<p>
So looking at this dendrogram, <b>how many clusters would you pick?</b> It
looks like maybe three or four clusters would be a good choice
according to the dendrogram, but let's keep our application in mind,
too.
</p>

<p>
We probably want more than two, three, or even four clusters of movies
to make recommendations to users.
</p>

<p>
It looks like there's a nice spot down here where there's 10
clusters. This is probably better for our application. We could select
even more clusters if we want to have very specific genre groups.
</p>

<p>
If you want a lot of clusters it's hard to pick the right number from
the dendrogram. You need to use your understanding of the problem to
pick the number of clusters. Let's stick with 10 clusters for now,
combining what we learned from the dendrogram with our understanding
of the problem.
</p>

<p>
We can label each of the data points according to what cluster it
belongs to using the cutree function.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Assign points to clusters..."</span>)
clusterGroups <span style="color: #db7093;">&lt;-</span> cutree(clusterMovies, k = 10)
</pre>
</div>

<pre class="example">
:: Assign points to clusters...
</pre>

<p>
Now let's figure out what the clusters are like. We'll use the tapply
function to compute the percentage of movies in each genre and
cluster.
</p>

<p>
So let's type tapply, and then give as the first argument,
movies$Action&#x2013; we'll start with the action genre&#x2013; and then
clusterGroups, and then mean.
</p>

<p>
<b>So what does this do?</b>
</p>

<p>
It divides our data points into the 10 clusters and then computes the
average value of the action variable for each cluster. Remember that
the action variable is a binary variable with value 0 or 1.
</p>

<p>
So by computing the average of this variable we're computing the
percentage of movies in that cluster that belong in that genre.
</p>

<div class="org-src-container">

<pre class="src src-R">tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
</pre>
</div>

<pre class="example">
        1         2         3         4         5         6         7         8
0.1784512 0.7839196 0.1238532 0.0000000 0.0000000 0.1015625 0.0000000 0.0000000
        9        10
0.0000000 0.0000000
         1          2          3          4          5          6          7
0.10437710 0.04522613 0.03669725 0.00000000 0.00000000 1.00000000 1.00000000
         8          9         10
0.00000000 0.00000000 0.00000000
</pre>

<p>
So we can see here that in cluster 2, about \(78\%\) of the movies have the
action genre label, whereas in cluster 4 none of the movies are
labeled as action movies.
</p>

<p>
Let's try this again, but this time let's look at the <b>romance</b>
genre. Here we can see that all of the movies in clusters six and
seven are labeled as romance movies, whereas only \(4\%\) of the movies
in cluster two are labeled as romance movies.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />

<col  class="right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">Cluster 1</th>
<th scope="col" class="right">Cluster 2</th>
<th scope="col" class="right">Cluster 3</th>
<th scope="col" class="right">Cluster 4</th>
<th scope="col" class="right">Cluster 5</th>
<th scope="col" class="right">Cluster 6</th>
<th scope="col" class="right">Cluster 7</th>
<th scope="col" class="right">Cluster 8</th>
<th scope="col" class="right">Cluster 9</th>
<th scope="col" class="right">Cluster 10</th>
<th scope="col" class="right">&#xa0;</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">Action</td>
<td class="right">0.18</td>
<td class="right">0.78</td>
<td class="right">0.12</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.10</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Adventure</td>
<td class="right">0.19</td>
<td class="right">0.35</td>
<td class="right">0.04</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Animation</td>
<td class="right">0.13</td>
<td class="right">0.01</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Childrens</td>
<td class="right">0.39</td>
<td class="right">0.01</td>
<td class="right">0.01</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Comedy</td>
<td class="right">0.36</td>
<td class="right">0.07</td>
<td class="right">0.06</td>
<td class="right">0.00</td>
<td class="right">1.00</td>
<td class="right">0.11</td>
<td class="right">1.00</td>
<td class="right">0.02</td>
<td class="right">1.00</td>
<td class="right">0.16</td>
</tr>

<tr>
<td class="left">Crime</td>
<td class="right">0.03</td>
<td class="right">0.01</td>
<td class="right">0.41</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.05</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Documentary</td>
<td class="right">0.01</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">1.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Drama</td>
<td class="right">0.31</td>
<td class="right">0.11</td>
<td class="right">0.38</td>
<td class="right">1.00</td>
<td class="right">0.00</td>
<td class="right">0.66</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">1.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Fantasy</td>
<td class="right">0.07</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Film Noir</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.11</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.01</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Horror</td>
<td class="right">0.02</td>
<td class="right">0.08</td>
<td class="right">0.02</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.02</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">1.00</td>
</tr>

<tr>
<td class="left">Musical</td>
<td class="right">0.19</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Mystery</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.28</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Romance</td>
<td class="right">0.10</td>
<td class="right">0.05</td>
<td class="right">0.04</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">1.00</td>
<td class="right">1.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Sci-Fi</td>
<td class="right">0.07</td>
<td class="right">0.35</td>
<td class="right">0.04</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Thriller</td>
<td class="right">0.04</td>
<td class="right">0.38</td>
<td class="right">0.61</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.14</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.16</td>
</tr>

<tr>
<td class="left">War</td>
<td class="right">0.23</td>
<td class="right">0.02</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.02</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Western</td>
<td class="right">0.09</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
<td class="right">0.00</td>
</tr>

<tr>
<td class="left">Misc</td>
<td class="right">Action-Adventure-SciFi</td>
<td class="right">Crime-Mystery-Thriller</td>
<td class="right">Drama</td>
<td class="right">Comedy</td>
<td class="right">Romance</td>
<td class="right">Romantic Comedies</td>
<td class="right">Documentary</td>
<td class="right">Dramatic Comedies</td>
<td class="right">Horror</td>
<td class="right">&#xa0;</td>
</tr>
</tbody>
</table>


<div class="figure">
<p><img src="../graphs/MoviesClustering.png" alt="MoviesClustering.png" />
</p>
</div>

<p>
Knowing common movie genres, these clusters seem to make a lot of
sense.
</p>

<p>
<b>Let's see how these clusters could be used in a recommendation system.</b>
</p>

<p>
Remember that Amy liked the movie Men in Black. Let's figure out what
cluster Men in Black is in.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Id of the movie:"</span>)
subset(movies, Title == <span style="color: #fffacd;">"Men in Black (1997)"</span>)

writeLines(<span style="color: #fffacd;">"\n :: Find which cluster Men in Black is in:"</span>)
clusterGroups[257]
</pre>
</div>

<pre class="example">
 :: Id of the movie:
                  Title Unknown Action Adventure Animation Childrens Comedy
257 Men in Black (1997)       0      1         1         0         0      1
    Crime Documentary Drama Fantasy FilmNoir Horror Musical Mystery Romance
257     0           0     0       0        0      0       0       0       0
    SciFi Thriller War Western
257     1        0   0       0

 :: Find which cluster Men in Black is in:
257
  2
</pre>

<p>
I knew that this is the title of Men in Black because I looked it up
in our data set. So it looks like Men in Black is the 257th row in our
data. So which cluster did the 257th movie go into?
</p>

<p>
It looks like Men in Black went into cluster 2. That make sense since
we just saw that <b>cluster 2 is the action, adventure, sci-fi cluster</b>.
</p>

<p>
So let's create a new data set with just the movies from cluster two.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Create a new data set with just the movies from cluster 2:"</span>)
cluster2 <span style="color: #db7093;">&lt;-</span> subset(movies, clusterGroups == 2)

writeLines(<span style="color: #fffacd;">"\n :: Look at the first 10 titles in this cluster:"</span>)
cluster2$Title[1:10]
</pre>
</div>

<pre class="example">
 :: Create a new data set with just the movies from cluster 2:

 :: Look at the first 10 titles in this cluster:
 [1] GoldenEye (1995)
 [2] Bad Boys (1995)
 [3] Apollo 13 (1995)
 [4] Net, The (1995)
 [5] Natural Born Killers (1994)
 [6] Outbreak (1995)
 [7] Stargate (1994)
 [8] Fugitive, The (1993)
 [9] Jurassic Park (1993)
[10] Robert A. Heinlein's The Puppet Masters (1994)
1664 Levels: 'Til There Was You (1997) ...
</pre>

<p>
So it looks like good movies to recommend to Amy, according to our
clustering algorithm, would be movies like Apollo 13 and Jurassic
Park.
</p>

<p>
In this video we saw how clustering can be applied to create a movie
recommendation system.
</p>
</div>

<div id="outline-container-sec-2-11-1" class="outline-4">
<h4 id="sec-2-11-1"><span class="section-number-4">2.11.1</span> An Advanced Approach to Finding Cluster Centroids</h4>
<div class="outline-text-4" id="text-2-11-1">
<p>
In this video, we explain how you can find the cluster centroids by
using the function <b>tapply</b> for each variable in the dataset. While
this approach works and is familiar to us, it can be a little tedious
when there are a lot of variables.
</p>

<p>
An alternative approach is to use the colMeans function. With this
approach, you only have one command for each cluster instead of one
command for each variable. If you run the following command in your R
console, you can get all of the column (variable) means for cluster 1:
</p>

<p>
<code>colMeans(subset(movies[2:20], clusterGroups == 1))</code>
</p>

<p>
You can repeat this for each cluster by changing the <b>clusterGroups</b>
number. However, if you also have a lot of clusters, this approach is
not that much more efficient than just using the tapply function.
</p>

<p>
A more advanced approach uses the <code>split</code> and <code>lapply</code> functions. The
following command will split the data into subsets based on the
clusters:
</p>

<p>
<code>spl = split(movies[2:20], clusterGroups)</code>
</p>

<p>
Then you can use spl to access the different clusters, because
</p>

<p>
<code>spl[ [1] ]</code>
</p>

<p>
is the same as
</p>

<p>
<code>subset(movies[2:20], clusterGroups == 1)</code>
</p>

<p>
so <code>colMeans(spl[ [1] ])</code> will output the centroid of cluster 1. But
an even easier approach uses the lapply function. The following
command will output the cluster centroids for all clusters:
</p>

<p>
<code>lapply(spl, colMeans)</code>
</p>

<p>
The lapply function runs the second argument (colMeans) on each
element of the first argument (each cluster subset in spl). So instead
of using 19 tapply commands, or 10 colMeans commands, we can output
our centroids with just two commands: one to define spl, and then the
<code>lapply</code> command.
</p>

<p>
Note that if you have a variable called "split" in your current R
session, you will need to remove it with rm(split) so that you can use
the split function.
</p>
</div>
</div>
</div>


<div id="outline-container-sec-2-12" class="outline-3">
<h3 id="sec-2-12"><span class="section-number-3">2.12</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-12">
<p>
Run the <code>cutree</code> function again to create the cluster groups, but this
time pick <code>k = 2</code> clusters. It turns out that the algorithm groups all
of the movies that only belong to one specific genre in one cluster
(cluster 2), and puts all of the other movies in the other cluster
(cluster 1).
</p>

<p>
What is the genre that all of the movies in cluster 2 belong to?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Assign points to clusters..."</span>)
clusterGroups2 <span style="color: #db7093;">&lt;-</span> cutree(clusterMovies, k = 2)

spl = split(movies[2:20], clusterGroups2)

writeLines(<span style="color: #fffacd;">"\n :: Percentage of movies in each cluster:"</span>)
lapply(spl, colMeans)
</pre>
</div>

<pre class="example">
 :: Assign points to clusters...

 :: Percentage of movies in each cluster:
$`1`
    Unknown      Action   Adventure   Animation   Childrens      Comedy
0.001545595 0.192426584 0.102782071 0.032457496 0.092735703 0.387944359
      Crime Documentary       Drama     Fantasy    FilmNoir      Horror
0.082689335 0.038639876 0.267387944 0.017001546 0.018547141 0.069551777
    Musical     Mystery     Romance       SciFi    Thriller         War
0.043276662 0.046367852 0.188562597 0.077279753 0.191653787 0.054868624
    Western
0.020865533

$`2`
    Unknown      Action   Adventure   Animation   Childrens      Comedy
          0           0           0           0           0           0
      Crime Documentary       Drama     Fantasy    FilmNoir      Horror
          0           0           1           0           0           0
    Musical     Mystery     Romance       SciFi    Thriller         War
          0           0           0           0           0           0
    Western
          0
</pre>
</div>

<div id="outline-container-sec-2-12-1" class="outline-4">
<h4 id="sec-2-12-1"><span class="section-number-4">2.12.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-12-1">
<p>
Drama
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can redo the cluster grouping with just two clusters by running
the following command:
</p>

<p>
<code>clusterGroups = cutree(clusterMovies, k = 2)</code>
</p>

<p>
Then, by using the tapply function just like we did in the video, you
can see the average value in each genre and cluster. It turns out that
all of the movies in the second cluster belong to the drama genre.
</p>

<p>
Alternatively, you can use colMeans or lapply as explained below
Video 7.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-13" class="outline-3">
<h3 id="sec-2-13"><span class="section-number-3">2.13</span> Video 8: The Analytics Edge of Recommendation Systems</h3>
<div class="outline-text-3" id="text-2-13">
<p>
Recommendation systems are used in many different areas other than
movies.
</p>

<p>
Jeff Bezos, the CEO of Amazon, said that, "If I have 3 million
customers on the web, I should have 3 million stores on the web."
</p>

<p>
The internet allows for mass personalization, and recommendation
systems are a key part of that. Recommendation systems build models
about users' preferences to personalize the user experience.
</p>


<div class="figure">
<p><img src="../graphs/RecommendationSystems-MassPersonalization.png" alt="RecommendationSystems-MassPersonalization.png" />
</p>
</div>

<p>
Recommendation systems are a cornerstone of these top
businesses. Social networking sites, like Facebook, music streaming
sites, like Pandora, and retail companies, like Amazon, all provide
recommendation systems for their users.
</p>


<div class="figure">
<p><img src="../graphs/RS-Cornerstone.png" alt="RS-Cornerstone.png" />
</p>
</div>

<p>
Both collaborative filtering and content filtering are used in
practice. Collaborative filtering is used by companies like Amazon,
Facebook, and Google News. Content filtering is used by companies like
Pandora, Rotten Tomatoes, and See This Next. And Netflix uses both
collaborative filtering and content filtering.
</p>


<div class="figure">
<p><img src="../graphs/RS-MethodUsed.png" alt="RS-MethodUsed.png" />
</p>
</div>

<p>
So now let's go back to the Netflix prize.
</p>

<p>
To really test the algorithms, Netflix tested them on a private test
set that the teams had never seen before. This is the true test of
predictive ability.
</p>


<div class="figure">
<p><img src="../graphs/NF-NetflixPrize.png" alt="NF-NetflixPrize.png" />
</p>
</div>

<p>
On September 18, 2009, Netflix announced that the winning team was
Bellkor's Pragmatic Chaos. They won the competition and the $1 million
grand prize.
</p>


<div class="figure">
<p><img src="../graphs/NF-Winners.png" alt="NF-Winners.png" />
</p>
</div>

<p>
Recommendation systems provide a significant edge to many
companies. In today's digital age, businesses often have hundreds of
thousands of items to offer their customers, whether they're movies,
songs , or people they might know on Facebook.
</p>


<div class="figure">
<p><img src="../graphs/TEA-RecommendationSystems.png" alt="TEA-RecommendationSystems.png" />
</p>
</div>

<p>
Excellent recommendation systems can make or break these
businesses. Clustering algorithms, which are tailored to find similar
customers or similar items, form the backbone of many of these
recommendation systems.
</p>

<p>
Clustering also has many other interesting applications. In the next
lecture, we'll see how clustering can be used to improve the
predictive ability of classification methods.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Predictive Diagnosis: Discovering Patterns for Disease Detection</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Video 1: Heart Attacks</h3>
<div class="outline-text-3" id="text-3-1">
<p>
We discuss the idea of predictive analytics in medicine. Specifically,
we introduce the idea of using clustering methods for better
predicting heart attacks.
</p>

<p>
Heart attacks are a common complication of coronary heart disease,
resulting from the interruption of blood supply to part of the
heart. Heart attack is the number one cause of death for both men and
women in the United States. About one in every four deaths is due to
heart attack.
</p>


<div class="figure">
<p><img src="../graphs/PredictiveDiagnosis.png" alt="PredictiveDiagnosis.png" />
</p>
</div>

<p>
A 2012 report from the American Heart Association estimates about
715,000 Americans have a heart attack every year. To put this number
into perspective, this means that every 20 seconds, a person has a
heart attack in the United States.
</p>

<p>
It is also equivalent of September the 11th repeating itself every 24
hours, 365 days a year.
</p>

<p>
Nearly half of these attacks occur without prior warning signs. In
fact, 250,000 Americans die of sudden cardiac death yearly, which
means 680 people every day die of sudden cardiac death.
</p>


<div class="figure">
<p><img src="../graphs/PD-HeartAttacks.png" alt="PD-HeartAttacks.png" />
</p>
</div>

<p>
A heart attack has well-known symptoms: chest pain, shortness of
breath, upper body pain, nausea.  The nature of heart attacks,
however, makes it hard to predict, prevent, and even diagnose. Here
are some statistics.
</p>


<div class="figure">
<p><img src="../graphs/PD-HeartAttacks02.png" alt="PD-HeartAttacks02.png" />
</p>
</div>

<p>
<b>How can analytics help?</b> The key to helping patients is to understand
the clinical characteristics of patients in whom heart attacks was
missed.
</p>

<p>
We need to better understand the patterns in a patient's diagnostic
history that link to heart attack and to predicting whether a patient
is at risk for a heart attack.
</p>

<p>
We'll see, how analytics helps to understand patterns of heart attacks
and to provide good predictions that in turn lead to improved
monitoring and taking action early and effectively.
</p>


<div class="figure">
<p><img src="../graphs/PD-AnalyticsHelpsMonitoring.png" alt="PD-AnalyticsHelpsMonitoring.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Quick Question (1/1 point)</h3>
<div class="outline-text-3" id="text-3-2">
<p>
In this class, we've learned many different methods for predicting
outcomes. Which of the following methods is designed to be used to
predict an outcome like whether or not someone will experience a heart
attack? Select all that apply.
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1"><span class="section-number-4">3.2.1</span> Answer <code>[3/4]</code></h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li><code>[&#xa0;]</code> Linear Regression
</li>
<li><code>[X]</code> Logistic Regression
</li>
<li><code>[X]</code> CART
</li>
<li><code>[X]</code> Random Forest
</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
<b>Logistic Regression</b>, <b>CART</b>, and <b>Random Forest</b> are all designed to
be used to predict whether or not someone has a heart attack, since
this is a classification problem. Linear regression would be
appropriate for a problem with a continuous outcome, such as the
amount of time until someone has a heart attack. In this lecture,
we'll use random forest, but the other methods could be used too.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> Video 2: The Data</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Claims data offers an expansive view of the patient's health
history. Specifically, claims data include information on
demographics, medical history, and medications. They offer insights
regarding a patient's risk. And as I will demonstrate, may reveal
indicative signals and patterns.
</p>


<div class="figure">
<p><img src="../graphs/PD-ClaimsData.png" alt="PD-ClaimsData.png" />
</p>
</div>

<p>
We concentrated on members with the following attributes. These
selections yield patients with a high risk of heart attack, and a
reasonably rich medical history with continuous coverage.
</p>


<div class="figure">
<p><img src="../graphs/PD-ClaimsData02.png" alt="PD-ClaimsData02.png" />
</p>
</div>

<p>
Let us discuss how we aggregated this data. The resulting data sets
includes about 20 million health insurance entries, including
individual, medical, and pharmaceutical records.
</p>


<div class="figure">
<p><img src="../graphs/PD-DataAggregation.png" alt="PD-DataAggregation.png" />
</p>
</div>

<p>
Let us discuss how we view the data over time. It is important in this
study to view the medical records chronologically, and to represent a
patient's diagnosis profile over time.
</p>

<p>
So we record the cost and number of medical claims and hospital visits
by a diagnosis. All the observations we have span over five years of
data. They were split into 21 periods, each 90 days in length.
</p>


<div class="figure">
<p><img src="../graphs/PD-DiagnosticHistory.png" alt="PD-DiagnosticHistory.png" />
</p>
</div>

<p>
What was the target variable we were trying to predict? The target
prediction variable is the occurrence of a heart attack. We define
this from a combination of several claims. Namely, diagnosis of a
heart attack, alongside a trip to the emergency room, followed by
subsequent hospitalization.
</p>

<p>
We define this from a combination of several claims. Namely, diagnosis
of a heart attack, alongside a trip to the emergency room, followed by
subsequent hospitalization. Only considering heart attack diagnosis
that are associated with a visit to the emergency room, and following
hospitalization helps ensure that the target outcome is in fact a
heart attack event.
</p>

<p>
The target variable is binary. It is denoted by plus 1 or minus 1 for
the occurrence or non-occurrence of a heart attack in the targeted
period of 90 days.
</p>


<div class="figure">
<p><img src="../graphs/PD-TargetVariable.png" alt="PD-TargetVariable.png" />
</p>
</div>

<p>
<b>How is the data organized?</b> There were 147 variables.
</p>


<div class="figure">
<p><img src="../graphs/PD-DatasetCompilation.png" alt="PD-DatasetCompilation.png" />
</p>
</div>

<p>
<b>Cost of medical care</b> is a good summary of a person's health. In our
database, the total cost of medical care in the three 90 day periods
preceding the heart attack target event ranged from $0 to $636,000 and
approximately 70% of the overall cost was generated by only 11% of the
population.
</p>

<p>
This means that the highest patients with high medical expenses are a
very small proportion of the data, and could skew our final results.
</p>

<p>
According to the American Medical Association, only 10% of individuals
have projected medical expenses of approximately $10,000 or greater
per year, which is more than four times greater than the average
projected medical expenses of $2,400 per year.
</p>

<p>
To lessen the effects of these high-cost outliers, we divided the data
into different cost buckets, based on the findings of the American
Medical Association.
</p>


<div class="figure">
<p><img src="../graphs/PD-CostBucketPartitioning.png" alt="PD-CostBucketPartitioning.png" />
</p>
</div>

<p>
We did not want to have too many cost bins because the size of the
data set. The table in the slide gives a summary of the cost bucket
partitions. Patients with expenses over $10,000 in the nine month
period were allocated to cost bucket 3.
</p>

<p>
Patients with less than $2,000 in expenses were allocated to cost
bucket 1. And the remaining patients with costs between $2,000 and
$10,000 to cost bucket 2.
</p>

<p>
Please note that the majority of patients, 4,400 out of 6,500, or
67.5% of all patients fell into the first bucket of low expenses.
</p>
</div>
</div>

<div id="outline-container-sec-3-4" class="outline-3">
<h3 id="sec-3-4"><span class="section-number-3">3.4</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-3-4">
<p>
In the previous video, we discussed how we split the data into three
groups, or buckets, according to cost.
</p>
</div>

<div id="outline-container-sec-3-4-1" class="outline-4">
<h4 id="sec-3-4-1"><span class="section-number-4">3.4.1</span> Question a</h4>
<div class="outline-text-4" id="text-3-4-1">
<p>
Which bucket has the most data, in terms of number of patients?
</p>
</div>

<div id="outline-container-sec-3-4-1-1" class="outline-5">
<h5 id="sec-3-4-1-1"><span class="section-number-5">3.4.1.1</span> Answer <code>[1/3]</code></h5>
<div class="outline-text-5" id="text-3-4-1-1">
<ul class="org-ul">
<li><code>[X]</code> Cost Bucket 1
</li>
<li><code>[&#xa0;]</code> Cost Bucket 2
</li>
<li><code>[&#xa0;]</code> Cost Bucket 3
</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-sec-3-4-2" class="outline-4">
<h4 id="sec-3-4-2"><span class="section-number-4">3.4.2</span> Question b</h4>
<div class="outline-text-4" id="text-3-4-2">
<p>
Which bucket probably has the densest data, in terms of number of
claims per person?
</p>
</div>

<div id="outline-container-sec-3-4-2-1" class="outline-5">
<h5 id="sec-3-4-2-1"><span class="section-number-5">3.4.2.1</span> Answer <code>[1/3]</code></h5>
<div class="outline-text-5" id="text-3-4-2-1">
<ul class="org-ul">
<li><code>[&#xa0;]</code> Cost Bucket 1
</li>
<li><code>[&#xa0;]</code> Cost Bucket 2
</li>
<li><code>[X]</code> Cost Bucket 3
</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
Cost Bucket 1 contains the most patients (see slide 7 of the previous
video), and Cost Bucket 3 probably has the densest data, since these
are the patients with the highest cost in terms of claims.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-3-5" class="outline-3">
<h3 id="sec-3-5"><span class="section-number-3">3.5</span> Video 3: Predicting Heart Attacks using Clustering</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Let us discuss the performance of a benchmark algorithm. The Random
Forest algorithm is known for its attractive property of detecting
variable interactions and excellent performance as a learning
algorithm. For this reason, we're selecting the Random Forest
algorithm as a benchmark&#x2013; initially, we randomly partitioned the full
data set into two separate parts, where the split was 50-50, and the
partitioning was done evenly within each cost bin.
</p>


<div class="figure">
<p><img src="../graphs/PD-PredictingHeartAttacks.png" alt="PD-PredictingHeartAttacks.png" />
</p>
</div>

<p>
The first part, the training set, was used to develop the method. The
second part, the test set, was used to evaluate the model's
performance. The table in this slide reports the accuracy of the
Random Forest algorithm on each of the three buckets.
</p>

<p>
Let us now introduce the idea of clustering. Patients in each bucket
may have different characteristics. For this reason, we create
clusters for each cost bucket and make predictions for each cluster
using the Random Forest algorithm.
</p>


<div class="figure">
<p><img src="../graphs/PD-IncorporatingClustering.png" alt="PD-IncorporatingClustering.png" />
</p>
</div>

<p>
For this reason, we create clusters for each cost bucket and make
predictions for each cluster using the Random Forest algorithm.
</p>


<div class="figure">
<p><img src="../graphs/PD-IncorporatingClustering02.png" alt="PD-IncorporatingClustering02.png" />
</p>
</div>

<p>
<b>Clustering</b> is mostly used in the absence of a target variable to
search for relationships among input variables or to organize data
into meaningful groups.
</p>

<p>
In this study, although the target variable is well-defined as a heart
attack or not a heart attack, there are many different trajectories
that are associated with the target.
</p>

<p>
There's not one set pattern of health or diagnostic combination that
leads a person to heart attack. Instead, we'll show that there are
many different dynamic health patterns and time series diagnostic
relations preceding a heart attack.
</p>


<div class="figure">
<p><img src="../graphs/PD-ClusteringCostBuckets.png" alt="PD-ClusteringCostBuckets.png" />
</p>
</div>

<p>
The clustering methods we used were spectral clustering and k-means
clustering. We focus, in the lecture, on the k-means clustering. The
broad description of the algorithm is as follows.
</p>


<div class="figure">
<p><img src="../graphs/PD-ClusteringCostBuckets02.png" alt="PD-ClusteringCostBuckets02.png" />
</p>
</div>

<p>
Let us illustrate the k-means algorithm in action. We specify the
desired number of clusters k. In this case, we use <code>k = 2</code>.
</p>

<p>
We then randomly assign each data point to a cluster.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering.png" alt="PD-k-MeansClustering.png" />
</p>
</div>

<p>
Randomly assign each data point to a cluster:
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering02.png" alt="PD-k-MeansClustering02.png" />
</p>
</div>

<p>
In this case, we have the three points in red, and the two points in
black.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering03.png" alt="PD-k-MeansClustering03.png" />
</p>
</div>

<p>
We then compute the cluster centroids, of the points showed.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering04.png" alt="PD-k-MeansClustering04.png" />
</p>
</div>

<p>
When we compute the cluster centroids, indicated by the red x and the
grey x. We re-assign each point to the closest cluster centroid.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering05.png" alt="PD-k-MeansClustering05.png" />
</p>
</div>

<p>
and now you observe that this point changes from a red to a gray.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering06.png" alt="PD-k-MeansClustering06.png" />
</p>
</div>

<p>
We re-compute the cluster centroids, and we repeat the previous steps,
4 and 5 until no improvement is made. You can see the initial
centroids:
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering07.png" alt="PD-k-MeansClustering07.png" />
</p>
</div>

<p>
And now the new calculated centroids. We observe that, in this case,
the k-means clustering is done, and this is our final clustering.
</p>


<div class="figure">
<p><img src="../graphs/PD-k-MeansClustering08.png" alt="PD-k-MeansClustering08.png" />
</p>
</div>

<p>
Let us discuss some practical considerations.
</p>


<div class="figure">
<p><img src="../graphs/PD-PracticalConsiderations.png" alt="PD-PracticalConsiderations.png" />
</p>
</div>

<p>
<b>So how do we measure performance?</b> After we construct the clusters in
the training set, we assign new observations to clusters by proximity
to the centroid of each cluster.
</p>


<div class="figure">
<p><img src="../graphs/PD-RandomForestWithClustering.png" alt="PD-RandomForestWithClustering.png" />
</p>
</div>

<p>
We measure performance by recording the average performance rate in
each cluster.
</p>

<p>
Let us now discuss the performance of the clustering methods. We
perform clustering on each bucket using k=10 clusters.
</p>

<p>
In the table we record the average prediction rate of each cost
bucket. We observe a very visible improvement when we use clustering&#x2013;
from 49% to 64%, from 56% to 73%, from 58% to 78%.
</p>


<div class="figure">
<p><img src="../graphs/PD-PredictingHeartAttacks02.png" alt="PD-PredictingHeartAttacks02.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-6" class="outline-3">
<h3 id="sec-3-6"><span class="section-number-3">3.6</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-3-6">
<p>
K-means clustering differs from Hierarchical clustering in a couple
important ways. Which of the following statements is true?
</p>
</div>

<div id="outline-container-sec-3-6-1" class="outline-4">
<h4 id="sec-3-6-1"><span class="section-number-4">3.6.1</span> Answer <code>[1/2]</code></h4>
<div class="outline-text-4" id="text-3-6-1">
<ul class="org-ul">
<li><code>[X]</code> In k-means clustering, you have to pick the number of clusters
you want before you run the algorithm.
</li>

<li><code>[&#xa0;]</code> In k-means clustering, you can pick the number of clusters you
want after the algorithm is done, just like in Hierarchical
clustering.
</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
In k-means clustering, you have to pick the number of clusters before
you run the algorithm, but the computational effort needed is much
less than that for hierarchical clustering (we'll see this in more
detail during the recitation).
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-7" class="outline-3">
<h3 id="sec-3-7"><span class="section-number-3">3.7</span> Video 4: Understanding Cluster Patterns</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Let us see what we learned about the patterns that emerge. We will
show that the clusters are interpretable and reveal unique patterns of
diagnostic history among the population.
</p>

<p>
We selected six patterns to present in this lecture&#x2013; Cluster 1, 6,
and 7, in Cost Bucket 2, and Clusters 4, 5, and 10, in Cost Bucket 3.
</p>


<div class="figure">
<p><img src="../graphs/PD-UnderstandingClusterPatterns.png" alt="PD-UnderstandingClusterPatterns.png" />
</p>
</div>

<p>
The first pattern shows the occurrence of chest pain three months
before the heart attack. Note that the red dots depict the visits per
diagnosis for patients in Cluster 1&#x2013; this is, we think, Bucket 2&#x2013;
and the blue dots depict the visits per diagnosis for patients in
Bucket 2 throughout.
</p>


<div class="figure">
<p><img src="../graphs/PD-OccurrenceOfChestPain.png" alt="PD-OccurrenceOfChestPain.png" />
</p>
</div>

<p>
Note the very significant increase for visits related to chest pains
three months before the event. About 17, three months before for the
red patients, and about 1 and 1/2 visits for the blue patients.
</p>

<p>
The next pattern reveals an increasing occurrence of chronic
obstructive pulmonary disease, COPD, for short. Patients from Cluster
7 in Bucket 2 have regular doctor visits for COPD.
</p>

<p>
Note that nine months before, we have 4 and 1/2 visits (red) versus
0.5 (blue) visits. Six months before, we have almost 7 visits versus
1/2 a visit, and three months before, we have 9 visits versus 1/2 a
visit for COPD, so <b>a clear increasing pattern</b>.
</p>


<div class="figure">
<p><img src="../graphs/PD-COPD.png" alt="PD-COPD.png" />
</p>
</div>

<p>
The next pattern shows gradually increasing occurrence of anemia. The
red line shows the patients in Cluster 4 increasingly visit the doctor
for anemia from nine months on before the event.
</p>

<p>
Nine months before, members have an average of 9 visits to the doctor
for anemia. This increases to an average of 11 visits six months
before the event, and then an average of 15 visits three months before
the event, a <b>clear increasing pattern</b>.
</p>


<div class="figure">
<p><img src="../graphs/PD-Anemia.png" alt="PD-Anemia.png" />
</p>
</div>

<p>
The final pattern shows the occurrence of diabetes as a pattern for
heart attacks. It is well known that both types 1 and 2 diabetes are
associated with accelerated atherosclerosis, one of the main causes of
myocardial infarction&#x2013; heart attacks, that is.
</p>

<p>
Well known diagnoses associated with heart attacks, such as diabetes,
hypertension, and hyperlipidemia, characterize many of the patterns of
the consistency of care throughout all of the cost buckets and
clustering models.
</p>


<div class="figure">
<p><img src="../graphs/PD-Diabetes.png" alt="PD-Diabetes.png" />
</p>
</div>

<p>
You observe a difference, here, of the number of visits for diabetes
for the population that had the event versus the average population.
</p>
</div>
</div>

<div id="outline-container-sec-3-8" class="outline-3">
<h3 id="sec-3-8"><span class="section-number-3">3.8</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-3-8">
<p>
As we saw in the previous video, the clusters can be used to find
interesting patterns of health in addition to being used to improve
predictive models. By changing the number of clusters, you can find
more general or more specific patterns.
</p>

<p>
If you wanted to find more unusual patterns shared by a small number
of people, would you increase or decrease the number of clusters?
</p>
</div>

<div id="outline-container-sec-3-8-1" class="outline-4">
<h4 id="sec-3-8-1"><span class="section-number-4">3.8.1</span> Answer <code>[1/2]</code></h4>
<div class="outline-text-4" id="text-3-8-1">
<ul class="org-ul">
<li><code>[X]</code> Increase
</li>
<li><code>[&#xa0;]</code> Decrease
</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
If you wanted to find more unusual patterns, you would increase the
number of clusters since the clusters would become smaller and more
patterns would probably emerge.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-9" class="outline-3">
<h3 id="sec-3-9"><span class="section-number-3">3.9</span> Video 5: The Analytics Edge</h3>
<div class="outline-text-3" id="text-3-9">
<p>
What is the impact of clustering?
</p>


<div class="figure">
<p><img src="../graphs/PD-ImpactOfClustering.png" alt="PD-ImpactOfClustering.png" />
</p>
</div>

<p>
The approach shows that using analytics for early heart failure
detection through pattern recognition can lead to interesting new
insights.
</p>

<p>
The findings here are reinforced by results from our research. IBM,
Sutter Health, and Geisinger Health Systems partnered in 2009 to
research analytics tools in view of early detection.
</p>

<p>
<b>Important insights</b>
</p>


<div class="figure">
<p><img src="../graphs/PD-AnalyticsForEarlyDetection.png" alt="PD-AnalyticsForEarlyDetection.png" />
</p>
</div>

<p>
Steve Steinhubl, a cardiologist from Geisinger, wrote, "our early
research showed the signs and symptoms of heart failure in patients
are often documented years before diagnosis.
</p>

<p>
The pattern of documentation can offer clinically useful signals for
early detection of this deadly disease."
</p>
</div>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Seeing the Big Picture: Segmenting Images to Create Data (Recitation)</h2>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 14/07/2015</p>
<p class="author">Author: Sergio-Feliciano Mendoza-Barrera</p>
<p class="date">Created: 2015-07-18 Sat 09:24</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
