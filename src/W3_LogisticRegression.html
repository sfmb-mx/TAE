<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
    <head>
        <title>Unit 3 - Logistic Regression</title>
        <!-- 2015-06-26 Fri 12:24 -->
        <meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
        <meta  name="generator" content="Org-mode" />
        <meta  name="author" content="Sergio-Feliciano Mendoza-Barrera" />
        <meta  name="description" content="R introduction, remembering the syntax and some useful examples"
<<<<<<< HEAD
               />
        <meta  name="keywords" content="R, data science, emacs, ESS, org-mode" />
        <style type="text/css">
            <!--/*--><![CDATA[/*><!--*/
            .title  { text-align: center; }
            .todo   { font-family: monospace; color: red; }
            .done   { color: green; }
            .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
            .timestamp { color: #bebebe; }
            .timestamp-kwd { color: #5f9ea0; }
            .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
            .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
            .center { margin-left: auto; margin-right: auto; text-align: center; }
            .underline { text-decoration: underline; }
            #postamble p, #preamble p { font-size: 90%; margin: .2em; }
            p.verse { margin-left: 3%; }
            pre {
            border: 1px solid #ccc;
            box-shadow: 3px 3px 3px #eee;
            padding: 8pt;
            font-family: monospace;
            overflow: auto;
            margin: 1.2em;
            }
            pre.src {
            position: relative;
            overflow: visible;
            padding-top: 1.2em;
            }
            pre.src:before {
            display: none;
            position: absolute;
            background-color: white;
            top: -10px;
            right: 10px;
            padding: 3px;
            border: 1px solid black;
            }
            pre.src:hover:before { display: inline;}
            pre.src-sh:before    { content: 'sh'; }
            pre.src-bash:before  { content: 'sh'; }
            pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
            pre.src-R:before     { content: 'R'; }
            pre.src-perl:before  { content: 'Perl'; }
            pre.src-java:before  { content: 'Java'; }
            pre.src-sql:before   { content: 'SQL'; }

            table { border-collapse:collapse; }
            caption.t-above { caption-side: top; }
            caption.t-bottom { caption-side: bottom; }
            td, th { vertical-align:top;  }
            th.right  { text-align: center;  }
            th.left   { text-align: center;   }
            th.center { text-align: center; }
            td.right  { text-align: right;  }
            td.left   { text-align: left;   }
            td.center { text-align: center; }
            dt { font-weight: bold; }
            .footpara:nth-child(2) { display: inline; }
            .footpara { display: block; }
            .footdef  { margin-bottom: 1em; }
            .figure { padding: 1em; }
            .figure p { text-align: center; }
            .inlinetask {
            padding: 10px;
            border: 2px solid gray;
            margin: 10px;
            background: #ffffcc;
            }
            #org-div-home-and-up
            { text-align: right; font-size: 70%; white-space: nowrap; }
            textarea { overflow-x: auto; }
            .linenr { font-size: smaller }
            .code-highlighted { background-color: #ffff00; }
            .org-info-js_info-navigation { border-style: none; }
            #org-info-js_console-label
            { font-size: 10px; font-weight: bold; white-space: nowrap; }
            .org-info-js_search-highlight
            { background-color: #ffff00; color: #000000; font-weight: bold; }
            /*]]>*/-->
=======
        />
        <meta  name="keywords" content="R, data science, emacs, ESS, org-mode" />
        <style type="text/css">
         <!--/*--><![CDATA[/*><!--*/
         .title  { text-align: center; }
         .todo   { font-family: monospace; color: red; }
         .done   { color: green; }
         .tag    { background-color: #eee; font-family: monospace;
             padding: 2px; font-size: 80%; font-weight: normal; }
         .timestamp { color: #bebebe; }
         .timestamp-kwd { color: #5f9ea0; }
         .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
         .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
         .center { margin-left: auto; margin-right: auto; text-align: center; }
         .underline { text-decoration: underline; }
         #postamble p, #preamble p { font-size: 90%; margin: .2em; }
         p.verse { margin-left: 3%; }
         pre {
             border: 1px solid #ccc;
             box-shadow: 3px 3px 3px #eee;
             padding: 8pt;
             font-family: monospace;
             overflow: auto;
             margin: 1.2em;
         }
         pre.src {
             position: relative;
             overflow: visible;
             padding-top: 1.2em;
         }
         pre.src:before {
             display: none;
             position: absolute;
             background-color: white;
             top: -10px;
             right: 10px;
             padding: 3px;
             border: 1px solid black;
         }
         pre.src:hover:before { display: inline;}
         pre.src-sh:before    { content: 'sh'; }
         pre.src-bash:before  { content: 'sh'; }
         pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
         pre.src-R:before     { content: 'R'; }
         pre.src-perl:before  { content: 'Perl'; }
         pre.src-java:before  { content: 'Java'; }
         pre.src-sql:before   { content: 'SQL'; }

         table { border-collapse:collapse; }
         caption.t-above { caption-side: top; }
         caption.t-bottom { caption-side: bottom; }
         td, th { vertical-align:top;  }
         th.right  { text-align: center;  }
         th.left   { text-align: center;   }
         th.center { text-align: center; }
         td.right  { text-align: right;  }
         td.left   { text-align: left;   }
         td.center { text-align: center; }
         dt { font-weight: bold; }
         .footpara:nth-child(2) { display: inline; }
         .footpara { display: block; }
         .footdef  { margin-bottom: 1em; }
         .figure { padding: 1em; }
         .figure p { text-align: center; }
         .inlinetask {
             padding: 10px;
             border: 2px solid gray;
             margin: 10px;
             background: #ffffcc;
         }
         #org-div-home-and-up
         { text-align: right; font-size: 70%; white-space: nowrap; }
         textarea { overflow-x: auto; }
         .linenr { font-size: smaller }
         .code-highlighted { background-color: #ffff00; }
         .org-info-js_info-navigation { border-style: none; }
         #org-info-js_console-label
         { font-size: 10px; font-weight: bold; white-space: nowrap; }
         .org-info-js_search-highlight
         { background-color: #ffff00; color: #000000; font-weight: bold; }
         /*]]>*/-->
>>>>>>> origin/master
        </style>
        <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
        <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
        <script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
        <script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
        <script type="text/javascript">
<<<<<<< HEAD
            /*
=======
         /*
>>>>>>> origin/master
            @licstart  The following is the entire license notice for the
            JavaScript code in this tag.

            Copyright (C) 2012-2013 Free Software Foundation, Inc.

            The JavaScript code in this tag is free software: you can
            redistribute it and/or modify it under the terms of the GNU
            General Public License (GNU GPL) as published by the Free Software
            Foundation, either version 3 of the License, or (at your option)
            any later version.  The code is distributed WITHOUT ANY WARRANTY;
            without even the implied warranty of MERCHANTABILITY or FITNESS
            FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

            As additional permission under GNU GPL version 3 section 7, you
            may distribute non-source (e.g., minimized or compacted) forms of
            that code without the copy of the GNU GPL normally required by
            section 4, provided you include this license notice and a URL
            through which recipients can access the Corresponding Source.


            @licend  The above is the entire license notice
            for the JavaScript code in this tag.
<<<<<<< HEAD
            */
            <!--/*--><![CDATA[/*><!--*/
            function CodeHighlightOn(elem, id)
            {
            var target = document.getElementById(id);
            if(null != target) {
            elem.cacheClassElem = elem.className;
            elem.cacheClassTarget = target.className;
            target.className = "code-highlighted";
            elem.className   = "code-highlighted";
            }
            }
            function CodeHighlightOff(elem, id)
            {
            var target = document.getElementById(id);
            if(elem.cacheClassElem)
            elem.className = elem.cacheClassElem;
            if(elem.cacheClassTarget)
            target.className = elem.cacheClassTarget;
            }
            /*]]>*///-->
        </script>
        <script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
        <script type="text/javascript">
            <!--/*--><![CDATA[/*><!--*/
            MathJax.Hub.Config({
            // Only one of the two following lines, depending on user settings
            // First allows browser-native MathML display, second forces HTML/CSS
            //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
            "TeX/noUndefined.js"],
            tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
            },
            showProcessingMessages: true,
            displayAlign: "center",
            displayIndent: "2em",

            "HTML-CSS": {
            scale: 100,
            availableFonts: ["STIX","TeX"],
            preferredFont: "TeX",
            webFont: "TeX",
            imageFont: "TeX",
            showMathMenu: true,
            },
            MMLorHTML: {
            prefer: {
            MSIE:    "MML",
            Firefox: "MML",
            Opera:   "HTML",
            other:   "HTML"
            }
            }
            });
            /*]]>*///-->
=======
          */
         <!--/*--><![CDATA[/*><!--*/
         function CodeHighlightOn(elem, id)
         {
             var target = document.getElementById(id);
             if(null != target) {
                 elem.cacheClassElem = elem.className;
                 elem.cacheClassTarget = target.className;
                 target.className = "code-highlighted";
                 elem.className   = "code-highlighted";
             }
         }
         function CodeHighlightOff(elem, id)
         {
             var target = document.getElementById(id);
             if(elem.cacheClassElem)
                 elem.className = elem.cacheClassElem;
             if(elem.cacheClassTarget)
                 target.className = elem.cacheClassTarget;
         }
         /*]]>*///-->
        </script>
        <script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
        <script type="text/javascript">
         <!--/*--><![CDATA[/*><!--*/
         MathJax.Hub.Config({
             // Only one of the two following lines, depending on user settings
             // First allows browser-native MathML display, second forces HTML/CSS
             //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
             jax: ["input/TeX", "output/HTML-CSS"],
             extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                          "TeX/noUndefined.js"],
             tex2jax: {
                 inlineMath: [ ["\\(","\\)"] ],
                 displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
                 skipTags: ["script","noscript","style","textarea","pre","code"],
                 ignoreClass: "tex2jax_ignore",
                 processEscapes: false,
                 processEnvironments: true,
                 preview: "TeX"
             },
             showProcessingMessages: true,
             displayAlign: "center",
             displayIndent: "2em",

             "HTML-CSS": {
                 scale: 100,
                 availableFonts: ["STIX","TeX"],
                 preferredFont: "TeX",
                 webFont: "TeX",
                 imageFont: "TeX",
                 showMathMenu: true,
             },
             MMLorHTML: {
                 prefer: {
                     MSIE:    "MML",
                     Firefox: "MML",
                     Opera:   "HTML",
                     other:   "HTML"
                 }
             }
         });
         /*]]>*///-->
>>>>>>> origin/master
        </script>
    </head>
    <body>
        <div id="content">
            <h1 class="title">Unit 3 - Logistic Regression</h1>
            <div id="table-of-contents">
                <h2>Table of Contents</h2>
                <div id="text-table-of-contents">
                    <ul>
                        <li><a href="#sec-1">1. Modeling the Expert: An Introduction to Logistic Regression</a>
<<<<<<< HEAD
                        <ul>
                            <li><a href="#sec-1-1">1.1. Logistic Regression</a></li>
                            <li><a href="#sec-1-2">1.2. Logistic Regression in R</a></li>
                            <li><a href="#sec-1-3">1.3. Video 1: Replicating Expert Assessment</a></li>
                            <li><a href="#sec-1-4">1.4. Video 2: Building the Dataset</a></li>
                            <li><a href="#sec-1-5">1.5. Quick Question (2 points possible)</a></li>
                            <li><a href="#sec-1-6">1.6. Video 3: Logistic Regression</a></li>
                            <li><a href="#sec-1-7">1.7. Understanding the Logistic Regression Function</a></li>
                            <li><a href="#sec-1-8">1.8. Quick Question (3 points possible)</a></li>
                            <li><a href="#sec-1-9">1.9. Video 4: Logistic Regression in R</a></li>
                            <li><a href="#sec-1-10">1.10. Quick Question (1 point possible)</a></li>
                            <li><a href="#sec-1-11">1.11. Quick Question (1 point possible)</a></li>
                            <li><a href="#sec-1-12">1.12. Video 5: Thresholding</a></li>
                            <li><a href="#sec-1-13">1.13. The confusion matrix or classification matrix</a></li>
                            <li><a href="#sec-1-14">1.14. Confusion matrices questions</a></li>
                            <li><a href="#sec-1-15">1.15. Video 6: ROC Curves</a></li>
                            <li><a href="#sec-1-16">1.16. Quick Question (2 points possible)</a></li>
                        </ul>
=======
                            <ul>
                                <li><a href="#sec-1-1">1.1. Logistic Regression</a></li>
                                <li><a href="#sec-1-2">1.2. Logistic Regression in R</a></li>
                                <li><a href="#sec-1-3">1.3. Video 1: Replicating Expert Assessment</a></li>
                                <li><a href="#sec-1-4">1.4. Video 2: Building the Dataset</a></li>
                                <li><a href="#sec-1-5">1.5. Quick Question (2 points possible)</a></li>
                                <li><a href="#sec-1-6">1.6. Video 3: Logistic Regression</a></li>
                                <li><a href="#sec-1-7">1.7. Understanding the Logistic Regression Function</a></li>
                                <li><a href="#sec-1-8">1.8. Quick Question (3 points possible)</a></li>
                                <li><a href="#sec-1-9">1.9. Video 4: Logistic Regression in R</a></li>
                                <li><a href="#sec-1-10">1.10. Quick Question (1 point possible)</a></li>
                                <li><a href="#sec-1-11">1.11. Quick Question (1 point possible)</a></li>
                                <li><a href="#sec-1-12">1.12. Video 5: Thresholding</a></li>
                                <li><a href="#sec-1-13">1.13. The confusion matrix or classification matrix</a></li>
                                <li><a href="#sec-1-14">1.14. Confusion matrices questions</a></li>
                                <li><a href="#sec-1-15">1.15. Video 6: ROC Curves</a></li>
                                <li><a href="#sec-1-16">1.16. Quick Question (2 points possible)</a></li>
                            </ul>
>>>>>>> origin/master
                        </li>
                    </ul>
                </div>
            </div>
            <div class="abstract">
                <p>
                    Logistic Regression topics. For the course "MITx: 15.071x The Analytics Edge".
                </p>

            </div>

            <div id="outline-container-sec-1" class="outline-2">
                <h2 id="sec-1"><span class="section-number-2">1</span> Modeling the Expert: An Introduction to Logistic Regression</h2>
                <div class="outline-text-2" id="text-1">
<<<<<<< HEAD
                    </div><div id="outline-container-sec-1-1" class="outline-3">
=======
                </div><div id="outline-container-sec-1-1" class="outline-3">
>>>>>>> origin/master
                    <h3 id="sec-1-1"><span class="section-number-3">1.1</span> Logistic Regression</h3>
                    <div class="outline-text-3" id="text-1-1">
                        <p>
                            <b>The Method</b>
                        </p>

                        <p>
                            Logistic regression extends the idea of linear regression to cases
                            where the dependent variable, \(y\), only has two possible outcomes,
                            called classes. Examples of dependent variables that could be used
                            with logistic regression are predicting whether a new business will
                            succeed or fail, predicting the approval or disapproval of a loan, and
                            predicting whether a stock will increase or decrease in value. These
                            are all called <b>classification problems</b>, since the goal is to figure
                            out which class each observation belongs to.
                        </p>

                        <p>
                            Similar to linear regression, logistic regression uses a set of
                            independent variables to make predictions, but instead of predicting a
                            continuous value for the dependent variable, it instead predicts the
                            probability of each of the possible outcomes, or classes.
                        </p>

                        <p>
                            Logistic regression consists of two steps. The first step is to
                            compute the probability that an observation belongs to class 1, using
                            the <b>Logistic Response Function</b>:
                        </p>

                        <p>
                            $$
                            P(y = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2 + \ldots + \beta_kx_k)}}
                            $$
                        </p>

                        <p>
                            The coefficients, or \(\beta\) values, are selected to maximize the likelihood
                            of predicting a high probability for observations actually belonging
                            to class 1, and predicting a low probability for observations actually
                            belonging to class 0.
                        </p>

                        <p>
                            In the second step of logistic regression, a threshold value is used
                            to classify each observation into one of the classes. A common choice
                            is \(0.5\), meaning that if \(P(y = 1) \geq 0.5\), the observation is
                            classified into class 1, and if \(P(y = 1) < 0.5\), the observation is
                            classified into class 0. Simply stated, each observation is classified
                            into the class with the highest probability.
                        </p>

                        <p>
                            However, other threshold values can be chosen, and in some cases are
                            more appropriate. The threshold value that should be selected often
                            depends on error preferences. When the probabilities are converted
                            into class predictions, two types of errors can be made: false
                            positives, and false negatives. A <b>false positive error</b> is made when
                            the model predicts class 1, but the observation actually belongs to
                            class 0. A <b>false negative error</b> is made when the model predicts class
                            0, but the observation actually belongs to class 1. If a higher
                            threshold value is selected, more false negative errors will be
                            made. If a lower threshold value is selected, more false positive
                            errors will be made.
                        </p>

                        <p>
                            One application where decision-makers often have an error preference
                            is in disease prediction. Suppose you built a model to predict whether
                            or not someone will develop heart disease in the next 10 years (like
                            the model we saw in the Framingham Heart Study lecture). We will
                            consider class 1 to be the outcome in which the person does develop
                            heart disease, and class 0 the outcome in which the person does not
                            develop heart disease. If you pick a high threshold, you will tend to
                            make more false negative errors, which means that you predicted that
                            the person would not develop heart disease, but they actually did. If
                            you pick a lower threshold, you will tend to make more false positive
                            errors, which means that you predicted they would develop heart
                            disease, but they actually did not. In this case, a false positive
                            error is often preferred. Unnecessary resources might be spent
                            treating a patient who did not need to worry, but you did not let as
                            many patients go untreated (which is what a false negative error
                            does).
                        </p>

                        <p>
                            Now, let's consider spam filters. Almost every email provider has a
                            built in spam filter that tries to detect whether or not an email
                            message is spam. Let's classify spam messages as class 1 and non-spam
                            messages as class 0. Then if we build a logistic regression model to
                            predict spam, we will probably want to select a high threshold. Why?
                            In this case, a false positive error means that we predicted a message
                            was spam, and sent it to the spam folder, when it actually was not
                            spam. We might have just sent an important email to the junk folder!
                            On the other hand, a false negative error means that we predicted a
                            message was not spam, when it actually was. This creates a slight
                            annoyance for the user (since they have to delete the message from the
                            inbox themselves) but at least an important message was not missed.
                        </p>

                        <p>
                            This error trade-off can be formalized with a <a href="https://courses.edx.org/wiki/15.071x_2/logistic-regression/confusion-matrix">Confusion Matrix</a> or a
                            <a href="https://courses.edx.org/wiki/15.071x_2/logistic-regression/roc-curve">Receiver Operator Characteristic Curve (ROC curve)</a>. A confusion matrix
                            compares predicted classes with actual classes for a particular
                            threshold value, while an ROC curve plots the false positive rate
                            versus the true positive rate for all possible threshold values. The
                            ROC curve motivates an important metric for classification problems:
                            the AUC, or Area Under the Curve. The AUC of a model gives the area
                            under the ROC curve, and is a number between 0 and 1. The higher the
                            AUC, the more area under the ROC curve, and the better the model. The
                            AUC of a model can be interpreted as the model's ability to
                            distinguish between the two different classes. If the model were
                            handed two random observations from the dataset, one belonging to one
                            class and one belonging to the other class, the AUC gives the
                            proportion of the time when the observation from class 1 has a higher
                            predicted probability of being in class 1. If you were to just guess
                            which observation was which, this would be an AUC of 0.5. So a model
                            with an AUC greater than 0.5 is doing something smarter than just
                            guessing, but we want the AUC of a model to be as close to 1 as
                            possible.
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-2" class="outline-3">
                    <h3 id="sec-1-2"><span class="section-number-3">1.2</span> Logistic Regression in R</h3>
                    <div class="outline-text-3" id="text-1-2">
                        <p>
                            Suppose the training data for your model is in a data frame called
                            "TrainingData", consisting of your dependent variable "DependentVar",
                            and your two independent variables "IndependentVar1" and
                            "IndependentVar2". (If you just have one dataset, you can <a href="https://courses.edx.org/wiki/15.071x_2/logistic-regression/randomly-splitting-data">randomly
                            split</a> your data frame into a training set and testing set with the
                            sample.split function.) Then you can build a logistic regression model
                            with the following command:
                        </p>

                        <p>
                            <code>LogModel = glm(DependentVar ~ IndependentVar1 + IndependentVar2,
<<<<<<< HEAD
                            data=TrainingData, family=binomial)</code>
=======
data=TrainingData, family=binomial)</code>
>>>>>>> origin/master
                        </p>

                        <p>
                            You can see the coefficients and other information about the model
                            with the summary function:
                        </p>

                        <p>
                            <code>summary(LogModel)</code>
                        </p>

                        <p>
                            You can then create a vector of predictions for the training set and
                            generate different confusion matrices with the predict() and table()
                            functions:
                        </p>

                        <p>
                            <code>TrainPredictions = predict(LogModel, type="response")</code>
                            <code>table(TrainingData$DependentVar, TrainPredictions &gt;= 0.5)</code>
                            <code>table(TrainingData$DependentVar, TrainPredictions &gt;= 0.3)</code>
                        </p>

                        <p>
                            You can generate an ROC curve with the following commands (you first
                            need to install and load the "ROCR" package):
                        </p>

                        <p>
                            <code>ROC.Pred = prediction(TrainPredictions, TrainingData$DependentVar)</code>
                            <code>ROC.Perf = performance(ROC.Pred, "tpr", "fpr")</code>
                            <code>plot(ROC.Perf)</code>
                        </p>

                        <p>
                            To add threshold labels and colors, replace the plot command with the following:
                        </p>

                        <p>
                            <code>plot(ROC.Perf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1),
<<<<<<< HEAD
                            text.adj=c(-0.2,1.7))</code>
=======
text.adj=c(-0.2,1.7))</code>
>>>>>>> origin/master
                        </p>

                        <p>
                            The AUC of the model can be computed with the following command:
                        </p>

                        <p>
                            <code>as.numeric(performance(ROC.Pred, "auc")@y.values)</code>
                        </p>

                        <p>
                            To make predictions on a test set called "TestData", you can use the
                            predict() function:
                        </p>

                        <p>
                            <code>TestPredictions = predict(LogModel, newdata=TestData,
<<<<<<< HEAD
                            type="response")</code>
=======
type="response")</code>
>>>>>>> origin/master
                        </p>

                        <p>
                            You can then create confusion matrices, an ROC curve, and compute the
                            AUC just like we did for the training set on the test set.
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-3" class="outline-3">
                    <h3 id="sec-1-3"><span class="section-number-3">1.3</span> Video 1: Replicating Expert Assessment</h3>
                    <div class="outline-text-3" id="text-1-3">
                        <p>
                            We'll examine how analytics can model an expert, in this case a
                            physician, in the context of assessing the quality of healthcare
                            patients receive, and introduce a technique called logistic regression
                            to achieve this objective.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/AskTheExperts.png" alt="AskTheExperts.png" />
                            </p>
                        </div>

                        <p>
                            The large scale problem:
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/ExpertsAreHuman.png" alt="ExpertsAreHuman.png" />
                            </p>
                        </div>

                        <p>
                            Clearly, physicians cannot assess quality for millions of patients,
                            and D2Hawkeye had, indeed, millions of patients who receive claims
                            data on a monthly basis that the quality of them needs to be assessed.
                        </p>

                        <p>
                            So the key question is as follows. Can we develop analytics tools that
                            replicate expert assessment on a large scale?
                        </p>

                        <p>
                            The goal is to learn from expert human judgment by developing a model,
                            interpret the results of the model, and further adjust the model to
                            improve predictability. The objective is to make predictions and
                            evaluations on a large scale basis, to be able to process millions of
                            assessing the health care quality for millions of people.
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-4" class="outline-3">
                    <h3 id="sec-1-4"><span class="section-number-3">1.4</span> Video 2: Building the Dataset</h3>
                    <div class="outline-text-3" id="text-1-4">
                        <p>
                            So let us explain what claims data is. So medical claims are generated
                            when a patient visits a doctor. Medical claims include diagnosis code,
                            procedures codes, as well as costs.
                        </p>

                        <p>
                            Pharmacy claims involve drugs, the quantity of these drugs, the
                            prescribing doctor, as well as the medication costs. Claims data are
                            electronically available, they are standardized, they use
                            well-established codes.
                        </p>

                        <p>
                            <b>However, since humans generate them, they are not 100% accurate</b>.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/ClaimsData.png" alt="ClaimsData.png" />
                            </p>
                        </div>

                        <p>
                            And often, under-reporting is common in the sense that it's a tedious
                            job to record these claims, and as a result, often people under-report
                            them. Also, claims for hospital visits can be vague.
                        </p>

                        <p>
                            In creating a data set, our objective was to assess quality, health
                            care quality.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/CreatingTheDataSet01.png" alt="CreatingTheDataSet01.png" />
                            </p>
                        </div>

                        <p>
                            So we used a large health insurance claims database, and we randomly
                            selected 131 diabetes patients. The ages ranged between 35 to 55 and
                            the costs were in the neighborhood of $10,000 to $20,000.
                        </p>

                        <p>
                            The period in which these claims were recorded were September 1, 2003
                            to August 31, 2005.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/CreatingTheDataSet02.png" alt="CreatingTheDataSet02.png" />
                            </p>
                        </div>

                        <p>
                            An expert physician reviewed the claims and wrote descriptive notes,
                            like "ongoing use of narcotics"; "only on Avandia, not a good first
                            choice drug"; "had regular visits, mammogram, and immunizations"; "was
                            given home testing supplies".
                        </p>

                        <p>
                            After this review, this expert physician rated the quality of care on
                            a two-point scale, poor or good. Examples included, I'd say care was
                            poor. Poorly treated diabetes. Not an eye exam, but overall I'd say
                            high quality.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/CreatingTheDataSet03.png" alt="CreatingTheDataSet03.png" />
                            </p>
                        </div>

                        <p>
                            So based on these comments, we extracted variables. The dependent
                            variable was the <b>quality of care</b>. The independent variables involve
                            the <b>ongoing use of narcotics</b>; only on Avandia, not a good first choice
                            drug; had <b>regular visits</b>, <b>mammogram</b>, and <b>immunizations</b>; was given home
                            testing supplies.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/CreatingTheDataSet04.png" alt="CreatingTheDataSet04.png" />
                            </p>
                        </div>

                        <p>
                            Overall, the independent variables involved diabetes treatment
                            variables, patient demographics, health care utilization, providers,
                            claims, and prescriptions. The dependent variable was modeled as a
                            binary variable &#x2013; 1 for low-quality care and 0 for high-quality
                            care.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/CreatingTheDataSet05.png" alt="CreatingTheDataSet05.png" />
                            </p>
                        </div>

                        <p>
                            This is by its nature a categorical variable. It only takes two
                            possible values. We have seen linear regression as a way of predicting
                            continuous outcomes.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/PredictingQualityOfCare.png" alt="PredictingQualityOfCare.png" />
                            </p>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-5" class="outline-3">
                    <h3 id="sec-1-5"><span class="section-number-3">1.5</span> Quick Question (2 points possible)</h3>
                    <div class="outline-text-3" id="text-1-5">
<<<<<<< HEAD
                        </div><div id="outline-container-sec-1-5-1" class="outline-4">
=======
                    </div><div id="outline-container-sec-1-5-1" class="outline-4">
>>>>>>> origin/master
                        <h4 id="sec-1-5-1"><span class="section-number-4">1.5.1</span> Question a</h4>
                        <div class="outline-text-4" id="text-1-5-1">
                            <p>
                                Which of the following dependent variables are categorical? (Select
                                all that apply.)
                            </p>

                            <ul class="org-ul">
                                <li><code>[X]</code> Deciding whether to buy, sell, or hold a stock
                                </li>
                                <li><code>[&#xa0;]</code> The weekly revenue of a company
                                </li>
                                <li><code>[X]</code> The winner of an election with two candidates
                                </li>
                                <li><code>[X]</code> The day of the week with the highest revenue
                                </li>
                                <li><code>[&#xa0;]</code> The number of daily car thefts in New York City
                                </li>
                                <li><code>[X]</code> Whether or not revenue will exceed $50,000
                                </li>
                            </ul>
                        </div>

                        <div id="outline-container-sec-1-5-1-1" class="outline-5">
                            <h5 id="sec-1-5-1-1"><span class="section-number-5">1.5.1.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-5-1-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The weekly revenue of a company is not categorical, since it has a
                                    large number of possible values, on a continuous range. The number of
                                    daily car thefts in New York City is also not categorical because the
                                    number of car thefts could range from 0 to hundreds.
                                </p>

                                <p>
                                    On the other hand, the other options each have a limited number of
                                    possible outcomes.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-5-2" class="outline-4">
                        <h4 id="sec-1-5-2"><span class="section-number-4">1.5.2</span> Question b</h4>
                        <div class="outline-text-4" id="text-1-5-2">
                            <p>
                                Which of the following dependent variables are binary? (Select all
                                that apply.)
                            </p>

                            <ul class="org-ul">
                                <li><code>[&#xa0;]</code> Deciding whether to buy, sell, or hold a stock
                                </li>
                                <li><code>[&#xa0;]</code> The weekly revenue of a company
                                </li>
                                <li><code>[X]</code> The winner of an election with two candidates
                                </li>
                                <li><code>[&#xa0;]</code> The day of the week with the highest revenue
                                </li>
                                <li><code>[&#xa0;]</code> The number of daily car thefts in New York City
                                </li>
                                <li><code>[X]</code> Whether or not revenue will exceed $50,000
                                </li>
                            </ul>
                        </div>

                        <div id="outline-container-sec-1-5-2-1" class="outline-5">
                            <h5 id="sec-1-5-2-1"><span class="section-number-5">1.5.2.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-5-2-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The only variables with two possible outcomes are the winner of an
                                    election with two candidates, and whether or not revenue will exceed
                                    $50,000.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-6" class="outline-3">
                    <h3 id="sec-1-6"><span class="section-number-3">1.6</span> Video 3: Logistic Regression</h3>
                    <div class="outline-text-3" id="text-1-6">
                        <p>
                            <b>Logistic regression</b> predicts the probability of the outcome variable
                            being <b>true</b>. In this example, a logistic regression model would predict
                            the probability that the patient is receiving <b>poor care</b>. Or if we
                            denote the PoorCare variable by \(y\), the probability that \(y = 1\).
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/LogisticRegression.png" alt="LogisticRegression.png" />
                            </p>
                        </div>

                        <p>
                            So by predicting the probability that \(y = 1\), we also get the
                            probability that \(y = 0\). Just like in linear regression, we have a
                            set of independent variables, \(x_1\) through \(x_k\), where \(k\) is the
                            total number of independent variables we have.
                        </p>

                        <p>
                            Then to predict the probability that \(y = 1\), we use what's called the
                            <b>Logistic Response Function</b>. This seems like a complicated, nonlinear
                            equation, but you can see the familiar linear regression equation in
                            this Logistic Response Function.
                        </p>

                        <p>
                            The Logistic Response Function is used to produce a number between \(0\)
                            and \(1\).
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-7" class="outline-3">
                    <h3 id="sec-1-7"><span class="section-number-3">1.7</span> Understanding the Logistic Regression Function</h3>
                    <div class="outline-text-3" id="text-1-7">

                        <div class="figure">
                            <p><img src="../graphs/UnderstandingTheLF.png" alt="UnderstandingTheLF.png" />
                            </p>
                        </div>

                        <p>
                            This plot shows the logistic response function for different values of
                            the linear regression piece. The logistic response function always
                            takes values between \(0\) and \(1\), which makes sense, since it equals a
                            probability.
                        </p>

                        <p>
                            A positive coefficient value for a variable increases the linear
                            regression piece, which increases the probability that \(y = 1\), or
                            increases the probability of poor care. On the other hand, a negative
                            coefficient value for a variable decreases the linear regression
                            piece, which in turn decreases the probability that \(y = 1\), or
                            increases the probability of good care.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/UnderstandingTheLF02.png" alt="UnderstandingTheLF02.png" />
                            </p>
                        </div>

                        <p>
                            The coefficients, or betas, are selected to predict a high probability
                            for the actual poor care cases, and to predict a low probability for
                            the actual good care cases.
                        </p>

                        <p>
                            Another useful way to think about the logistic response function is in
                            terms of Odds, like in gambling.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/UnderstandingTheLF03.png" alt="UnderstandingTheLF03.png" />
                            </p>
                        </div>

                        <p>
                            If you substitute the <b>Logistic Response Function</b> for the
                            probabilities in the Odds equation.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/TheLogit.png" alt="TheLogit.png" />
                            </p>
                        </div>

                        <p>
                            This helps us understand how the coefficients, or betas, affect our
                            prediction of the probability. A positive \(\beta\) value increases the
                            <b>Logit</b>, which in turn increases the Odds of \(1\). A negative \(\beta\)
                            value decreases the <b>Logit</b>, which in turn, decreases the Odds of
                            one.
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-8" class="outline-3">
                    <h3 id="sec-1-8"><span class="section-number-3">1.8</span> Quick Question (3 points possible)</h3>
                    <div class="outline-text-3" id="text-1-8">
                        <p>
                            Suppose the coefficients of a logistic regression model with two
                            independent variables are as follows:
                        </p>

                        <p>
                            $$
                            \beta_0 = -1.5,~ \beta_1 = 3,~\beta_2 = -0.5
                            $$
                        </p>

                        <p>
                            And we have an observation with the following values for the
                            independent variables:
                        </p>

                        <p>
                            $$
                            x_1 = 1,~x_2 = 5
                            $$
                        </p>
                    </div>

                    <div id="outline-container-sec-1-8-1" class="outline-4">
                        <h4 id="sec-1-8-1"><span class="section-number-4">1.8.1</span> Question a</h4>
                        <div class="outline-text-4" id="text-1-8-1">
                            <p>
                                What is the value of the Logit for this observation? Recall that the
                                Logit is log(Odds).
                            </p>

                            <p>
                                $$
                                log(Odds) = \beta_0 + \beta_1 x_1 + \beta_2 x_2
                                $$
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">beta0 <span style="color: #db7093;">&lt;-</span> -1.5; beta1 <span style="color: #db7093;">&lt;-</span> 3; beta2 <span style="color: #db7093;">&lt;-</span> -0.5;
<<<<<<< HEAD
                                x1 <span style="color: #db7093;">&lt;-</span> 1; x2 <span style="color: #db7093;">&lt;-</span> 5
                                logit <span style="color: #db7093;">&lt;-</span> beta0 + (beta1 * x1) + (beta2 * x2)
                                writeLines(<span style="color: #fffacd;">"\n :: The value of logit is:"</span>)
                                logit
=======
x1 <span style="color: #db7093;">&lt;-</span> 1; x2 <span style="color: #db7093;">&lt;-</span> 5
logit <span style="color: #db7093;">&lt;-</span> beta0 + (beta1 * x1) + (beta2 * x2)
writeLines(<span style="color: #fffacd;">"\n :: The value of logit is:"</span>)
logit
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: The value of logit is:
                                [1] -1
=======
 :: The value of logit is:
[1] -1
>>>>>>> origin/master
                            </pre>
                        </div>

                        <div id="outline-container-sec-1-8-1-1" class="outline-5">
                            <h5 id="sec-1-8-1-1"><span class="section-number-5">1.8.1.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-8-1-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The Logit is just log(Odds), and looks like the linear regression
                                    equation. So the Logit is -1.5 + 3*1 - 0.5*5 = -1.
                                </p>
                            </div>
                        </div>
                    </div>


                    <div id="outline-container-sec-1-8-2" class="outline-4">
                        <h4 id="sec-1-8-2"><span class="section-number-4">1.8.2</span> Question b</h4>
                        <div class="outline-text-4" id="text-1-8-2">
                            <p>
                                What is the value of the Odds for this observation? Note that you can
                                compute e^x, for some number x, in your R console by typing
                                exp(x). The function exp() computes the exponential of its argument.
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: The value of odds is:"</span>)
<<<<<<< HEAD
                                exp(logit)
=======
exp(logit)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: The value of odds is:
                                [1] 0.3678794
=======
 :: The value of odds is:
[1] 0.3678794
>>>>>>> origin/master
                            </pre>
                        </div>

                        <div id="outline-container-sec-1-8-2-1" class="outline-5">
                            <h5 id="sec-1-8-2-1"><span class="section-number-5">1.8.2.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-8-2-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    Using the value of the Logit from the previous question, we have that
                                    Odds = e^(-1) = 0.3678794.
                                </p>
                            </div>
                        </div>
                    </div>


                    <div id="outline-container-sec-1-8-3" class="outline-4">
                        <h4 id="sec-1-8-3"><span class="section-number-4">1.8.3</span> Question c</h4>
                        <div class="outline-text-4" id="text-1-8-3">
                            <p>
                                What is the value of P(y = 1) for this observation?
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">P <span style="color: #db7093;">&lt;-</span> 1 / (1 + exp(-logit))
<<<<<<< HEAD
                                writeLines(<span style="color: #fffacd;">"\n :: The probability of P(y = 1) is:"</span>)
                                P
=======
writeLines(<span style="color: #fffacd;">"\n :: The probability of P(y = 1) is:"</span>)
P
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: The probability of P(y = 1) is:
                                [1] 0.2689414
=======
 :: The probability of P(y = 1) is:
[1] 0.2689414
>>>>>>> origin/master
                            </pre>
                        </div>

                        <div id="outline-container-sec-1-8-3-1" class="outline-5">
                            <h5 id="sec-1-8-3-1"><span class="section-number-5">1.8.3.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-8-3-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    Using the Logistic Response Function, we can compute that P(y = 1) =
                                    1/(1 + e^(-Logit)) = 1/(1 + e^(1)) = 0.2689414.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>


                <div id="outline-container-sec-1-9" class="outline-3">
                    <h3 id="sec-1-9"><span class="section-number-3">1.9</span> Video 4: Logistic Regression in R</h3>
                    <div class="outline-text-3" id="text-1-9">

                        <div class="figure">
                            <p><img src="../graphs/HealthQualityModel.png" alt="HealthQualityModel.png" />
                            </p>
                        </div>

                        <p>
                            This plot shows two of our independent variables, the number of office
                            visits on the x-axis and the number of narcotics prescribed on the
                            y-axis. Each point is an observation or a patient in our data set. The
                            red points are patients who received poor care, and the green points
                            are patients who received good care.
                        </p>

                        <p>
                            It's hard to see a trend in the data by just visually inspecting
                            it. But it looks like maybe more office visits and more narcotics, or
                            data points to the right of this line, are more likely to have poor
                            care.
                        </p>

                        <p>
                            We'll be using the dataset <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/quality.csv">quality.csv</a> to build a logistic regression
                            model in R. Please download this file to follow along.
                        </p>

                        <p>
                            An R script file with all of the commands used in this lecture can be
                            downloaded <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/Unit3_ModelingExpert.R">here</a>.
                        </p>
                    </div>

                    <div id="outline-container-sec-1-9-1" class="outline-4">
                        <h4 id="sec-1-9-1"><span class="section-number-4">1.9.1</span> Download the data sets</h4>
                        <div class="outline-text-4" id="text-1-9-1">
                            <p>
                                In this part we can download the data
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R"><span style="color: #db7093;">library</span>(parallel)

<<<<<<< HEAD
                                <span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #fffacd;">"../data"</span>)) {
                                dir.create(<span style="color: #fffacd;">"../data"</span>)
                                }

                                fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/quality.csv"</span>

                                fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"quality.csv"</span>

                                dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"../data"</span>

                                filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #fffacd;">"/"</span>)

                                <span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
                                download.file(fileUrl, destfile = filePath, method = <span style="color: #fffacd;">"curl"</span>)
                                }

                                list.files(<span style="color: #fffacd;">"../data"</span>)
=======
                                    <span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #fffacd;">"../data"</span>)) {
        dir.create(<span style="color: #fffacd;">"../data"</span>)
}

fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/quality.csv"</span>

fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"quality.csv"</span>

dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #fffacd;">"../data"</span>

filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #fffacd;">"/"</span>)

                                    <span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = <span style="color: #fffacd;">"curl"</span>)
}

list.files(<span style="color: #fffacd;">"../data"</span>)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                [1] "AnonymityPoll.csv"      "BoeingStock.csv"        "CPSData.csv"
                                [4] "CocaColaStock.csv"      "CountryCodes.csv"       "FluTest.csv"
                                [7] "FluTrain.csv"           "GEStock.csv"            "IBMStock.csv"
                                [10] "MetroAreaCodes.csv"     "NBA_test.csv"           "NBA_train.csv"
                                [13] "ProcterGambleStock.csv" "README.md"              "USDA.csv"
                                [16] "WHO.csv"                "WHO_Europe.csv"         "baseball.csv"
                                [19] "climate_change.csv"     "mvtWeek1.csv"           "pisa2009test.csv"
                                [22] "pisa2009train.csv"      "quality.csv"            "wine.csv"
                                [25] "wine_test.csv"
=======
 [1] "AnonymityPoll.csv"      "BoeingStock.csv"        "CPSData.csv"
 [4] "CocaColaStock.csv"      "CountryCodes.csv"       "FluTest.csv"
 [7] "FluTrain.csv"           "GEStock.csv"            "IBMStock.csv"
[10] "MetroAreaCodes.csv"     "NBA_test.csv"           "NBA_train.csv"
[13] "ProcterGambleStock.csv" "README.md"              "USDA.csv"
[16] "WHO.csv"                "WHO_Europe.csv"         "baseball.csv"
[19] "climate_change.csv"     "mvtWeek1.csv"           "pisa2009test.csv"
[22] "pisa2009train.csv"      "quality.csv"            "wine.csv"
[25] "wine_test.csv"
>>>>>>> origin/master
                            </pre>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-9-2" class="outline-4">
                        <h4 id="sec-1-9-2"><span class="section-number-4">1.9.2</span> Load the data set</h4>
                        <div class="outline-text-4" id="text-1-9-2">
                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"    Loading data into their data frames."</span>)
<<<<<<< HEAD
                                quality <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #fffacd;">"../data/quality.csv"</span>, sep = <span style="color: #fffacd;">","</span>, header = <span style="color: #3cb371;">TRUE</span>)
                                str(quality)
                                summary(quality)
=======
quality <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #fffacd;">"../data/quality.csv"</span>, sep = <span style="color: #fffacd;">","</span>, header = <span style="color: #3cb371;">TRUE</span>)
str(quality)
summary(quality)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                Loading data into their data frames.
                                'data.frame':	131 obs. of  14 variables:
                                $ MemberID            : int  1 2 3 4 5 6 7 8 9 10 ...
                                $ InpatientDays       : int  0 1 0 0 8 2 16 2 2 4 ...
                                $ ERVisits            : int  0 1 0 1 2 0 1 0 1 2 ...
                                $ OfficeVisits        : int  18 6 5 19 19 9 8 8 4 0 ...
                                $ Narcotics           : int  1 1 3 0 3 2 1 0 3 2 ...
                                $ DaysSinceLastERVisit: num  731 411 731 158 449 ...
                                $ Pain                : int  10 0 10 34 10 6 4 5 5 2 ...
                                $ TotalVisits         : int  18 8 5 20 29 11 25 10 7 6 ...
                                $ ProviderCount       : int  21 27 16 14 24 40 19 11 28 21 ...
                                $ MedicalClaims       : int  93 19 27 59 51 53 40 28 20 17 ...
                                $ ClaimLines          : int  222 115 148 242 204 156 261 87 98 66 ...
                                $ StartedOnCombination: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
                                $ AcuteDrugGapSmall   : int  0 1 5 0 0 4 0 0 0 0 ...
                                $ PoorCare            : int  0 0 0 0 0 1 0 0 1 0 ...
                                MemberID     InpatientDays       ERVisits       OfficeVisits
                                Min.   :  1.0   Min.   : 0.000   Min.   : 0.000   Min.   : 0.00
                                1st Qu.: 33.5   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 7.00
                                Median : 66.0   Median : 0.000   Median : 1.000   Median :12.00
                                Mean   : 66.0   Mean   : 2.718   Mean   : 1.496   Mean   :13.23
                                3rd Qu.: 98.5   3rd Qu.: 3.000   3rd Qu.: 2.000   3rd Qu.:18.50
                                Max.   :131.0   Max.   :30.000   Max.   :11.000   Max.   :46.00
                                Narcotics      DaysSinceLastERVisit      Pain         TotalVisits
                                Min.   : 0.000   Min.   :  6.0        Min.   :  0.00   Min.   : 0.00
                                1st Qu.: 0.000   1st Qu.:207.0        1st Qu.:  1.00   1st Qu.: 8.00
                                Median : 1.000   Median :641.0        Median :  8.00   Median :15.00
                                Mean   : 4.573   Mean   :480.6        Mean   : 15.56   Mean   :17.44
                                3rd Qu.: 3.000   3rd Qu.:731.0        3rd Qu.: 23.00   3rd Qu.:22.50
                                Max.   :59.000   Max.   :731.0        Max.   :104.00   Max.   :69.00
                                ProviderCount   MedicalClaims      ClaimLines    StartedOnCombination
                                Min.   : 5.00   Min.   : 11.00   Min.   : 20.0   Mode :logical
                                1st Qu.:15.00   1st Qu.: 25.50   1st Qu.: 83.5   FALSE:125
                                Median :20.00   Median : 37.00   Median :120.0   TRUE :6
                                Mean   :23.98   Mean   : 43.24   Mean   :142.9   NA's :0
                                3rd Qu.:30.00   3rd Qu.: 49.50   3rd Qu.:185.0
                                Max.   :82.00   Max.   :194.00   Max.   :577.0
                                AcuteDrugGapSmall    PoorCare
                                Min.   : 0.000    Min.   :0.0000
                                1st Qu.: 0.000    1st Qu.:0.0000
                                Median : 1.000    Median :0.0000
                                Mean   : 2.695    Mean   :0.2519
                                3rd Qu.: 3.000    3rd Qu.:0.5000
                                Max.   :71.000    Max.   :1.0000
=======
    Loading data into their data frames.
'data.frame':	131 obs. of  14 variables:
 $ MemberID            : int  1 2 3 4 5 6 7 8 9 10 ...
 $ InpatientDays       : int  0 1 0 0 8 2 16 2 2 4 ...
 $ ERVisits            : int  0 1 0 1 2 0 1 0 1 2 ...
 $ OfficeVisits        : int  18 6 5 19 19 9 8 8 4 0 ...
 $ Narcotics           : int  1 1 3 0 3 2 1 0 3 2 ...
 $ DaysSinceLastERVisit: num  731 411 731 158 449 ...
 $ Pain                : int  10 0 10 34 10 6 4 5 5 2 ...
 $ TotalVisits         : int  18 8 5 20 29 11 25 10 7 6 ...
 $ ProviderCount       : int  21 27 16 14 24 40 19 11 28 21 ...
 $ MedicalClaims       : int  93 19 27 59 51 53 40 28 20 17 ...
 $ ClaimLines          : int  222 115 148 242 204 156 261 87 98 66 ...
 $ StartedOnCombination: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
 $ AcuteDrugGapSmall   : int  0 1 5 0 0 4 0 0 0 0 ...
 $ PoorCare            : int  0 0 0 0 0 1 0 0 1 0 ...
    MemberID     InpatientDays       ERVisits       OfficeVisits
 Min.   :  1.0   Min.   : 0.000   Min.   : 0.000   Min.   : 0.00
 1st Qu.: 33.5   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 7.00
 Median : 66.0   Median : 0.000   Median : 1.000   Median :12.00
 Mean   : 66.0   Mean   : 2.718   Mean   : 1.496   Mean   :13.23
 3rd Qu.: 98.5   3rd Qu.: 3.000   3rd Qu.: 2.000   3rd Qu.:18.50
 Max.   :131.0   Max.   :30.000   Max.   :11.000   Max.   :46.00
   Narcotics      DaysSinceLastERVisit      Pain         TotalVisits
 Min.   : 0.000   Min.   :  6.0        Min.   :  0.00   Min.   : 0.00
 1st Qu.: 0.000   1st Qu.:207.0        1st Qu.:  1.00   1st Qu.: 8.00
 Median : 1.000   Median :641.0        Median :  8.00   Median :15.00
 Mean   : 4.573   Mean   :480.6        Mean   : 15.56   Mean   :17.44
 3rd Qu.: 3.000   3rd Qu.:731.0        3rd Qu.: 23.00   3rd Qu.:22.50
 Max.   :59.000   Max.   :731.0        Max.   :104.00   Max.   :69.00
 ProviderCount   MedicalClaims      ClaimLines    StartedOnCombination
 Min.   : 5.00   Min.   : 11.00   Min.   : 20.0   Mode :logical
 1st Qu.:15.00   1st Qu.: 25.50   1st Qu.: 83.5   FALSE:125
 Median :20.00   Median : 37.00   Median :120.0   TRUE :6
 Mean   :23.98   Mean   : 43.24   Mean   :142.9   NA's :0
 3rd Qu.:30.00   3rd Qu.: 49.50   3rd Qu.:185.0
 Max.   :82.00   Max.   :194.00   Max.   :577.0
 AcuteDrugGapSmall    PoorCare
 Min.   : 0.000    Min.   :0.0000
 1st Qu.: 0.000    1st Qu.:0.0000
 Median : 1.000    Median :0.0000
 Mean   : 2.695    Mean   :0.2519
 3rd Qu.: 3.000    3rd Qu.:0.5000
 Max.   :71.000    Max.   :1.0000
>>>>>>> origin/master
                            </pre>

                            <p>
                                We'll be using the number of office visits and the number of
                                prescriptions for narcotics that the patient had.
                            </p>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-9-3" class="outline-4">
                        <h4 id="sec-1-9-3"><span class="section-number-4">1.9.3</span> Data dictionary</h4>
                        <div class="outline-text-4" id="text-1-9-3">
                            <p>
                                The variables in the dataset quality.csv are as follows:
                            </p>

                            <ul class="org-ul">
                                <li><b>MemberID</b> numbers the patients from 1 to 131, and is just an
<<<<<<< HEAD
                                identifying number.
                                </li>

                                <li><b>InpatientDays</b> is the number of inpatient visits, or number of days
                                the person spent in the hospital.
                                </li>

                                <li><b>ERVisits</b> is the number of times the patient visited the emergency
                                room.
                                </li>

                                <li><b>OfficeVisits</b> is the number of times the patient visited any
                                doctor's office.
                                </li>

                                <li><b>Narcotics</b> is the number of prescriptions the patient had for
                                narcotics.
                                </li>

                                <li><b>DaysSinceLastERVisit</b> is the number of days between the patient's
                                last emergency room visit and the end of the study period (set to
                                the length of the study period if they never visited the ER).
                                </li>

                                <li><b>Pain</b> is the number of visits for which the patient complained
                                about pain.
                                </li>

                                <li><b>TotalVisits</b> is the total number of times the patient visited any
                                healthcare provider.
=======
                                    identifying number.
                                </li>

                                <li><b>InpatientDays</b> is the number of inpatient visits, or number of days
                                    the person spent in the hospital.
                                </li>

                                <li><b>ERVisits</b> is the number of times the patient visited the emergency
                                    room.
                                </li>

                                <li><b>OfficeVisits</b> is the number of times the patient visited any
                                    doctor's office.
                                </li>

                                <li><b>Narcotics</b> is the number of prescriptions the patient had for
                                    narcotics.
                                </li>

                                <li><b>DaysSinceLastERVisit</b> is the number of days between the patient's
                                    last emergency room visit and the end of the study period (set to
                                    the length of the study period if they never visited the ER).
                                </li>

                                <li><b>Pain</b> is the number of visits for which the patient complained
                                    about pain.
                                </li>

                                <li><b>TotalVisits</b> is the total number of times the patient visited any
                                    healthcare provider.
>>>>>>> origin/master
                                </li>

                                <li><b>ProviderCount</b> is the number of providers that served the patient.
                                </li>

                                <li><b>MedicalClaims</b> is the number of days on which the patient had a
<<<<<<< HEAD
                                medical claim.
=======
                                    medical claim.
>>>>>>> origin/master
                                </li>

                                <li><b>ClaimLines</b> is the total number of medical claims.
                                </li>

                                <li><b>StartedOnCombination</b> is whether or not the patient was started on
<<<<<<< HEAD
                                a combination of drugs to treat their diabetes (TRUE or FALSE).
                                </li>

                                <li><b>AcuteDrugGapSmall</b> is the fraction of acute drugs that were
                                refilled quickly after the prescription ran out.
                                </li>

                                <li><b>PoorCare</b> is the outcome or dependent variable, and is equal to 1
                                if the patient had poor care, and equal to 0 if the patient had good
                                care.
=======
                                    a combination of drugs to treat their diabetes (TRUE or FALSE).
                                </li>

                                <li><b>AcuteDrugGapSmall</b> is the fraction of acute drugs that were
                                    refilled quickly after the prescription ran out.
                                </li>

                                <li><b>PoorCare</b> is the outcome or dependent variable, and is equal to 1
                                    if the patient had poor care, and equal to 0 if the patient had good
                                    care.
>>>>>>> origin/master
                                </li>
                            </ul>

                            <p>
                                In this part we learned how to use the <code>sample.split()</code> function from
                                the <b>caTools</b> package to split data for a classification problem,
                                balancing the positive and negative observations in the training and
                                testing sets.
                            </p>

                            <p>
                                If you wanted to instead split a data frame data, where the dependent
                                variable is a continuous outcome (this was the case for all the
                                datasets we used last week), you could instead use the <code>sample()</code>
                                function. Here is how to select \(70\%\) of observations for the training
                                set (called <b>train</b>) and \(30\%\) of observations for the testing set
                                (called <b>test</b>):
                            </p>

                            <p>
                                <code>spl = sample(1:nrow(data), size=0.7 * nrow(data))</code>
                            </p>

                            <p>
                                <code>train = data[spl,]</code>
                            </p>

                            <p>
                                <code>test = data[-spl,]</code>
                            </p>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-9-4" class="outline-4">
                        <h4 id="sec-1-9-4"><span class="section-number-4">1.9.4</span> Logistic Regression model building</h4>
                        <div class="outline-text-4" id="text-1-9-4">
                            <p>
                                In a classification problem, a standard baseline method is to just
                                predict the most frequent outcome for all observations.
                            </p>

                            <p>
                                Since good care is more common than poor care, in this case, we would
                                predict that all patients are receiving good care. If we did this, we
                                would get \(98\) out of the \(131\) observations correct, or have an accuracy
                                of about \(75\%\).
                            </p>

                            <p>
                                So our baseline model has an accuracy of \(75\%\). This is what we'll
                                try to beat with our logistic regression model.
                            </p>

                            <p>
                                we only have one data set. So we want to randomly split our data set
                                into a training set and testing set so that we'll have a test set to
                                measure our out-of-sample accuracy.
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Install and load caTools package (Only once)"</span>)
<<<<<<< HEAD
                                <span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('caTools', repos='http://cran.rstudio.com/')</span>
                                <span style="color: #db7093;">library</span>(caTools)

                                writeLines(<span style="color: #fffacd;">"\n :: Randomly split data"</span>)
                                set.seed(88)
                                split <span style="color: #db7093;">&lt;-</span> sample.split(quality$PoorCare, SplitRatio = 0.75)
                                head(split)
=======
                                    <span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('caTools', repos='http://cran.rstudio.com/')</span>
                                    <span style="color: #db7093;">library</span>(caTools)

writeLines(<span style="color: #fffacd;">"\n :: Randomly split data"</span>)
set.seed(88)
split <span style="color: #db7093;">&lt;-</span> sample.split(quality$PoorCare, SplitRatio = 0.75)
head(split)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Install and load caTools package (Only once)

                                :: Randomly split data
                                [1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE
=======
 :: Install and load caTools package (Only once)

 :: Randomly split data
[1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE
>>>>>>> origin/master
                            </pre>

                            <p>
                                Since sample.split randomly splits your data, it could split it
                                differently for each of us. To make sure that we all get the same
                                split, we'll set our seed. This initializes the random number
                                generator.
                            </p>

                            <p>
                                <code>Sample.split</code> randomly splits the data. But it also makes sure that
                                the outcome variable is well-balanced in each piece. We saw earlier
                                that about \(75\%\) of our patients are receiving good care.
                            </p>

                            <p>
                                This function makes sure that in our training set, \(75\%\) of our patients
                                are receiving good care and in our testing set \(75\%\) of our patients are
                                receiving good care.
                            </p>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-9-5" class="outline-4">
                        <h4 id="sec-1-9-5"><span class="section-number-4">1.9.5</span> Building the training and the testing sets</h4>
                        <div class="outline-text-4" id="text-1-9-5">
                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Create training and testing sets"</span>)
<<<<<<< HEAD
                                qualityTrain <span style="color: #db7093;">&lt;-</span> subset(quality, split == <span style="color: #3cb371;">TRUE</span>)
                                qualityTest <span style="color: #db7093;">&lt;-</span> subset(quality, split == <span style="color: #3cb371;">FALSE</span>)

                                writeLines(<span style="color: #fffacd;">"\n :: The number of observations in the training set"</span>)
                                nrow(qualityTrain)

                                writeLines(<span style="color: #fffacd;">"\n :: The number of observations in the testing set"</span>)
                                nrow(qualityTest)
=======
qualityTrain <span style="color: #db7093;">&lt;-</span> subset(quality, split == <span style="color: #3cb371;">TRUE</span>)
qualityTest <span style="color: #db7093;">&lt;-</span> subset(quality, split == <span style="color: #3cb371;">FALSE</span>)

writeLines(<span style="color: #fffacd;">"\n :: The number of observations in the training set"</span>)
nrow(qualityTrain)

writeLines(<span style="color: #fffacd;">"\n :: The number of observations in the testing set"</span>)
nrow(qualityTest)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Create training and testing sets

                                :: The number of observations in the training set
                                [1] 99

                                :: The number of observations in the testing set
                                [1] 32
=======
 :: Create training and testing sets

 :: The number of observations in the training set
[1] 99

 :: The number of observations in the testing set
[1] 32
>>>>>>> origin/master
                            </pre>

                            <p>
                                We are ready to build a logistic regression model using <b>OfficeVisits</b>
                                and <b>Narcotics</b> as independent variables.
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: First Logistic Regression Model"</span>)
<<<<<<< HEAD
                                QualityLog <span style="color: #db7093;">&lt;-</span> glm(PoorCare ~ OfficeVisits + Narcotics,
                                data=qualityTrain, family = binomial)
                                summary(QualityLog)
=======
QualityLog <span style="color: #db7093;">&lt;-</span> glm(PoorCare ~ OfficeVisits + Narcotics,
                  data=qualityTrain, family = binomial)
summary(QualityLog)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: First Logistic Regression Model

                                Call:
                                glm(formula = PoorCare ~ OfficeVisits + Narcotics, family = binomial,
                                data = qualityTrain)

                                Deviance Residuals:
                                Min        1Q    Median        3Q       Max
                                -2.06303  -0.63155  -0.50503  -0.09689   2.16686

                                Coefficients:
                                Estimate Std. Error z value Pr(&gt;|z|)
                                (Intercept)  -2.64613    0.52357  -5.054 4.33e-07 ***
                                OfficeVisits  0.08212    0.03055   2.688  0.00718 **
                                Narcotics     0.07630    0.03205   2.381  0.01728 *
                                ---
                                Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

                                (Dispersion parameter for binomial family taken to be 1)

                                Null deviance: 111.888  on 98  degrees of freedom
                                Residual deviance:  89.127  on 96  degrees of freedom
                                AIC: 95.127

                                Number of Fisher Scoring iterations: 4
=======
 :: First Logistic Regression Model

Call:
glm(formula = PoorCare ~ OfficeVisits + Narcotics, family = binomial,
    data = qualityTrain)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-2.06303  -0.63155  -0.50503  -0.09689   2.16686

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)  -2.64613    0.52357  -5.054 4.33e-07 ***
OfficeVisits  0.08212    0.03055   2.688  0.00718 **
Narcotics     0.07630    0.03205   2.381  0.01728 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 111.888  on 98  degrees of freedom
Residual deviance:  89.127  on 96  degrees of freedom
AIC: 95.127

Number of Fisher Scoring iterations: 4
>>>>>>> origin/master
                            </pre>

                            <p>
                                This gives the estimate values for the coefficients, or the betas, for
                                our logistic regression model. We see here that the coefficients for
                                <b>OfficeVisits</b> and <b>Narcotics</b> are both positive, which means that higher
                                values in these two variables are indicative of poor care as we
                                suspected from looking at the data.
                            </p>

                            <p>
                                We also see that both of these variables have at least one star,
                                meaning that they're significant in our model.
                            </p>

                            <p>
                                The preferred model is the one with the minimum <b>AIC</b>.
                            </p>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-9-6" class="outline-4">
                        <h4 id="sec-1-9-6"><span class="section-number-4">1.9.6</span> Predictions in the training set</h4>
                        <div class="outline-text-4" id="text-1-9-6">
                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Make predictions on training set"</span>)
<<<<<<< HEAD
                                predictTrain <span style="color: #db7093;">&lt;-</span> predict(QualityLog, type = <span style="color: #fffacd;">"response"</span>)
=======
predictTrain <span style="color: #db7093;">&lt;-</span> predict(QualityLog, type = <span style="color: #fffacd;">"response"</span>)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Make predictions on training set
=======
:: Make predictions on training set
>>>>>>> origin/master
                            </pre>

                            <p>
                                The second argument which is type="response". This tells the predict
                                function to give us probabilities. Let's take a look at the
                                statistical summary of our predictions.
                            </p>

                            <div class="org-src-container">

                                <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Analyze predictions"</span>)
<<<<<<< HEAD
                                summary(predictTrain)
                                tapply(predictTrain, qualityTrain$PoorCare, mean)
=======
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Analyze predictions
                                Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
                                0.06623 0.11910 0.15970 0.25250 0.26760 0.98460
                                0         1
                                0.1894512 0.4392246
=======
 :: Analyze predictions
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.06623 0.11910 0.15970 0.25250 0.26760 0.98460
        0         1
0.1894512 0.4392246
>>>>>>> origin/master
                            </pre>

                            <p>
                                Since we're expecting probabilities, all of the numbers should be
                                between zero and one. And we see that the minimum value is about
                                \(0.07\) and the maximum value is \(0.98\).
                            </p>

                            <p>
                                Let's see if we're predicting higher probabilities for the actual poor
                                care cases as we expect. Using the <code>tapply</code> function. So we see that
                                for all of the <b>true poor care</b> cases, we predict an average probability
                                of about \(0.44\). And all of the <b>true good care</b> cases, we predict an
                                average probability of about \(0.19\).
                            </p>

                            <p>
                                <b>So this is a good sign, because it looks like we're predicting a
<<<<<<< HEAD
                                higher probability for the actual poor care cases</b>.
=======
                                    higher probability for the actual poor care cases</b>.
>>>>>>> origin/master
                            </p>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-10" class="outline-3">
                    <h3 id="sec-1-10"><span class="section-number-3">1.10</span> Quick Question (1 point possible)</h3>
                    <div class="outline-text-3" id="text-1-10">
                        <p>
                            In R, create a logistic regression model to predict "PoorCare" using
                            the independent variables "StartedOnCombination" and
                            "ProviderCount". Use the training set we created in the previous video
                            to build the model.
                        </p>

                        <p>
                            Note: If you haven't already loaded and split the data in R, please
                            run these commands in your R console to load and split the data
                            set. Remember to first navigate to the directory where you have saved
                            "quality.csv".
                        </p>

                        <p>
                            <code>quality = read.csv("quality.csv")</code>
                        </p>

                        <p>
                            <code>install.packages("caTools")</code>
                        </p>

                        <p>
                            <code>library(caTools)</code>
                        </p>

                        <p>
                            <code>set.seed(88)</code>
                        </p>

                        <p>
                            <code>split = sample.split(quality$PoorCare, SplitRatio = 0.75)</code>
                        </p>

                        <p>
                            <code>qualityTrain = subset(quality, split == TRUE)</code>
                        </p>

                        <p>
                            <code>qualityTest = subset(quality, split == FALSE)</code>
                        </p>

                        <p>
                            Then recall that we built a logistic regression model to predict
                            PoorCare using the R command:
                        </p>

                        <div class="org-src-container">

                            <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: create a logistic regression model to predict PoorCare using</span>
<<<<<<< HEAD
                            <span style="color: #fffacd;">the independent variables StartedOnCombination and ProviderCount:"</span>)
                            QualityLog2 <span style="color: #db7093;">&lt;-</span> glm(PoorCare ~ StartedOnCombination + ProviderCount,
                            data = qualityTrain, family = binomial)
                            summary(QualityLog2)
=======
                                <span style="color: #fffacd;">the independent variables StartedOnCombination and ProviderCount:"</span>)
QualityLog2 <span style="color: #db7093;">&lt;-</span> glm(PoorCare ~ StartedOnCombination + ProviderCount,
                   data = qualityTrain, family = binomial)
summary(QualityLog2)
>>>>>>> origin/master
                            </pre>
                        </div>

                        <pre class="example">
<<<<<<< HEAD
                            :: create a logistic regression model to predict PoorCare using
                            the independent variables StartedOnCombination and ProviderCount:

                            Call:
                            glm(formula = PoorCare ~ StartedOnCombination + ProviderCount,
                            family = binomial, data = qualityTrain)

                            Deviance Residuals:
                            Min        1Q    Median        3Q       Max
                            -1.61826  -0.72782  -0.64555  -0.08407   1.94662

                            Coefficients:
                            Estimate Std. Error z value Pr(&gt;|z|)
                            (Intercept)              -2.00097    0.55097  -3.632 0.000282 ***
                            StartedOnCombinationTRUE  1.95230    1.22342   1.596 0.110541
                            ProviderCount             0.03366    0.01983   1.697 0.089706 .
                            ---
                            Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

                            (Dispersion parameter for binomial family taken to be 1)

                            Null deviance: 111.89  on 98  degrees of freedom
                            Residual deviance: 104.37  on 96  degrees of freedom
                            AIC: 110.37

                            Number of Fisher Scoring iterations: 4
=======
 :: create a logistic regression model to predict PoorCare using
the independent variables StartedOnCombination and ProviderCount:

Call:
glm(formula = PoorCare ~ StartedOnCombination + ProviderCount,
    family = binomial, data = qualityTrain)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-1.61826  -0.72782  -0.64555  -0.08407   1.94662

Coefficients:
                         Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)              -2.00097    0.55097  -3.632 0.000282 ***
StartedOnCombinationTRUE  1.95230    1.22342   1.596 0.110541
ProviderCount             0.03366    0.01983   1.697 0.089706 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 111.89  on 98  degrees of freedom
Residual deviance: 104.37  on 96  degrees of freedom
AIC: 110.37

Number of Fisher Scoring iterations: 4
>>>>>>> origin/master
                        </pre>

                        <p>
                            You will need to adjust this command to answer this question, and then
                            look at the <code>summary(QualityLog)</code> output.
                        </p>

                        <p>
                            What is the coefficient for <b>StartedOnCombination</b>?
                        </p>
                    </div>

                    <div id="outline-container-sec-1-10-1" class="outline-4">
                        <h4 id="sec-1-10-1"><span class="section-number-4">1.10.1</span> Answer</h4>
                        <div class="outline-text-4" id="text-1-10-1">
                            <p>
                                If you look at the output of <code>summary(Model)</code>, the value of the
                                coefficient (Estimate) for <code>StartedOnCombination</code> is \(1.95230\).
                            </p>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-11" class="outline-3">
                    <h3 id="sec-1-11"><span class="section-number-3">1.11</span> Quick Question (1 point possible)</h3>
                    <div class="outline-text-3" id="text-1-11">
                        <p>
                            <b>StartedOnCombination</b> is a binary variable, which equals \(1\) if the
                            patient is started on a combination of drugs to treat their diabetes,
                            and equals \(0\) if the patient is not started on a combination of
                            drugs. All else being equal, does this model imply that starting a
                            patient on a combination of drugs is indicative of poor care, or good
                            care?
                        </p>
                    </div>

                    <div id="outline-container-sec-1-11-1" class="outline-4">
                        <h4 id="sec-1-11-1"><span class="section-number-4">1.11.1</span> Answer</h4>
                        <div class="outline-text-4" id="text-1-11-1">
                            <p>
                                <b>Explanation</b>
                            </p>

                            <p>
                                The coefficient value is positive, meaning that positive values of the
                                variable make the outcome of \(1\) more likely. This corresponds to Poor
                                Care.
                            </p>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-12" class="outline-3">
                    <h3 id="sec-1-12"><span class="section-number-3">1.12</span> Video 5: Thresholding</h3>
                    <div class="outline-text-3" id="text-1-12">
                        <p>
                            Often, we want to make an actual prediction.  Should we predict \(1\) for
                            <b>poor care</b>, or should we predict \(0\) for <b>good care</b>? We can convert the
                            probabilities to predictions using what's called a threshold value, \(t\).
                        </p>

                        <p>
                            If the probability of <b>poor care</b> is greater than this threshold value,
                            \(t\), we predict <b>poor quality care</b>. But if the probability of <b>poor care</b>
                            is less than the threshold value, \(t\), then we predict <b>good quality
                            care</b>.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/ThresholdValue.png" alt="ThresholdValue.png" />
                            </p>
                        </div>

                        <p>
                            <b>What value should we pick for the threshold, t?</b>
                        </p>

                        <p>
                            The threshold value, \(t\), is often selected based on which errors are
                            better. You might be thinking that making no errors is better, which
                            is, of course, true.
                        </p>

                        <p>
                            But it's rare to have a model that predicts perfectly, so you're bound
                            to make some errors. There are two types of errors that a model can
                            make &#x2013;ones where you predict \(1\), or <b>poor care</b>, but the actual
                            outcome is \(0\), and ones where you predict \(0\), or good care, but the
                            actual outcome is \(1\).
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/ThresholdValue02.png" alt="ThresholdValue02.png" />
                            </p>
                        </div>

                        <ul class="org-ul">
                            <li>The large \(t\) selection approach would detect the patients receiving
                            </li>
                        </ul>
                        <p>
                            the worst care and prioritize them for intervention.
                        </p>

                        <ul class="org-ul">
                            <li>The small \(t\) selection approach would detect all patients who might
                            </li>
                        </ul>
                        <p>
                            be receiving poor care.
                        </p>

                        <p>
                            Some decision-makers often have a preference for one type of error
                            over the other, which should influence the threshold value they pick.
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-13" class="outline-3">
                    <h3 id="sec-1-13"><span class="section-number-3">1.13</span> The confusion matrix or classification matrix</h3>
                    <div class="outline-text-3" id="text-1-13">

                        <div class="figure">
                            <p><img src="../graphs/ThresholdValue03.png" alt="ThresholdValue03.png" />
                            </p>
                        </div>

                        <p>
                            The rows are labeled with the actual outcome, and the columns are
                            labeled with the predicted outcome.
                        </p>

                        <p>
                            Each entry of the table gives the number of data observations that
                            fall into that category. So the number of <b>true negatives</b>, or <b>TN</b>, is
                            the number of observations that are actually good care and for which
                            we predict good care.
                        </p>

                        <p>
                            The <b>true positives</b>, or <b>TP</b>, is the number of observations that are
                            actually poor care and for which we predict poor care. These are the
                            two types that we get correct.
                        </p>

                        <p>
                            The <b>false positives</b>, or <b>FP</b>, are the number of data points for which we
                            predict poor care, but they're actually good care. And the <b>false
                            negatives</b>, or FN, are the number of data points for which we predict
                            good care, but they're actually poor care.
                        </p>

                        <ul class="org-ul">
                            <li>The Sensitivity is often called <b>the true positive rate</b> and
<<<<<<< HEAD
                            measures the percentage of actual poor care cases that we classify
                            correctly.
                            </li>

                            <li>The Specificity is called <b>the true negative rate</b> and measures the
                            percentage of actual good care cases that we classify correctly.
=======
                                measures the percentage of actual poor care cases that we classify
                                correctly.
                            </li>

                            <li>The Specificity is called <b>the true negative rate</b> and measures the
                                percentage of actual good care cases that we classify correctly.
>>>>>>> origin/master
                            </li>
                        </ul>

                        <p>
                            A model with a <b>higher threshold</b> will have a <b>lower sensitivity</b> and a
                            <b>higher specificity</b>. A model with a <b>lower threshold</b> will have a higher
                            <b>sensitivity</b> and a lower <b>specificity</b>.
                        </p>

                        <div class="org-src-container">

                            <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Confusion matrix for threshold of 0.5:"</span>)
<<<<<<< HEAD
                            table(qualityTrain$PoorCare, predictTrain &gt; 0.5)

                            writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
                            10/25

                            writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
                            70/74
=======
table(qualityTrain$PoorCare, predictTrain &gt; 0.5)

writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
10/25

writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
70/74
>>>>>>> origin/master
                            </pre>
                        </div>

                        <pre class="example">
<<<<<<< HEAD
                            :: Confusion matrix for threshold of 0.5:

                            FALSE TRUE
                            0    70    4
                            1    15   10

                            :: Sensitivity:
                            [1] 0.4

                            :: Specificity:
                            [1] 0.9459459
=======
 :: Confusion matrix for threshold of 0.5:

    FALSE TRUE
  0    70    4
  1    15   10

 :: Sensitivity:
[1] 0.4

 :: Specificity:
[1] 0.9459459
>>>>>>> origin/master
                        </pre>

                        <p>
                            So you can see here that for \(70\) cases, we <b>predict good care</b> and they
                            actually <b>received good care</b>, and for \(10\) cases, we <b>predict poor care</b>,
                            and they actually <b>received poor care</b>.
                        </p>

                        <p>
                            We make \(4\) mistakes where <b>we say poor care</b> and it's actually <b>good
                            care</b>, and we make \(15\) mistakes where <b>we say good care</b>, but it's
                            <b>actually poor care</b>.
                        </p>

                        <p>
                            Now we can experiment with a higher threshold:
                        </p>

                        <div class="org-src-container">

                            <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Confusion matrix for threshold of 0.7"</span>)
<<<<<<< HEAD
                            table(qualityTrain$PoorCare, predictTrain &gt; 0.7)

                            writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
                            8/25

                            writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
                            73/74
=======
table(qualityTrain$PoorCare, predictTrain &gt; 0.7)

writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
8/25

writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
73/74
>>>>>>> origin/master
                            </pre>
                        </div>

                        <pre class="example">
<<<<<<< HEAD
                            :: Confusion matrix for threshold of 0.7

                            FALSE TRUE
                            0    73    1
                            1    17    8

                            :: Sensitivity:
                            [1] 0.32

                            :: Specificity:
                            [1] 0.9864865
=======
 :: Confusion matrix for threshold of 0.7

    FALSE TRUE
  0    73    1
  1    17    8

 :: Sensitivity:
[1] 0.32

 :: Specificity:
[1] 0.9864865
>>>>>>> origin/master
                        </pre>

                        <p>
                            So by increasing the threshold, our sensitivity went down and our
                            specificity went up.
                        </p>

                        <p>
                            If now we choose a small threshold:
                        </p>

                        <div class="org-src-container">

                            <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Confusion matrix for threshold of 0.2"</span>)
<<<<<<< HEAD
                            table(qualityTrain$PoorCare, predictTrain &gt; 0.2)

                            writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
                            16/25

                            writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
                            54/74
=======
table(qualityTrain$PoorCare, predictTrain &gt; 0.2)

writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
16/25

writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
54/74
>>>>>>> origin/master
                            </pre>
                        </div>

                        <pre class="example">
<<<<<<< HEAD
                            :: Confusion matrix for threshold of 0.2

                            FALSE TRUE
                            0    54   20
                            1     9   16

                            :: Sensitivity:
                            [1] 0.64

                            :: Specificity:
                            [1] 0.7297297
=======
 :: Confusion matrix for threshold of 0.2

    FALSE TRUE
  0    54   20
  1     9   16

 :: Sensitivity:
[1] 0.64

 :: Specificity:
[1] 0.7297297
>>>>>>> origin/master
                        </pre>

                        <p>
                            So with the lower threshold, our sensitivity went up, and our
                            specificity went down.
                        </p>

                        <p>
                            <b>But which threshold should we pick?</b> Maybe \(0.4\) is better, or
                            \(0.6\). How do we decide?
                        </p>
                    </div>
                </div>

                <div id="outline-container-sec-1-14" class="outline-3">
                    <h3 id="sec-1-14"><span class="section-number-3">1.14</span> Confusion matrices questions</h3>
                    <div class="outline-text-3" id="text-1-14">
                        <p>
                            This question asks about the following two confusion matrices:
                        </p>
                    </div>

                    <div id="outline-container-sec-1-14-1" class="outline-4">
                        <h4 id="sec-1-14-1"><span class="section-number-4">1.14.1</span> Confusion Matrix #1:</h4>
                        <div class="outline-text-4" id="text-1-14-1">
                            <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


                                <colgroup>
                                    <col  class="left" />

                                    <col  class="right" />

                                    <col  class="right" />
                                </colgroup>
                                <thead>
                                    <tr>
                                        <th scope="col" class="left">&#xa0;</th>
                                        <th scope="col" class="right">Predicted = 0</th>
                                        <th scope="col" class="right">Predicted = 1</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td class="left">Actual = 0</td>
                                        <td class="right">15</td>
                                        <td class="right">10</td>
                                    </tr>

                                    <tr>
                                        <td class="left">Actual = 1</td>
                                        <td class="right">5</td>
                                        <td class="right">20</td>
                                    </tr>
                                </tbody>
                            </table>

                            <div class="org-src-container">

                                <pre class="src src-R">TP <span style="color: #db7093;">&lt;-</span> 20; TN <span style="color: #db7093;">&lt;-</span> 15; FP <span style="color: #db7093;">&lt;-</span> 10; FN <span style="color: #db7093;">&lt;-</span> 5;
<<<<<<< HEAD
                                writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
                                Sensitivity <span style="color: #db7093;">&lt;-</span> TP / (TP + FN)
                                Sensitivity

                                writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
                                Specificity <span style="color: #db7093;">&lt;-</span> TN / (TN + FP)
                                Specificity
=======
writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
Sensitivity <span style="color: #db7093;">&lt;-</span> TP / (TP + FN)
Sensitivity

writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
Specificity <span style="color: #db7093;">&lt;-</span> TN / (TN + FP)
Specificity
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Sensitivity:
                                [1] 0.8

                                :: Specificity:
                                [1] 0.6
=======
 :: Sensitivity:
[1] 0.8

 :: Specificity:
[1] 0.6
>>>>>>> origin/master
                            </pre>
                        </div>

                        <div id="outline-container-sec-1-14-1-1" class="outline-5">
                            <h5 id="sec-1-14-1-1"><span class="section-number-5">1.14.1.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-14-1-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The <b>sensitivity</b> of a confusion matrix is the true positives, divided
                                    by the true positives plus the false negatives. In this case, it is
                                    20/(20+5) = 0.8
                                </p>

                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The <b>specificity</b> of a confusion matrix is the true negatives, divided
                                    by the true negatives plus the false positives. In this case, it is
                                    15/(15+10) = 0.6
                                </p>
                            </div>
                        </div>
                    </div>



                    <div id="outline-container-sec-1-14-2" class="outline-4">
                        <h4 id="sec-1-14-2"><span class="section-number-4">1.14.2</span> Confusion Matrix #2:</h4>
                        <div class="outline-text-4" id="text-1-14-2">
                            <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


                                <colgroup>
                                    <col  class="left" />

                                    <col  class="right" />

                                    <col  class="right" />
                                </colgroup>
                                <thead>
                                    <tr>
                                        <th scope="col" class="left">&#xa0;</th>
                                        <th scope="col" class="right">Predicted = 0</th>
                                        <th scope="col" class="right">Predicted = 1</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td class="left">Actual = 0</td>
                                        <td class="right">20</td>
                                        <td class="right">5</td>
                                    </tr>

                                    <tr>
                                        <td class="left">Actual = 1</td>
                                        <td class="right">10</td>
                                        <td class="right">15</td>
                                    </tr>
                                </tbody>
                            </table>

                            <div class="org-src-container">

                                <pre class="src src-R">TP <span style="color: #db7093;">&lt;-</span> 15; TN <span style="color: #db7093;">&lt;-</span> 20; FP <span style="color: #db7093;">&lt;-</span> 5; FN <span style="color: #db7093;">&lt;-</span> 10;
<<<<<<< HEAD
                                writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
                                Sensitivity <span style="color: #db7093;">&lt;-</span> TP / (TP + FN)
                                Sensitivity

                                writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
                                Specificity <span style="color: #db7093;">&lt;-</span> TN / (TN + FP)
                                Specificity
=======
writeLines(<span style="color: #fffacd;">"\n :: Sensitivity:"</span>)
Sensitivity <span style="color: #db7093;">&lt;-</span> TP / (TP + FN)
Sensitivity

writeLines(<span style="color: #fffacd;">"\n :: Specificity:"</span>)
Specificity <span style="color: #db7093;">&lt;-</span> TN / (TN + FP)
Specificity
>>>>>>> origin/master
                                </pre>
                            </div>

                            <pre class="example">
<<<<<<< HEAD
                                :: Sensitivity:
                                [1] 0.6

                                :: Specificity:
                                [1] 0.8
=======
 :: Sensitivity:
[1] 0.6

 :: Specificity:
[1] 0.8
>>>>>>> origin/master
                            </pre>
                        </div>

                        <div id="outline-container-sec-1-14-2-1" class="outline-5">
                            <h5 id="sec-1-14-2-1"><span class="section-number-5">1.14.2.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-14-2-1">
                                <p>
                                    The <b>Sensitivity</b> in the matrix 1 was \(0.8\) and was \(0.6\) in the
                                    second matrix, then the threshold went up.
                                </p>

                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    We predict the outcome 1 less often in Confusion Matrix #2. This means
                                    we must have increased the threshold.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-15" class="outline-3">
                    <h3 id="sec-1-15"><span class="section-number-3">1.15</span> Video 6: ROC Curves</h3>
                    <div class="outline-text-3" id="text-1-15">
                        <p>
                            Picking a good threshold value is often challenging. A Receiver
                            Operator Characteristic curve, or ROC curve, can help you decide which
                            value of the threshold is best.
                        </p>


                        <div class="figure">
                            <p><img src="../graphs/ROC.png" alt="ROC.png" />
                            </p>
                        </div>

                        <p>
                            The sensitivity or true positive rate is in the \(y\) axis and the false
                            positive rate, or 1 minus the specificity, is given on the x-axis.
                        </p>

                        <ul class="org-ul">
                            <li>The line shows how these two outcome measures vary with different
<<<<<<< HEAD
                            threshold values. The ROC curve always starts at the point \((0,
                            0)\). This corresponds to a threshold value of \(1\). If you have a
                            threshold of \(1\), you will not catch any poor care cases, or have a
                            sensitivity of \(0\). But you will correctly label of all the good
                            care cases, meaning you have a false positive rate of \(0\).
                            </li>

                            <li>The ROC curve always ends at the point \((1, 1)\), which corresponds
                            to a threshold value of \(0\). If you have a threshold of \(0\), you'll
                            catch all of the poor care cases, or have a sensitivity of \(1\), but
                            you'll label all of the good care cases as poor care cases too,
                            meaning you have a false positive rate of \(1\).
                            </li>

                            <li>The threshold decreases as you move from \((0, 0)\) to \((1, 1)\). At
                            the point \((0, 0.4)\), or about here, you're correctly labeling about
                            \(40\%\) of the poor care cases with a very small false positive
                            rate.
                            </li>

                            <li>On the other hand, at the point \((0.6, 0.9)\), you're correctly
                            labeling about \(90\%\) of the poor care cases, but have a false
                            positive rate of \(60\%\).
                            </li>

                            <li>In the middle, around \((0.3, 0.8)\), you're correctly labeling about
                            80% of the poor care cases, with a \(30\%\) false positive rate.
=======
                                threshold values. The ROC curve always starts at the point \((0,
                                0)\). This corresponds to a threshold value of \(1\). If you have a
                                threshold of \(1\), you will not catch any poor care cases, or have a
                                sensitivity of \(0\). But you will correctly label of all the good
                                care cases, meaning you have a false positive rate of \(0\).
                            </li>

                            <li>The ROC curve always ends at the point \((1, 1)\), which corresponds
                                to a threshold value of \(0\). If you have a threshold of \(0\), you'll
                                catch all of the poor care cases, or have a sensitivity of \(1\), but
                                you'll label all of the good care cases as poor care cases too,
                                meaning you have a false positive rate of \(1\).
                            </li>

                            <li>The threshold decreases as you move from \((0, 0)\) to \((1, 1)\). At
                                the point \((0, 0.4)\), or about here, you're correctly labeling about
                                \(40\%\) of the poor care cases with a very small false positive
                                rate.
                            </li>

                            <li>On the other hand, at the point \((0.6, 0.9)\), you're correctly
                                labeling about \(90\%\) of the poor care cases, but have a false
                                positive rate of \(60\%\).
                            </li>

                            <li>In the middle, around \((0.3, 0.8)\), you're correctly labeling about
                                80% of the poor care cases, with a \(30\%\) false positive rate.
>>>>>>> origin/master
                            </li>
                        </ul>


                        <div class="figure">
                            <p><img src="../graphs/ROC02.png" alt="ROC02.png" />
                            </p>
                        </div>

                        <ul class="org-ul">
                            <li>The <b>higher the threshold</b>, or closer to \((0, 0)\), the <b>higher</b> the
<<<<<<< HEAD
                            <b>specificity</b> and the <b>lower</b> the <b>sensitivity</b>. The <b>lower the
                            threshold</b>,   or closer to \((1,1)\), the <b>higher</b> the <b>sensitivity</b>
                            and lower the <b>specificity</b>.
=======
                                <b>specificity</b> and the <b>lower</b> the <b>sensitivity</b>. The <b>lower the
                                    threshold</b>,   or closer to \((1,1)\), the <b>higher</b> the <b>sensitivity</b>
                                and lower the <b>specificity</b>.
>>>>>>> origin/master
                            </li>
                        </ul>

                        <p>
                            <b>So which threshold value should you pick?</b> You should select the best
                            threshold for the trade-off you want to make.
                        </p>

                        <ul class="org-ul">
                            <li>If you're more concerned with having a <b>high specificity</b> or <b>low
<<<<<<< HEAD
                            false positive rate</b>, pick the threshold that <b>maximizes the true
                            positive rate</b> while <b>keeping the false positive rate really low</b>. A
                            threshold around \((0.1, 0.5)\) on this ROC curve looks like a good
                            choice in this case.
                            </li>

                            <li>On the other hand, if you're more concerned with having a <b>high
                            sensitivity</b> or <b>high true positive rate</b>, pick a threshold that
                            <b>minimizes the false positive rate but has a very high true positive
                            rate</b>. A threshold around \((0.3, 0.8)\) looks like a good choice in
                            this case.
=======
                                false positive rate</b>, pick the threshold that <b>maximizes the true
                                positive rate</b> while <b>keeping the false positive rate really low</b>. A
                                threshold around \((0.1, 0.5)\) on this ROC curve looks like a good
                                choice in this case.
                            </li>

                            <li>On the other hand, if you're more concerned with having a <b>high
                                sensitivity</b> or <b>high true positive rate</b>, pick a threshold that
                                <b>minimizes the false positive rate but has a very high true positive
                                    rate</b>. A threshold around \((0.3, 0.8)\) looks like a good choice in
                                this case.
>>>>>>> origin/master
                            </li>
                        </ul>


                        <div class="figure">
                            <p><img src="../graphs/ROC03.png" alt="ROC03.png" />
                            </p>
                        </div>

                        <p>
                            Recall that we made predictions on our training set and called them
                            <b>predictTrain</b>. We'll use these predictions to create our ROC
                            curve. First, we'll call the <b>prediction function of ROCR</b>. We'll call
                            the output of this function <b>ROCRpred</b>, and then use the prediction
                            function.
                        </p>

                        <p>
                            This function takes two arguments. The first is the predictions we
                            made with our model, which we called <b>predictTrain</b>. The second argument
                            is the true outcomes of our data points, which in our case, is
                            <b>qualityTrain$PoorCare</b>.
                        </p>

                        <p>
                            Now, we need to use the <b>performance function</b>. This defines what we'd
                            like to plot on the x and y-axes of our ROC curve. We'll call the
                            output of this <b>ROCRperf</b>, and use the performance function, which takes
                            as arguments the <b>output of the prediction function</b>, and then what we
                            want on the x and y-axes.
                        </p>

                        <div class="org-src-container">

                            <pre class="src src-R">writeLines(<span style="color: #fffacd;">"\n :: Install package only once"</span>)
<<<<<<< HEAD
                            <span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('ROCR', repos='http://cran.rstudio.com/')</span>
                            <span style="color: #db7093;">library</span>(ROCR)

                            writeLines(<span style="color: #fffacd;">"\n :: Prediction function"</span>)
                            ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)

                            writeLines(<span style="color: #fffacd;">"\n :: Performance function"</span>)
                            ROCRperf = performance(ROCRpred, <span style="color: #fffacd;">"tpr"</span>, <span style="color: #fffacd;">"fpr"</span>)
=======
                                <span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('ROCR', repos='http://cran.rstudio.com/')</span>
                                <span style="color: #db7093;">library</span>(ROCR)

writeLines(<span style="color: #fffacd;">"\n :: Prediction function"</span>)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)

writeLines(<span style="color: #fffacd;">"\n :: Performance function"</span>)
ROCRperf = performance(ROCRpred, <span style="color: #fffacd;">"tpr"</span>, <span style="color: #fffacd;">"fpr"</span>)
>>>>>>> origin/master
                            </pre>
                        </div>

                        <pre class="example">
<<<<<<< HEAD
                            :: Install package only once

                            :: Prediction function

                            :: Performance function
=======
:: Install package only once

:: Prediction function

:: Performance function
>>>>>>> origin/master
                        </pre>


                        <div id="fig:ThresholdLabelsPlot" class="figure">
                            <p><img src="../graphs/ThresholdLabelsPlot.png" alt="ThresholdLabelsPlot.png" />
                            </p>
                            <p><span class="figure-number">Figure 22:</span> Add threshold labels to better pick up a right value of t</p>
                        </div>
                    </div>
                </div>

                <div id="outline-container-sec-1-16" class="outline-3">
                    <h3 id="sec-1-16"><span class="section-number-3">1.16</span> Quick Question (2 points possible)</h3>
                    <div class="outline-text-3" id="text-1-16">
<<<<<<< HEAD
                        </div><div id="outline-container-sec-1-16-1" class="outline-4">
=======
                    </div><div id="outline-container-sec-1-16-1" class="outline-4">
>>>>>>> origin/master
                        <h4 id="sec-1-16-1"><span class="section-number-4">1.16.1</span> Question a</h4>
                        <div class="outline-text-4" id="text-1-16-1">
                            <p>
                                Given this ROC curve, which threshold would you pick if you wanted to
                                correctly identify a small group of patients who are receiving the
                                worst care with high confidence?
                            </p>
                        </div>

                        <div id="outline-container-sec-1-16-1-1" class="outline-5">
                            <h5 id="sec-1-16-1-1"><span class="section-number-5">1.16.1.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-16-1-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The threshold \(0.7\) is best to identify a small group of patients who
                                    are receiving the worst care with high confidence, since at this
                                    threshold we make very few false positive mistakes, and identify about
                                    35% of the true positives.
                                </p>

                                <p>
                                    The threshold \(t = 0.8\) is not a good choice, since it makes about the
                                    same number of false positives, but only identifies \(10\%\) of the true
                                    positives. The thresholds \(0.2\) and \(0.3\) both identify more of the true
                                    positives, but they make more false positive mistakes, so our
                                    confidence decreases.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div id="outline-container-sec-1-16-2" class="outline-4">
                        <h4 id="sec-1-16-2"><span class="section-number-4">1.16.2</span> Question b</h4>
                        <div class="outline-text-4" id="text-1-16-2">
                            <p>
                                Which threshold would you pick if you wanted to correctly identify
                                half of the patients receiving poor care, while making as few errors
                                as possible?
                            </p>
                        </div>

                        <div id="outline-container-sec-1-16-2-1" class="outline-5">
                            <h5 id="sec-1-16-2-1"><span class="section-number-5">1.16.2.1</span> Answer</h5>
                            <div class="outline-text-5" id="text-1-16-2-1">
                                <p>
                                    <b>Explanation</b>
                                </p>

                                <p>
                                    The threshold \(0.3\) is the best choice in this scenerio. The threshold
                                    \(0.2\) also identifies over half of the patients receiving poor care,
                                    but it makes many more false positive mistakes. The thresholds \(0.7\)
                                    and \(0.8\) don't identify at least half of the patients receiving poor
                                    care.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div id="postamble" class="status">
            <p class="date">Date: 26/06/2015</p>
            <p class="author">Author: Sergio-Feliciano Mendoza-Barrera</p>
            <p class="date">Created: 2015-06-26 Fri 12:24</p>
            <p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
            <p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
        </div>
    </body>
</html>
