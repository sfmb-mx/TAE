x1 <- c(0, 1, 2, 3, 4);

writeLines("\n :: The step in odds units:")
exp(beta1)

logit <- beta0 + (beta1 * x1)
writeLines("\n :: The value of logit is:")
logit
'org_babel_R_eoe'
writeLines("\n :: Building the new test set:")
newObservation <- c(1, 1, 50, 1, 3, 12, 0, 2, 1)
newTest <- rbind(test, newObservation)
newTest <- newTest[203, ]
newTest
'org_babel_R_eoe'
logit <- -4.2411574 + (0.3869904 * 1) + (0.8867192 * 1) + (-0.0001756
        * 50) + (-0.1238867 * 3) + (0.0802954 * 12) + (0.6837143 * 1)

writeLines("\n :: The Odds are:")
exp(logit)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of this individual is a violator:")
predictNewTest <- predict(ParoleLog1, type = "response", newdata = newTest)
predictNewTest
'org_babel_R_eoe'
writeLines("\n :: Predicting the maximum probability of a violation:")
predictTest <- predict(ParoleLog1, type = "response", newdata = test)
head(sort(predictTest, decreasing = TRUE), 1)
'org_babel_R_eoe'
predictTest <- predict(ParoleLog1, type = "response", newdata = test)

writeLines("\n :: Confusion matrix for threshold of 0.5:")
table(test$violator, predictTest >= 0.5)

TN <- 167; FP <- 12;
FN <- 11;  TP <- 12;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(test$violator)

writeLines("\n :: The accuracy of the simple model:")
179 / (179 + 23)
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.2:")
table(test$violator, predictTest >= 0.2)

TN <- 154; FP <- 25;
FN <- 6;  TP <- 17;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Install package only once")
library(ROCR)

writeLines("\n :: Prediction function")
ROCRpred = prediction(predictTest, test$violator)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans.csv"

fileName <- "loans.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frame.")
loans <- read.csv("../data/loans.csv")
str(loans)
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Proportion of not fully paid loans:")
nrow(subset(loans, loans$not.fully.paid == 1)) / nrow(loans)
'org_babel_R_eoe'
writeLines("\n :: Variables with NA instances:")
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Number of loans:")
nrow(loans)

writeLines("\n :: Number of observations with complete information:")
nrow(loans[complete.cases(loans), ])

writeLines("\n :: Non complete cases:")
nrow(loans[!complete.cases(loans), ])

table(loans[!complete.cases(loans), ]$not.fully.paid)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans_imputed.csv"

fileName <- "loans_imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading imputed data into their data frame.")
loans <- read.csv("../data/loans_imputed.csv")

writeLines("\n :: Verifying non NA existance:")
anyNA(loans)
'org_babel_R_eoe'
writeLines("\n :: Split the loans dataset in training and testing datasets:")
set.seed(144)
library(caTools)
split <- sample.split(loans$not.fully.paid, SplitRatio = 0.7)
loansTrain <- subset(loans, split == TRUE)
loansTest <- subset(loans, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
LoansLog1 = glm(not.fully.paid ~ ., data = loansTrain, family = binomial)
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: The value of Logit(A) - Logit(B)")
LogitAMinusLogitB <- -9.317e-03 * (700 - 710)
LogitAMinusLogitB
'org_babel_R_eoe'
writeLines("\n :: The value of O(A) / O(B):")
exp(LogitAMinusLogitB)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of the testing set loans not being paid:")
predicted.risk <- predict(LoansLog1, type = "response", newdata = loansTest)
loansTest$predicted.risk <- predicted.risk

writeLines("\n :: Calculate the confusion matrix:")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
TN <- 2400; FP <- 13;
FN <- 457; TP <- 3;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(loansTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(loansTest$not.fully.paid)

writeLines("\n :: The accuracy of the simple model:")
2413 / (2413 + 460)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Prediction function:")
ROCRpred = prediction(predicted.risk, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 2")
LoansLog2 <- glm(not.fully.paid ~ int.rate, data = loansTrain, family = binomial)
summary(LoansLog2)

writeLines("\n :: Remembering the Model 1: Loanslog1:")
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: Correlation between int.rate and fico features:")
cor(loansTrain$int.rate, loansTrain$fico)
'org_babel_R_eoe'
names(loansTest)
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
table(loansTest$not.fully.paid, loansTest$predicted.risk > 0.5)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
table(loansTest$not.fully.paid, loansTest$predicted.risk > 0.5)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
table(loansTest$not.fully.paid, loansTest$predicted.risk > 0.5)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
table(loansTest$not.fully.paid, LoansTestprediction >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
table(loansTest$not.fully.paid, LoansTestPrediction >= 0.5)
'org_babel_R_eoe'
class(LoansTestPrediction)
writeLines("\n :: Number of loans not fully paid prediction:")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(Loanstestprediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(Loanstestprediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpredBV, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(LoansTestPrediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpredBV, "auc")@y.values)
'org_babel_R_eoe'
q()
n
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/songs.csv"

fileName <- "songs.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
songs <- read.csv("../data/songs.csv")
str(songs)
table(songs$Year)
summary(songs)
'org_babel_R_eoe'
writeLines("\n :: Number of songs in 2010:")
nrow(subset(songs, songs$year == 2010))

writeLines("\n :: Other way to calculate:")
table(songs$year)
'org_babel_R_eoe'
writeLines("\n :: Number of songs of Michael Jackson:")
nrow(subset(songs, songs$artistname == "Michael Jackson"))
'org_babel_R_eoe'
writeLines("\n :: Songs of Michael Jackson in the Top 10:")
sort(subset(songs, songs$artistname == "Michael Jackson" & songs$Top10
            == 1)$songtitle, decreasing = TRUE)
'org_babel_R_eoe'
writeLines("\n :: The values of the timesignature variable in the dataset:")
table(songs$timesignature)
'org_babel_R_eoe'
writeLines("\n :: the song with the highest tempo is:")
songs[which.max(songs$tempo), 2]

writeLines("\n :: Other way to calculate:")
songs$songtitle[which.max(songs$tempo)]
'org_babel_R_eoe'
writeLines("\n :: Building the training and testing sets:")
SongsTrain <- subset(songs, songs$year <= 2009)
writeLines("\n :: Number of observations in the training set:")
nrow(SongsTrain)

SongsTest <- subset(songs, songs$year >= 2010)
writeLines("\n :: Number of observations on the test set:")
nrow(SongsTest)
'org_babel_R_eoe'
writeLines("\n :: To remove variables from your training and testing sets:")
nonvars <- c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain <- SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest <- SongsTest[ , !(names(SongsTest) %in% nonvars) ]

writeLines("\n :: Build the logistic regression model:")
SongsLog1 <- glm(Top10 ~ ., data=SongsTrain, family=binomial)
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The summary of the model 1:")
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The summary of the model 1:")
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The correlation between variables loudness and energy:")
cor(SongsTrain$loudness, SongsTrain$energy)
'org_babel_R_eoe'
writeLines("\n :: Model 2 omiting the loudness variable:")
SongsLog2 <- glm(Top10 ~ . -loudness, data = SongsTrain, family = binomial)
summary(SongsLog2)
'org_babel_R_eoe'
writeLines("\n :: Model 3 omiting the energy variable:")
SongsLog3 <- glm(Top10 ~ . - energy, data = SongsTrain, family = binomial)
summary(SongsLog3)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
SongsTestPrediction <- predict(SongsLog3, newdata = SongsTest, type = "response")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(SongsTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Baseline accuracy:")
table(SongsTest$Top10)
'org_babel_R_eoe'
writeLines("\n :: Baseline model accuracy:")
BaselineModelAcc <- 314 / (314 + 59)
BaselineModelAcc
'org_babel_R_eoe'
writeLines("\n :: Test set predictions for 2010:")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Prediction in Top 10 in 2010:")
PredTop10.2010 <- TP
PredTop10.2010
'org_babel_R_eoe'
writeLines("\n :: Prediction in NON hits in 2010:")
PredNonHits2010 <- FP
PredNonHits2010
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Test set predictions for 2010:")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/parole.csv"

fileName <- "parole.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
parole <- read.csv("../data/parole.csv")
str(parole)
summary(parole)
'org_babel_R_eoe'
writeLines("\n :: Parelee violator in the data set")
nrow(subset(parole, parole$violator == 1))

writeLines("\n :: Other way to calculate the same result:")
table(parole$violator)
'org_babel_R_eoe'
str(parole)
'org_babel_R_eoe'
writeLines("\n :: Parole data set original:")
paroleOrig <- parole

writeLines("\n :: str() function over state and crime feature:")
str(paroleOrig$state)
str(paroleOrig$crime)

writeLines("\n :: table() function over state and crime feature:")
table(paroleOrig$state)
table(paroleOrig$crime)

writeLines("\n :: Converting state and crime features to factor...")
parole$state <- as.factor(parole$state)
parole$crime <- as.factor(parole$crime)
summary(parole)
'org_babel_R_eoe'
set.seed(144)
library(caTools)
split <- sample.split(parole$violator, SplitRatio = 0.7)
train <- subset(parole, split == TRUE)
test <- subset(parole, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Training set proportion:")
nrow(train) / (nrow(train) + nrow(test))

writeLines("\n :: Testing set proportion:")
nrow(test) / (nrow(train) + nrow(test))
'org_babel_R_eoe'
set.seed(144)
library(caTools)
split <- sample.split(parole$violator, SplitRatio = 0.7)
train <- subset(parole, split == TRUE)
test <- subset(parole, split == FALSE)

writeLines("\n :: Training set proportion:")
nrow(train) / (nrow(train) + nrow(test))

writeLines("\n :: Testing set proportion:")
nrow(test) / (nrow(train) + nrow(test))
'org_babel_R_eoe'
split2 <- sample.split(parole$violator, SplitRatio = 0.7)
train2 <- subset(parole, split2 == TRUE)
test2 <- subset(parole, split2 == FALSE)

writeLines("\n :: Differences between both sets of splits:")
## install.packages('compare', repos='http://cran.rstudio.com/')
library(compare)
compare(train, train2)
compare(test, test2)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
ParoleLog1 = glm(violator ~ ., data = train, family = binomial)
summary(ParoleLog1)
'org_babel_R_eoe'
beta0 <- -4.2411574; beta1 <- 1.6119919;
x1 <- c(0, 1, 2, 3, 4);

writeLines("\n :: The step in odds units:")
exp(beta1)

logit <- beta0 + (beta1 * x1)
writeLines("\n :: The value of logit is:")
logit
'org_babel_R_eoe'
writeLines("\n :: Building the new test set:")
newObservation <- c(1, 1, 50, 1, 3, 12, 0, 2, 1)
newTest <- rbind(test, newObservation)
newTest <- newTest[203, ]
newTest
'org_babel_R_eoe'
logit <- -4.2411574 + (0.3869904 * 1) + (0.8867192 * 1) + (-0.0001756
        * 50) + (-0.1238867 * 3) + (0.0802954 * 12) + (0.6837143 * 1)

writeLines("\n :: The Odds are:")
exp(logit)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of this individual is a violator:")
predictNewTest <- predict(ParoleLog1, type = "response", newdata = newTest)
predictNewTest
'org_babel_R_eoe'
writeLines("\n :: Predicting the maximum probability of a violation:")
predictTest <- predict(ParoleLog1, type = "response", newdata = test)
head(sort(predictTest, decreasing = TRUE), 1)
'org_babel_R_eoe'
predictTest <- predict(ParoleLog1, type = "response", newdata = test)

writeLines("\n :: Confusion matrix for threshold of 0.5:")
table(test$violator, predictTest >= 0.5)

TN <- 167; FP <- 12;
FN <- 11;  TP <- 12;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(test$violator)

writeLines("\n :: The accuracy of the simple model:")
179 / (179 + 23)
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.2:")
table(test$violator, predictTest >= 0.2)

TN <- 154; FP <- 25;
FN <- 6;  TP <- 17;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Install package only once")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Prediction function")
ROCRpred = prediction(predictTest, test$violator)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans.csv"

fileName <- "loans.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frame.")
loans <- read.csv("../data/loans.csv")
str(loans)
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Proportion of not fully paid loans:")
nrow(subset(loans, loans$not.fully.paid == 1)) / nrow(loans)
'org_babel_R_eoe'
writeLines("\n :: Variables with NA instances:")
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Number of loans:")
nrow(loans)

writeLines("\n :: Number of observations with complete information:")
nrow(loans[complete.cases(loans), ])

writeLines("\n :: Non complete cases:")
nrow(loans[!complete.cases(loans), ])

table(loans[!complete.cases(loans), ]$not.fully.paid)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans_imputed.csv"

fileName <- "loans_imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading imputed data into their data frame.")
loans <- read.csv("../data/loans_imputed.csv")

writeLines("\n :: Verifying non NA existance:")
anyNA(loans)
'org_babel_R_eoe'
writeLines("\n :: Split the loans dataset in training and testing datasets:")
set.seed(144)
library(caTools)
split <- sample.split(loans$not.fully.paid, SplitRatio = 0.7)
loansTrain <- subset(loans, split == TRUE)
loansTest <- subset(loans, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
LoansLog1 = glm(not.fully.paid ~ ., data = loansTrain, family = binomial)
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: The value of Logit(A) - Logit(B)")
LogitAMinusLogitB <- -9.317e-03 * (700 - 710)
LogitAMinusLogitB
'org_babel_R_eoe'
writeLines("\n :: The value of O(A) / O(B):")
exp(LogitAMinusLogitB)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of the testing set loans not being paid:")
predicted.risk <- predict(LoansLog1, type = "response", newdata = loansTest)
loansTest$predicted.risk <- predicted.risk

writeLines("\n :: Calculate the confusion matrix:")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
TN <- 2400; FP <- 13;
FN <- 457; TP <- 3;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(loansTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(loansTest$not.fully.paid)

writeLines("\n :: The accuracy of the simple model:")
2413 / (2413 + 460)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Prediction function:")
ROCRpred = prediction(predicted.risk, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 2")
LoansLog2 <- glm(not.fully.paid ~ int.rate, data = loansTrain, family = binomial)
summary(LoansLog2)

writeLines("\n :: Remembering the Model 1: Loanslog1:")
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: Correlation between int.rate and fico features:")
cor(loansTrain$int.rate, loansTrain$fico)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(LoansTestPrediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpredBV, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- 3
InterestRevenue <- c * exp(rt)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- 3
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- c(0, 1, 2, 3)
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: Creating the profit feature in the testing set:")
loansTest$profit <- exp(loansTest$int.rate*3) - 1
loansTest$profit[loansTest$not.fully.paid == 1] = -1
'org_babel_R_eoe'
writeLines("\n :: The maximum profit of $10 investment is:")
10 * loansTest$profit[which.max(loansTest$profit)]
'org_babel_R_eoe'
summary(highInterest)
writeLines("\n :: Building a DF of the highest interest rates (>= 15%):")
highInterest <- subset(loansTest, loansTest$int.rate >= 0.15)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
summary(loansTest$profit)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
mean(loansTest$profit)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
mean(loansTest$profit)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
mean(highInterest$profit)
'org_babel_R_eoe'
table(highInterest$not.fully.paid)
'org_babel_R_eoe'
writeLines("\n :: Proportion of the high-interest loans were not paid back in full:")
table(highInterest$not.fully.paid)
110 / (327 + 110)
'org_babel_R_eoe'
table(highInterest$not.fully.paid)
writeLines("\n :: Proportion of the high-interest loans were not paid back in full:")
110 / (327 + 110)
'org_babel_R_eoe'
cutoff <- sort(highInterest$predicted.risk, decreasing = FALSE)[100]
'org_babel_R_eoe'
cutoff <- sort(highInterest$predicted.risk, decreasing = FALSE)[100]
cutoff
'org_babel_R_eoe'
nrow(selectedLoans)
writeLines("\n :: New DF of the high-interest loans with predicted risk <= cutoff")
selectedLoans <- subset(highInterest, highInterest$predicted.risk <= cutoff)
nrow(selectedLoans)
'org_babel_R_eoe'
writeLines("\n :: The profit of the investor, whoinvested $1 in each of these 100 loans:")
sum(selectedLoans$profit)
'org_babel_R_eoe'
writeLines("\n :: The number of the 100 selected loans that were not paid back in full:")
sum(selectedLoans$not.fully.paid)

writeLines("\n :: Other way to calculate the same number:")
nrow(subset(selectedLoans, selectedLoans$not.fully.paid == 1))
'org_babel_R_eoe'
writeLines("\n :: The profit of the investor, who invested $1 in each of these 100 loans:")
sum(selectedLoans$profit)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/songs.csv"

fileName <- "songs.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
songs <- read.csv("../data/songs.csv")
str(songs)
table(songs$Year)
summary(songs)
'org_babel_R_eoe'
writeLines("\n :: Number of songs in 2010:")
nrow(subset(songs, songs$year == 2010))

writeLines("\n :: Other way to calculate:")
table(songs$year)
'org_babel_R_eoe'
writeLines("\n :: Number of songs of Michael Jackson:")
nrow(subset(songs, songs$artistname == "Michael Jackson"))
'org_babel_R_eoe'
writeLines("\n :: Songs of Michael Jackson in the Top 10:")
sort(subset(songs, songs$artistname == "Michael Jackson" & songs$Top10
            == 1)$songtitle, decreasing = TRUE)
'org_babel_R_eoe'
writeLines("\n :: The values of the timesignature variable in the dataset:")
table(songs$timesignature)
'org_babel_R_eoe'
writeLines("\n :: the song with the highest tempo is:")
songs[which.max(songs$tempo), 2]

writeLines("\n :: Other way to calculate:")
songs$songtitle[which.max(songs$tempo)]
'org_babel_R_eoe'
writeLines("\n :: Building the training and testing sets:")
SongsTrain <- subset(songs, songs$year <= 2009)
writeLines("\n :: Number of observations in the training set:")
nrow(SongsTrain)

SongsTest <- subset(songs, songs$year >= 2010)
writeLines("\n :: Number of observations on the test set:")
nrow(SongsTest)
'org_babel_R_eoe'
writeLines("\n :: To remove variables from your training and testing sets:")
nonvars <- c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain <- SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest <- SongsTest[ , !(names(SongsTest) %in% nonvars) ]

writeLines("\n :: Build the logistic regression model:")
SongsLog1 <- glm(Top10 ~ ., data=SongsTrain, family=binomial)
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The summary of the model 1:")
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The summary of the model 1:")
summary(SongsLog1)
'org_babel_R_eoe'
writeLines("\n :: The correlation between variables loudness and energy:")
cor(SongsTrain$loudness, SongsTrain$energy)
'org_babel_R_eoe'
writeLines("\n :: Model 2 omiting the loudness variable:")
SongsLog2 <- glm(Top10 ~ . -loudness, data = SongsTrain, family = binomial)
summary(SongsLog2)
'org_babel_R_eoe'
writeLines("\n :: Model 3 omiting the energy variable:")
SongsLog3 <- glm(Top10 ~ . - energy, data = SongsTrain, family = binomial)
summary(SongsLog3)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
SongsTestPrediction <- predict(SongsLog3, newdata = SongsTest, type = "response")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(SongsTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Baseline accuracy:")
table(SongsTest$Top10)
'org_babel_R_eoe'
writeLines("\n :: Baseline model accuracy:")
BaselineModelAcc <- 314 / (314 + 59)
BaselineModelAcc
'org_babel_R_eoe'
writeLines("\n :: Test set predictions for 2010:")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Prediction in Top 10 in 2010:")
PredTop10.2010 <- TP
PredTop10.2010
'org_babel_R_eoe'
writeLines("\n :: Prediction in NON hits in 2010:")
PredNonHits2010 <- FP
PredNonHits2010
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
TN <- 309; FP <- 5;
FN <- 40; TP <- 19;

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Test set predictions for 2010:")
table(SongsTest$Top10, SongsTestPrediction >= 0.45)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/parole.csv"

fileName <- "parole.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
parole <- read.csv("../data/parole.csv")
str(parole)
summary(parole)
'org_babel_R_eoe'
writeLines("\n :: Parelee violator in the data set")
nrow(subset(parole, parole$violator == 1))

writeLines("\n :: Other way to calculate the same result:")
table(parole$violator)
'org_babel_R_eoe'
str(parole)
'org_babel_R_eoe'
writeLines("\n :: Parole data set original:")
paroleOrig <- parole

writeLines("\n :: str() function over state and crime feature:")
str(paroleOrig$state)
str(paroleOrig$crime)

writeLines("\n :: table() function over state and crime feature:")
table(paroleOrig$state)
table(paroleOrig$crime)

writeLines("\n :: Converting state and crime features to factor...")
parole$state <- as.factor(parole$state)
parole$crime <- as.factor(parole$crime)
summary(parole)
'org_babel_R_eoe'
set.seed(144)
library(caTools)
split <- sample.split(parole$violator, SplitRatio = 0.7)
train <- subset(parole, split == TRUE)
test <- subset(parole, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Training set proportion:")
nrow(train) / (nrow(train) + nrow(test))

writeLines("\n :: Testing set proportion:")
nrow(test) / (nrow(train) + nrow(test))
'org_babel_R_eoe'
set.seed(144)
library(caTools)
split <- sample.split(parole$violator, SplitRatio = 0.7)
train <- subset(parole, split == TRUE)
test <- subset(parole, split == FALSE)

writeLines("\n :: Training set proportion:")
nrow(train) / (nrow(train) + nrow(test))

writeLines("\n :: Testing set proportion:")
nrow(test) / (nrow(train) + nrow(test))
'org_babel_R_eoe'
split2 <- sample.split(parole$violator, SplitRatio = 0.7)
train2 <- subset(parole, split2 == TRUE)
test2 <- subset(parole, split2 == FALSE)

writeLines("\n :: Differences between both sets of splits:")
## install.packages('compare', repos='http://cran.rstudio.com/')
library(compare)
compare(train, train2)
compare(test, test2)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
ParoleLog1 = glm(violator ~ ., data = train, family = binomial)
summary(ParoleLog1)
'org_babel_R_eoe'
beta0 <- -4.2411574; beta1 <- 1.6119919;
x1 <- c(0, 1, 2, 3, 4);

writeLines("\n :: The step in odds units:")
exp(beta1)

logit <- beta0 + (beta1 * x1)
writeLines("\n :: The value of logit is:")
logit
'org_babel_R_eoe'
writeLines("\n :: Building the new test set:")
newObservation <- c(1, 1, 50, 1, 3, 12, 0, 2, 1)
newTest <- rbind(test, newObservation)
newTest <- newTest[203, ]
newTest
'org_babel_R_eoe'
logit <- -4.2411574 + (0.3869904 * 1) + (0.8867192 * 1) + (-0.0001756
        * 50) + (-0.1238867 * 3) + (0.0802954 * 12) + (0.6837143 * 1)

writeLines("\n :: The Odds are:")
exp(logit)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of this individual is a violator:")
predictNewTest <- predict(ParoleLog1, type = "response", newdata = newTest)
predictNewTest
'org_babel_R_eoe'
writeLines("\n :: Predicting the maximum probability of a violation:")
predictTest <- predict(ParoleLog1, type = "response", newdata = test)
head(sort(predictTest, decreasing = TRUE), 1)
'org_babel_R_eoe'
predictTest <- predict(ParoleLog1, type = "response", newdata = test)

writeLines("\n :: Confusion matrix for threshold of 0.5:")
table(test$violator, predictTest >= 0.5)

TN <- 167; FP <- 12;
FN <- 11;  TP <- 12;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(test$violator)

writeLines("\n :: The accuracy of the simple model:")
179 / (179 + 23)
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.2:")
table(test$violator, predictTest >= 0.2)

TN <- 154; FP <- 25;
FN <- 6;  TP <- 17;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(test)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(test)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
writeLines("\n :: Install package only once")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Prediction function")
ROCRpred = prediction(predictTest, test$violator)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans.csv"

fileName <- "loans.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frame.")
loans <- read.csv("../data/loans.csv")
str(loans)
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Proportion of not fully paid loans:")
nrow(subset(loans, loans$not.fully.paid == 1)) / nrow(loans)
'org_babel_R_eoe'
writeLines("\n :: Variables with NA instances:")
summary(loans)
'org_babel_R_eoe'
writeLines("\n :: Number of loans:")
nrow(loans)

writeLines("\n :: Number of observations with complete information:")
nrow(loans[complete.cases(loans), ])

writeLines("\n :: Non complete cases:")
nrow(loans[!complete.cases(loans), ])

table(loans[!complete.cases(loans), ]$not.fully.paid)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/loans_imputed.csv"

fileName <- "loans_imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading imputed data into their data frame.")
loans <- read.csv("../data/loans_imputed.csv")

writeLines("\n :: Verifying non NA existance:")
anyNA(loans)
'org_babel_R_eoe'
writeLines("\n :: Split the loans dataset in training and testing datasets:")
set.seed(144)
library(caTools)
split <- sample.split(loans$not.fully.paid, SplitRatio = 0.7)
loansTrain <- subset(loans, split == TRUE)
loansTest <- subset(loans, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
LoansLog1 = glm(not.fully.paid ~ ., data = loansTrain, family = binomial)
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: The value of Logit(A) - Logit(B)")
LogitAMinusLogitB <- -9.317e-03 * (700 - 710)
LogitAMinusLogitB
'org_babel_R_eoe'
writeLines("\n :: The value of O(A) / O(B):")
exp(LogitAMinusLogitB)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of the testing set loans not being paid:")
predicted.risk <- predict(LoansLog1, type = "response", newdata = loansTest)
loansTest$predicted.risk <- predicted.risk

writeLines("\n :: Calculate the confusion matrix:")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
TN <- 2400; FP <- 13;
FN <- 457; TP <- 3;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(loansTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(loansTest$not.fully.paid)

writeLines("\n :: The accuracy of the simple model:")
2413 / (2413 + 460)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Prediction function:")
ROCRpred = prediction(predicted.risk, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 2")
LoansLog2 <- glm(not.fully.paid ~ int.rate, data = loansTrain, family = binomial)
summary(LoansLog2)

writeLines("\n :: Remembering the Model 1: Loanslog1:")
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: Correlation between int.rate and fico features:")
cor(loansTrain$int.rate, loansTrain$fico)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(LoansTestPrediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpredBV, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- 3
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- c(0, 1, 2, 3)
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: Creating the profit feature in the testing set:")
loansTest$profit <- exp(loansTest$int.rate*3) - 1
loansTest$profit[loansTest$not.fully.paid == 1] = -1
'org_babel_R_eoe'
writeLines("\n :: The maximum profit of $10 investment is:")
10 * loansTest$profit[which.max(loansTest$profit)]
'org_babel_R_eoe'
writeLines("\n :: Building a DF of the highest interest rates (>= 15%):")
highInterest <- subset(loansTest, loansTest$int.rate >= 0.15)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
mean(highInterest$profit)
'org_babel_R_eoe'
table(highInterest$not.fully.paid)
writeLines("\n :: Proportion of the high-interest loans were not paid back in full:")
110 / (327 + 110)
'org_babel_R_eoe'
cutoff <- sort(highInterest$predicted.risk, decreasing = FALSE)[100]
cutoff
'org_babel_R_eoe'
writeLines("\n :: New DF of the high-interest loans with predicted risk <= cutoff")
selectedLoans <- subset(highInterest, highInterest$predicted.risk <= cutoff)
nrow(selectedLoans)
'org_babel_R_eoe'
writeLines("\n :: The profit of the investor, who invested $1 in each of these 100 loans:")
sum(selectedLoans$profit)
'org_babel_R_eoe'
writeLines("\n :: The number of the 100 selected loans that were not paid back in full:")
sum(selectedLoans$not.fully.paid)

writeLines("\n :: Other way to calculate the same number:")
nrow(subset(selectedLoans, selectedLoans$not.fully.paid == 1))
'org_babel_R_eoe'
beta0 <- -1.5; beta1 <- 3; beta2 <- -0.5;
x1 <- 1; x2 <- 5
logit <- beta0 + (beta1 * x1) + (beta2 * x2)
writeLines("\n :: The value of logit is:")
logit
'org_babel_R_eoe'
writeLines("\n :: The value of odds is:")
exp(logit)
'org_babel_R_eoe'
P <- 1 / (1 + exp(-logit))
writeLines("\n :: The probability of P(y = 1) is:")
P
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/quality.csv"

fileName <- "quality.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
quality <- read.table("../data/quality.csv", sep = ",", header = TRUE)
str(quality)
summary(quality)
'org_babel_R_eoe'
writeLines("\n :: Install and load caTools package (Only once)")
## install.packages('caTools', repos='http://cran.rstudio.com/')
library(caTools)

writeLines("\n :: Randomly split data")
set.seed(88)
split <- sample.split(quality$PoorCare, SplitRatio = 0.75)
head(split)
'org_babel_R_eoe'
writeLines("\n :: Create training and testing sets")
qualityTrain <- subset(quality, split == TRUE)
qualityTest <- subset(quality, split == FALSE)

writeLines("\n :: The number of observations in the training set")
nrow(qualityTrain)

writeLines("\n :: The number of observations in the testing set")
nrow(qualityTest)
'org_babel_R_eoe'
writeLines("\n :: First Logistic Regression Model")
QualityLog <- glm(PoorCare ~ OfficeVisits + Narcotics,
                  data=qualityTrain, family = binomial)
summary(QualityLog)
'org_babel_R_eoe'
writeLines("\n :: Make predictions on training set")
predictTrain <- predict(QualityLog, type = "response")
'org_babel_R_eoe'
writeLines("\n :: Analyze predictions")
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
'org_babel_R_eoe'
writeLines("\n :: create a logistic regression model to predict PoorCare using
the independent variables StartedOnCombination and ProviderCount:")
QualityLog2 <- glm(PoorCare ~ StartedOnCombination + ProviderCount,
                   data = qualityTrain, family = binomial)
summary(QualityLog2)
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.5:")
table(qualityTrain$PoorCare, predictTrain > 0.5)

writeLines("\n :: Sensitivity:")
10/25

writeLines("\n :: Specificity:")
70/74
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.7")
table(qualityTrain$PoorCare, predictTrain > 0.7)

writeLines("\n :: Sensitivity:")
8/25

writeLines("\n :: Specificity:")
73/74
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.2")
table(qualityTrain$PoorCare, predictTrain > 0.2)

writeLines("\n :: Sensitivity:")
16/25

writeLines("\n :: Specificity:")
54/74
'org_babel_R_eoe'
TP <- 20; TN <- 15; FP <- 10; FN <- 5;
writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
TP <- 15; TN <- 20; FP <- 5; FN <- 10;
writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
writeLines("\n :: Install package only once")
## install.packages('ROCR', repos='http://cran.rstudio.com/')
library(ROCR)

writeLines("\n :: Prediction function")
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)

writeLines("\n :: Performance function")
ROCRperf = performance(ROCRpred, "tpr", "fpr")
'org_babel_R_eoe'
predictTest <- predict(QualityLog, type = "response", newdata = qualityTest)

writeLines("\n :: Confusion matrix for threshold of 0.3:")
table(qualityTest$PoorCare, predictTest > 0.3)

TN <- 19; TP <- 6; FN <- 2; FP <- 5

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(qualityTest)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(qualityTest)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
ROCRpredTest <- prediction(predictTest, qualityTest$PoorCare)
auc <- as.numeric(performance(ROCRpredTest, "auc")@y.values)

writeLines("\n :: The AUC of the test set is:")
auc
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/framingham.csv"

fileName <- "framingham.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
framingham <- read.table("../data/framingham.csv", sep = ",", header = TRUE)
str(framingham)
summary(framingham)
'org_babel_R_eoe'
writeLines("\n :: Load the library caTools")
library(caTools)

writeLines("\n :: Randomly split the data into training and testing sets")
set.seed(1000)
split <- sample.split(framingham$TenYearCHD, SplitRatio = 0.65)

writeLines("\n :: Split up the data using subset")
train <- subset(framingham, split==TRUE)
test <- subset(framingham, split==FALSE)
'org_babel_R_eoe'
writeLines("\n :: Logistic Regression Model")
framinghamLog <- glm(TenYearCHD ~ ., data = train, family=binomial)
summary(framinghamLog)
'org_babel_R_eoe'
writeLines("\n :: Predictions on the test set")
predictTest <- predict(framinghamLog, type="response", newdata=test)

writeLines("\n :: Confusion matrix with threshold of 0.5")
table(test$TenYearCHD, predictTest > 0.5)

writeLines("\n :: Accuracy")
(1069 + 11) / (1069 + 6 + 187 + 11)

writeLines("\n :: Baseline accuracy")
(1069 + 6) / (1069 + 6 + 187 + 11)
'org_babel_R_eoe'
writeLines("\n :: Test set AUC ")
library(ROCR)
ROCRpred <- prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
TN <- 1069; FP <- 6
FN <- 187; TP <- 11

writeLines("\n :: The Sensitivity is:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: The Specificity is:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/PollingData.csv"

fileName <- "PollingData.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
polling <- read.table("../data/PollingData.csv", sep = ",", header = TRUE)
str(polling)
table(polling$Year)
summary(polling)
'org_babel_R_eoe'
writeLines("\n :: Install and load mice package (Only once)")
## install.packages('mice', repos='http://cran.rstudio.com/')
library(mice)
'org_babel_R_eoe'
writeLines("\n :: Multiple imputation")
simple <- polling[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount")]
summary(simple)
'org_babel_R_eoe'
set.seed(144)
imputed <- complete(mice(simple))
summary(imputed)
'org_babel_R_eoe'
polling$Rasmussen <- imputed$Rasmussen
polling$SurveyUSA <- imputed$SurveyUSA
summary(polling)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/PollingData_Imputed.csv"

fileName <- "PollingData_Imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading the imputed data into their data frame.")
polling <- read.table("../data/PollingData_Imputed.csv", sep = ",", header = TRUE)
str(polling)
table(polling$Year)
summary(polling)
'org_babel_R_eoe'
writeLines("\n :: Subset data into training set and test set")
Train <- subset(polling, Year == 2004 | Year == 2008)
Test <- subset(polling, Year == 2012)
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(Train$Republican)
'org_babel_R_eoe'
writeLines("\n :: The Sign function:")
sign(20)
sign(-10)
sign(0)

writeLines("\n :: Applying to the training set")
table(sign(Train$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Comparing the smart baseline with the actual result")
table(Train$Republican, sign(Train$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Multicollinearity")
## cor(Train)                              # Error because is not numeric
'org_babel_R_eoe'
writeLines("\n :: Eliminate the issue:")
str(Train)

writeLines("\n :: The correlation between variables:")
cor(Train[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount", "Republican")])
'org_babel_R_eoe'
writeLines("\n :: Logistic Regression Model 1:")
mod1 <- glm(Republican ~ PropR, data = Train, family = "binomial")
summary(mod1)
'org_babel_R_eoe'
writeLines("\n :: Training set predictions")
pred1 <- predict(mod1, type="response")
table(Train$Republican, pred1 >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Two-variable model")
mod2 <- glm(Republican ~ SurveyUSA + DiffCount, data = Train, family = "binomial")
pred2 <- predict(mod2, type = "response")
table(Train$Republican, pred2 >= 0.5)
summary(mod2)
'org_babel_R_eoe'
writeLines("\n :: Smart baseline accuracy:")
table(Test$Republican, sign(Test$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
TestPrediction <- predict(mod2, newdata = Test, type = "response")
table(Test$Republican, TestPrediction >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Analyze mistake:")
subset(Test, TestPrediction >= 0.5 & Republican == 0)
'org_babel_R_eoe'
q()
n
