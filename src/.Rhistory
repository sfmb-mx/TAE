fileName <- "loans_imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading imputed data into their data frame.")
loans <- read.csv("../data/loans_imputed.csv")

writeLines("\n :: Verifying non NA existance:")
anyNA(loans)
'org_babel_R_eoe'
writeLines("\n :: Split the loans dataset in training and testing datasets:")
set.seed(144)
library(caTools)
split <- sample.split(loans$not.fully.paid, SplitRatio = 0.7)
loansTrain <- subset(loans, split == TRUE)
loansTest <- subset(loans, split == FALSE)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 1")
LoansLog1 = glm(not.fully.paid ~ ., data = loansTrain, family = binomial)
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: The value of Logit(A) - Logit(B)")
LogitAMinusLogitB <- -9.317e-03 * (700 - 710)
LogitAMinusLogitB
'org_babel_R_eoe'
writeLines("\n :: The value of O(A) / O(B):")
exp(LogitAMinusLogitB)
'org_babel_R_eoe'
writeLines("\n :: Predicting the probability of the testing set loans not being paid:")
predicted.risk <- predict(LoansLog1, type = "response", newdata = loansTest)
loansTest$predicted.risk <- predicted.risk

writeLines("\n :: Calculate the confusion matrix:")
table(loansTest$not.fully.paid, loansTest$predicted.risk >= 0.5)
'org_babel_R_eoe'
TN <- 2400; FP <- 13;
FN <- 457; TP <- 3;

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(loansTest)
OverallAccuracy
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(loansTest$not.fully.paid)

writeLines("\n :: The accuracy of the simple model:")
2413 / (2413 + 460)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Prediction function:")
ROCRpred = prediction(predicted.risk, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the prediction function:")
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: Building the logistic regression model 2")
LoansLog2 <- glm(not.fully.paid ~ int.rate, data = loansTrain, family = binomial)
summary(LoansLog2)

writeLines("\n :: Remembering the Model 1: Loanslog1:")
summary(LoansLog1)
'org_babel_R_eoe'
writeLines("\n :: Correlation between int.rate and fico features:")
cor(loansTrain$int.rate, loansTrain$fico)
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
LoansTestPrediction <- predict(LoansLog2, newdata = loansTest, type = "response")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Number of loans not fully paid prediction:")
summary(LoansTestPrediction)
'org_babel_R_eoe'
writeLines("\n :: Install package only once:")
library(ROCR)

writeLines("\n :: Bivariate Prediction function:")
ROCRpredBV <- prediction(LoansTestPrediction, loansTest$not.fully.paid)

writeLines("\n :: The AUC for the bivariate prediction function:")
as.numeric(performance(ROCRpredBV, "auc")@y.values)
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- 3
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: The total interest revenue is:")
c <- 10; r <- 0.06; t <- c(0, 1, 2, 3)
InterestRevenue <- c * exp(r*t)
InterestRevenue
'org_babel_R_eoe'
writeLines("\n :: Creating the profit feature in the testing set:")
loansTest$profit <- exp(loansTest$int.rate*3) - 1
loansTest$profit[loansTest$not.fully.paid == 1] = -1
'org_babel_R_eoe'
writeLines("\n :: The maximum profit of $10 investment is:")
10 * loansTest$profit[which.max(loansTest$profit)]
'org_babel_R_eoe'
writeLines("\n :: Building a DF of the highest interest rates (>= 15%):")
highInterest <- subset(loansTest, loansTest$int.rate >= 0.15)
'org_babel_R_eoe'
writeLines("\n :: The average profit of a $1 investment in one of the high-interest loans:")
mean(highInterest$profit)
'org_babel_R_eoe'
table(highInterest$not.fully.paid)
writeLines("\n :: Proportion of the high-interest loans were not paid back in full:")
110 / (327 + 110)
'org_babel_R_eoe'
cutoff <- sort(highInterest$predicted.risk, decreasing = FALSE)[100]
cutoff
'org_babel_R_eoe'
writeLines("\n :: New DF of the high-interest loans with predicted risk <= cutoff")
selectedLoans <- subset(highInterest, highInterest$predicted.risk <= cutoff)
nrow(selectedLoans)
'org_babel_R_eoe'
writeLines("\n :: The profit of the investor, who invested $1 in each of these 100 loans:")
sum(selectedLoans$profit)
'org_babel_R_eoe'
writeLines("\n :: The number of the 100 selected loans that were not paid back in full:")
sum(selectedLoans$not.fully.paid)

writeLines("\n :: Other way to calculate the same number:")
nrow(subset(selectedLoans, selectedLoans$not.fully.paid == 1))
'org_babel_R_eoe'
beta0 <- -1.5; beta1 <- 3; beta2 <- -0.5;
x1 <- 1; x2 <- 5
logit <- beta0 + (beta1 * x1) + (beta2 * x2)
writeLines("\n :: The value of logit is:")
logit
'org_babel_R_eoe'
writeLines("\n :: The value of odds is:")
exp(logit)
'org_babel_R_eoe'
P <- 1 / (1 + exp(-logit))
writeLines("\n :: The probability of P(y = 1) is:")
P
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/quality.csv"

fileName <- "quality.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
quality <- read.table("../data/quality.csv", sep = ",", header = TRUE)
str(quality)
summary(quality)
'org_babel_R_eoe'
writeLines("\n :: Install and load caTools package (Only once)")
library(caTools)

writeLines("\n :: Randomly split data")
set.seed(88)
split <- sample.split(quality$PoorCare, SplitRatio = 0.75)
head(split)
'org_babel_R_eoe'
writeLines("\n :: Create training and testing sets")
qualityTrain <- subset(quality, split == TRUE)
qualityTest <- subset(quality, split == FALSE)

writeLines("\n :: The number of observations in the training set")
nrow(qualityTrain)

writeLines("\n :: The number of observations in the testing set")
nrow(qualityTest)
'org_babel_R_eoe'
writeLines("\n :: First Logistic Regression Model")
QualityLog <- glm(PoorCare ~ OfficeVisits + Narcotics,
                  data=qualityTrain, family = binomial)
summary(QualityLog)
'org_babel_R_eoe'
writeLines("\n :: Make predictions on training set")
predictTrain <- predict(QualityLog, type = "response")
'org_babel_R_eoe'
writeLines("\n :: Analyze predictions")
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
'org_babel_R_eoe'
writeLines("\n :: create a logistic regression model to predict PoorCare using
the independent variables StartedOnCombination and ProviderCount:")
QualityLog2 <- glm(PoorCare ~ StartedOnCombination + ProviderCount,
                   data = qualityTrain, family = binomial)
summary(QualityLog2)
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.5:")
table(qualityTrain$PoorCare, predictTrain > 0.5)

writeLines("\n :: Sensitivity:")
10/25

writeLines("\n :: Specificity:")
70/74
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.7")
table(qualityTrain$PoorCare, predictTrain > 0.7)

writeLines("\n :: Sensitivity:")
8/25

writeLines("\n :: Specificity:")
73/74
'org_babel_R_eoe'
writeLines("\n :: Confusion matrix for threshold of 0.2")
table(qualityTrain$PoorCare, predictTrain > 0.2)

writeLines("\n :: Sensitivity:")
16/25

writeLines("\n :: Specificity:")
54/74
'org_babel_R_eoe'
TP <- 20; TN <- 15; FP <- 10; FN <- 5;
writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
TP <- 15; TN <- 20; FP <- 5; FN <- 10;
writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
writeLines("\n :: Install package only once")
library(ROCR)

writeLines("\n :: Prediction function")
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)

writeLines("\n :: Performance function")
ROCRperf = performance(ROCRpred, "tpr", "fpr")
'org_babel_R_eoe'
predictTest <- predict(QualityLog, type = "response", newdata = qualityTest)

writeLines("\n :: Confusion matrix for threshold of 0.3:")
table(qualityTest$PoorCare, predictTest > 0.3)

TN <- 19; TP <- 6; FN <- 2; FP <- 5

writeLines("\n :: Overall accuracy:")
OverallAccuracy <- (TN + TP) / nrow(qualityTest)
OverallAccuracy

writeLines("\n :: Sensitivity:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: Specificity:")
Specificity <- TN / (TN + FP)
Specificity

writeLines("\n :: Overall error rate:")
OverallErrorRate <- (FP + FN) / nrow(qualityTest)
OverallErrorRate

writeLines("\n :: False Negative Error Rate:")
FalseNegativeErrorRate <- FN / (TP + FN)
FalseNegativeErrorRate

writeLines("\n :: False Positive Error Rate:")
FalsePositiveErrorRate <- FP / ( TN + FP)
FalsePositiveErrorRate
'org_babel_R_eoe'
ROCRpredTest <- prediction(predictTest, qualityTest$PoorCare)
auc <- as.numeric(performance(ROCRpredTest, "auc")@y.values)

writeLines("\n :: The AUC of the test set is:")
auc
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/framingham.csv"

fileName <- "framingham.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
framingham <- read.table("../data/framingham.csv", sep = ",", header = TRUE)
str(framingham)
summary(framingham)
'org_babel_R_eoe'
writeLines("\n :: Load the library caTools")
library(caTools)

writeLines("\n :: Randomly split the data into training and testing sets")
set.seed(1000)
split <- sample.split(framingham$TenYearCHD, SplitRatio = 0.65)

writeLines("\n :: Split up the data using subset")
train <- subset(framingham, split==TRUE)
test <- subset(framingham, split==FALSE)
'org_babel_R_eoe'
writeLines("\n :: Logistic Regression Model")
framinghamLog <- glm(TenYearCHD ~ ., data = train, family=binomial)
summary(framinghamLog)
'org_babel_R_eoe'
writeLines("\n :: Predictions on the test set")
predictTest <- predict(framinghamLog, type="response", newdata=test)

writeLines("\n :: Confusion matrix with threshold of 0.5")
table(test$TenYearCHD, predictTest > 0.5)

writeLines("\n :: Accuracy")
(1069 + 11) / (1069 + 6 + 187 + 11)

writeLines("\n :: Baseline accuracy")
(1069 + 6) / (1069 + 6 + 187 + 11)
'org_babel_R_eoe'
writeLines("\n :: Test set AUC ")
library(ROCR)
ROCRpred <- prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
'org_babel_R_eoe'
TN <- 1069; FP <- 6
FN <- 187; TP <- 11

writeLines("\n :: The Sensitivity is:")
Sensitivity <- TP / (TP + FN)
Sensitivity

writeLines("\n :: The Specificity is:")
Specificity <- TN / (TN + FP)
Specificity
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/PollingData.csv"

fileName <- "PollingData.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading data into their data frames.")
polling <- read.table("../data/PollingData.csv", sep = ",", header = TRUE)
str(polling)
table(polling$Year)
summary(polling)
'org_babel_R_eoe'
writeLines("\n :: Install and load mice package (Only once)")
library(mice)
'org_babel_R_eoe'
writeLines("\n :: Multiple imputation")
simple <- polling[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount")]
summary(simple)
'org_babel_R_eoe'
set.seed(144)
imputed <- complete(mice(simple))
summary(imputed)
'org_babel_R_eoe'
polling$Rasmussen <- imputed$Rasmussen
polling$SurveyUSA <- imputed$SurveyUSA
summary(polling)
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/PollingData_Imputed.csv"

fileName <- "PollingData_Imputed.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("    Loading the imputed data into their data frame.")
polling <- read.table("../data/PollingData_Imputed.csv", sep = ",", header = TRUE)
str(polling)
table(polling$Year)
summary(polling)
'org_babel_R_eoe'
writeLines("\n :: Subset data into training set and test set")
Train <- subset(polling, Year == 2004 | Year == 2008)
Test <- subset(polling, Year == 2012)
'org_babel_R_eoe'
writeLines("\n :: Naive Baseline")
table(Train$Republican)
'org_babel_R_eoe'
writeLines("\n :: The Sign function:")
sign(20)
sign(-10)
sign(0)

writeLines("\n :: Applying to the training set")
table(sign(Train$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Comparing the smart baseline with the actual result")
table(Train$Republican, sign(Train$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Multicollinearity")
'org_babel_R_eoe'
writeLines("\n :: Eliminate the issue:")
str(Train)

writeLines("\n :: The correlation between variables:")
cor(Train[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount", "Republican")])
'org_babel_R_eoe'
writeLines("\n :: Logistic Regression Model 1:")
mod1 <- glm(Republican ~ PropR, data = Train, family = "binomial")
summary(mod1)
'org_babel_R_eoe'
writeLines("\n :: Training set predictions")
pred1 <- predict(mod1, type="response")
table(Train$Republican, pred1 >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Two-variable model")
mod2 <- glm(Republican ~ SurveyUSA + DiffCount, data = Train, family = "binomial")
pred2 <- predict(mod2, type = "response")
table(Train$Republican, pred2 >= 0.5)
summary(mod2)
'org_babel_R_eoe'
writeLines("\n :: Smart baseline accuracy:")
table(Test$Republican, sign(Test$Rasmussen))
'org_babel_R_eoe'
writeLines("\n :: Test set predictions:")
TestPrediction <- predict(mod2, newdata = Test, type = "response")
table(Test$Republican, TestPrediction >= 0.5)
'org_babel_R_eoe'
writeLines("\n :: Analyze mistake:")
subset(Test, TestPrediction >= 0.5 & Republican == 0)
'org_babel_R_eoe'
q()
n
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/baseball.csv"

fileName <- "baseball.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
library(parallel)

if(!file.exists("../data")) {
        dir.create("../data")
}

fileUrl <- "https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/baseball.csv"

fileName <- "baseball.csv"

dataPath <- "../data"

filePath <- paste(dataPath, fileName, sep = "/")

if(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = "curl")
}

list.files("../data")
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
baseball <- read.table("../data/baseball.csv", sep = ",", header = TRUE)

str(baseball)
table(baseball)
summary(baseball)
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
baseball <- read.table("../data/baseball.csv", sep = ",", header = TRUE)

str(baseball)
'org_babel_R_eoe'
writeLines("\n :: Loading data into their data frames.")
baseball <- read.table("../data/baseball.csv", sep = ",", header = TRUE)

str(baseball)
'org_babel_R_eoe'
writeLines("\n :: Number of team-year pairs in the data set:")
table(baseball$Team, baseball$Year)
'org_babel_R_eoe'
writeLines("\n :: Number of team-year pairs in the data set:")
nrow(baseball)
'org_babel_R_eoe'
writeLines("\n :: Number of team-year pairs in the data set (R):")
nrow(baseball)
'org_babel_R_eoe'
writeLines("\n :: Detecting the missing Years in the dataset (R):")
table(baseball$Year)
'org_babel_R_eoe'
writeLines("\n :: Detecting the missing Years in the dataset (R):")
length(table(baseball$Year))
'org_babel_R_eoe'
nrow(baseball)
writeLines("\n :: Subsetting the original baseball DF with the playoffs DF (R):")
baseball <- subset(baseball, baseball$Playoffs == 1)

writeLines("\n :: Number of observations in the new DF (R):")
nrow(baseball)
'org_babel_R_eoe'
q()
n
