#+TITLE:               Kaggle Competition. 15.071x - The Analytics Edge (Summer 2015).
#+AUTHOR:              Sergio-Feliciano Mendoza-Barrera
#+DRAWERS:             sfmb
#+EMAIL:               smendoza.barrera@gmail.com
#+DATE:                02/07/2015
#+DESCRIPTION:         The Analytics Edge Kaggle competition
#+KEYWORDS:            R, data science, emacs, ESS, org-mode, kaggle, competition
#+LANGUAGE:            en
#+OPTIONS:             H:10 num:t toc:nil \n:nil @:t ::t |:t ^:{} -:t f:t *:t <:t d:HIDDEN
#+OPTIONS:             TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+OPTIONS:             LaTeX:dvipng
#+INFOJS_OPT:          view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS:  export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+XSLT:
#+STYLE: <link rel="stylesheet" type="text/css" href="dft.css"/>

#+LaTeX_CLASS: IEEEtran
#+LATEX_CLASS_OPTIONS: [letterpaper, 9pt, onecolumn, twoside, technote, final]
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{makeidx}

#+LATEX_HEADER: \usepackage[lining,tabular]{fbb} % so math uses tabular lining figures
#+LATEX_HEADER: \usepackage[scaled=.95,type1]{cabin} % sans serif in style of Gill Sans
#+LATEX_HEADER: \usepackage[varqu,varl]{zi4}% inconsolata typewriter
#+LATEX_HEADER: \usepackage[T1]{fontenc} % LY1 also works
#+LATEX_HEADER: \usepackage[libertine,bigdelims]{newtxmath}
#+LATEX_HEADER: \usepackage[cal=boondoxo,bb=boondox,frak=boondox]{mathalfa}
#+LATEX_HEADER: \useosf % change normal text to use proportional oldstyle figures

#+LATEX_HEADER: \markboth{Kaggle competition, July 2015.}%
#+LATEX_HEADER: {Sergio-Feliciano Mendoza-Barrera}

#+LATEX_HEADER: \newcommand{\degC}{$^\circ$C{}}

#+STYLE: <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>

#+ATTR_HTML: width="500px"

# -*- mode: org; -*-
#+OPTIONS:   toc:2

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>

#+HTML_HEAD: <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
#+HTML_HEAD: <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>

#+BEGIN_ABSTRACT
This is the document for the Kaggle competition for the Analytics Edge
course from MIT.
#+END_ABSTRACT

* Introduction

** Welcome to the Kaggle Competition!

For the next three weeks, you will be participating in a competition
on Kaggle. You should have already set up a Kaggle account (this was
the last component of Unit 6). When the competition is over, you will
be able to check your grade on the competition by going to your
Progress page.

We have created two R script files to help you get started on this
competition. The first script (on the next page), is intended to help
you get started by building a simple logistic regression model and
preparing the results for submission on Kaggle. The second script (on
the following page), is designed to help you deal with the text data
provided in this competition. We highly recommend that you carefully
go through both of these script files, and refer to them during the
competition.

If you get stuck or have questions, please use the Discussion forum on
the edX site for this class. Remember though that the standard
discussion forum rules apply. You should not ask for answers or give
any answers on the forum.

Once you are ready, go ahead and get started by heading to the
[[https://kaggle.com/join/15071xtheanalyticsedgesummer2015][competition page]] on Kaggle. Note that this competition is a private
competition only for students in 15.071x. Please do not distribute
this link to people who are not enrolled in this class.

Good luck!

** Getting started on Kaggle

If you have never participated in a Kaggle competition before, or if
you just want some help getting started, we have created [[https://courses.edx.org/asset-v1:MITx%2B15.071x_2a%2B2T2015%2Btype@asset%2Bblock/KCompetition_GettingStarted.R][this R script]]
file to help you get started. It shows you how to prepare a submission
file for a simple logistic regression model, and how to get the most
out of the date/time variable in the dataset.

Before going through the script file, please explore the Kaggle
competition by following the link on the previous page. There are
several very important pages in the competition:

- The "*Data*" page of the competition describes the data and gives
 you links to download the data.

- The "*Evaluation*" page is where you will learn how the competition
 is graded and how to make submissions.

- The "*Rules*" page outlines some very important rules for the
 competition. Please keep in mind that all of your submissions should
 reflect the results of your own analytical models, built using the
 data provided on the Kaggle site. While you can use the discussion
 forum to ask questions and get help, the standard rules
 apply. Please do not ask for or give solutions to the
 competition. We will be checking submissions for signs of copying,
 either from your classmates or from outside sources.

- When you are ready to make a submission, the "*Make a Submission*"
 page is where you can submit your solution. Note that you can make
 up to 5 submissions each day, so don't hesitate to get creative and
 try out many different models!

If you have questions about the logistics of the competition, or need
help understanding the provided script file, please go to the
Discussion forum by using the link below.

Remember that this script file is just designed to help you get
started. You will need to build better models to do well in the
competition!

** Dealing with the text data

The data for this competition has a few variables composed of
unstructured text data. You should be comfortable using the *bag of
words* approach on text data from Unit 5, and we want to encourage you
to use this data to improve your predictive models. However, you need
to deal with the text data for this competition in a slightly
different way from how we have dealt with text data in the past,
because it is already split into a training set and a test set.

This [[https://courses.edx.org/asset-v1:MITx%2B15.071x_2a%2B2T2015%2Btype@asset%2Bblock/KCompetition_TextData.R][R script file]] is designed to help you get started working with
some the text data provided in the eBay dataset. If you have any
questions about the approach used in the script file, please go to the
Dicussion forum to get help by following the link below.

Remember that this script file is just designed to help you get
started. You will need to build better models to do well in the
competition!

** Example R script

*** KAGGLE COMPETITION - GETTING STARTED

This script file is intended to help you get started on the Kaggle
platform, and to show you how to make a submission to the
competition.

*** Let's start by reading the data into R

Make sure you have downloaded these files from the Kaggle website,
and have navigated to the directory where you saved the files on
your computer

We are adding in the argument ~stringsAsFactors = FALSE~, since we have
some text fields

#+begin_src R :session :results output :exports all
  eBayDS1 <- read.csv("../data/eBayiPadTrain.csv", stringsAsFactors = FALSE)
  eBayValidation1 <- read.csv("../data/eBayiPadTest.csv", stringsAsFactors = FALSE)
#+end_src

#+RESULTS:

We will just create a simple logistic regression model, to predict
Sold using Price:

#+begin_src R :session :results output :exports all
  SimpleMod <- glm(sold ~ startprice, data = eBayDS1, family = binomial)
#+end_src

#+RESULTS:

And then make predictions on the test set:

#+begin_src R :session :results output :exports all
  PredTest <- predict(SimpleMod, newdata = eBayValidation1, type = "response")
#+end_src

#+RESULTS:

We can't compute the ~accuracy~ or ~AUC~ on the test set ourselves,
since we don't have the dependent variable on the test set (you can
compute it on the training set though!).

However, you can submit the file on Kaggle to see how well the
model performs. You can make up to 5 submissions per day, so don't
hesitate to just upload a solution to see how you did.

Let's prepare a submission file for Kaggle (for more about this,
see the "Evaluation" page on the competition site):

#+begin_src R :session :results output :exports all
    MySubmission <- data.frame(UniqueID = eBayValidation1$UniqueID, Probability1
                               = PredTest)

    write.csv(MySubmission, "../data/SubmissionSimpleLogV1.csv", row.names
              = FALSE)

  rm(list = ls())                         # Remove all workspace data
#+end_src

#+RESULTS:

You should upload the submission ~SubmissionSimpleLog.csv~ on the
Kaggle website to use this as a submission to the competition

This model was just designed to help you get started - to do well
in the competition, you will need to build better models!

* Test your analytics skills by predicting which iPads listed on eBay will be sold

*IMPORTANT NOTE*: This competition is only open to students of the
MITx free, online course 15.071x - The Analytics Edge.

*What makes an eBay listing successful?*

Sellers on online auction websites need to understand the
characteristics of a successful item listing to maximize their
revenue. Buyers might also be interested in understanding which
listings are less attractive so as to score a good deal. In this
competition, we challenge you to develop an analytics model that will
help buyers and sellers predict the sales success of a set of eBay
listings for Apple iPads from spring 2015.

The following screenshot shows an example of iPad listings on eBay:

[[../graphs/ScreenshotEbay.png]]

To download the data and learn how this competition works, please be
sure to read the "Data" page, as well as the "Evaluation" page, which
can both be found in the panel on the left.

** Acknowledgments

This competition is brought to you by MITx and edX.

* Feature Engineering

** Clear workspace for initialization purposes

As first step we will reset all the workspace

#+begin_src R :session :results output :exports all
  writeLines("\n :: clearing workspace...")
  rm(list = ls(all = TRUE))
#+end_src

#+RESULTS:
:
:  :: clearing workspace...

** Download the data sets

In this part we can download the data

#+BEGIN_SRC R :session :results output :exports all
  if(!file.exists("../data")) {
          dir.create("../data")
  }

  fileUrl <-
  c("https://inclass.kaggle.com/c/15-071x-the-analytics-edge-summer-2015/download/eBayiPadTest.csv",
  "https://inclass.kaggle.com/c/15-071x-the-analytics-edge-summer-2015/download/eBayiPadTrain.csv",
  "https://inclass.kaggle.com/c/15-071x-the-analytics-edge-summer-2015/download/SampleSubmission.csv")

  fileName <- c("eBayiPadTest.csv", "eBayiPadTrain.csv", "SampleSubmission.csv")

  dataPath <- "../data"

  for(i in 1:3) {
          filePath <- paste(dataPath, fileName[i], sep = "/")

          if(!file.exists(filePath)) {
                  download.file(fileUrl[i], destfile = filePath, method = "curl")
          }
  }
  writeLines("\n :: Files downloaded...")
#+END_SRC

#+RESULTS:
:
:  :: Files downloaded...

** Load the data sets

We need to investigate the best way to load the data, in this case a
series of factor features can improve the performance of the algorithms

#+begin_src R :session :results output :exports all
  Sys.setlocale('LC_ALL','C')
  eBayDS <- read.csv("../data/eBayiPadTrain.csv", stringsAsFactors = FALSE)
  eBayValidation <- read.csv("../data/eBayiPadTest.csv", stringsAsFactors = FALSE)
#+end_src

#+RESULTS:
: [1] "C/C/C/C/C/en_US.UTF-8"

** File descriptions

The data provided for this competition is split into two files:

- *eBayiPadTrain.csv* = the training data set. It consists of 1861 listings.

- *eBayiPadTest.csv* = the testing data set. It consists of 798 listings.

- We have also provided a sample submission file,
  *SampleSubmission.csv*. This file gives an example of the format of
  submission files (see the Evaluation page for more information). The
  data for this competition comes from eBay.com.

** Data fields or data features available

The dependent variable in this problem is the variable sold, which
labels if an iPad listed on the eBay site was sold (equal to 1 if it
did, and 0 if it did not). The dependent variable is provided in the
training data set, but not the testing dataset. This is an important
difference from what you are used to - you will not be able to see how
well your model does on the test set until you make a submission on
Kaggle.

The independent variables consist of 9 pieces of product data
available at the time the iPad listing is posted, and a unique
identifier:

- *description* = The text description of the product provided by the
  seller.

- *biddable* = Whether this is an auction (biddable=1) or a sale with
  a fixed price (biddable=0).

- *startprice* = The start price (in US Dollars) for the auction (if
  biddable=1) or the sale price (if biddable=0).

- *condition* = The condition of the product (new, used, etc.)

- *cellular* = Whether the iPad has cellular connectivity (cellular=1)
  or not (cellular=0).

- *carrier* = The cellular carrier for which the iPad is equipped (if
  cellular=1); listed as "None" if cellular=0.

- *color* = The color of the iPad.

- *storage* = The iPad's storage capacity (in gigabytes).

- *productline* = The name of the product being sold.

** Load the necessary libraries

#+begin_src R :session :results output :exports all
  writeLines("\n :: Loading the necessary libraries...")
  library(caret)                          # ML interface to many
                                          # functions
  library(ggplot2)                        # Graphical libraries
  library(caTools)                        # Partition data sets
  library(parallel)                       # Parallel computation
  library(mice)                           # Imputation library
  library(ROCR)                           # ROCS for AUC calculation
  library(randomForest)                   # Random Forest library
  library(pROC)                           # ROC calculations
  library(gbm)                            # gbm algorithm
  library(parallel)                       # Multicore calculations
  library(corrplot)                       # Correlation matrix plot
  library(plyr)
  library(tm)                             # Tecx minning library
  library(rpart)                          # CART libraries
  library(rpart.plot)
#+end_src

#+RESULTS:
:
:  :: Loading the necessary libraries...

** Inspecting the data set

Lets begin researching in the training data set.

#+BEGIN_SRC R :session :results output :exports all
  writeLines("    The structure of the training data set:")
  str(eBayDS)
#+END_SRC

#+RESULTS:
#+begin_example
    The structure of the training data set:
'data.frame':	1861 obs. of  11 variables:
 $ description: chr  "iPad is in 8.5+ out of 10 cosmetic condition!" "Previously used, please read description. May show signs of use such as scratches to the screen and " "" "" ...
 $ biddable   : int  0 1 0 0 0 1 1 0 1 1 ...
 $ startprice : num  159.99 0.99 199.99 235 199.99 ...
 $ condition  : chr  "Used" "Used" "Used" "New other (see details)" ...
 $ cellular   : chr  "0" "1" "0" "0" ...
 $ carrier    : chr  "None" "Verizon" "None" "None" ...
 $ color      : chr  "Black" "Unknown" "White" "Unknown" ...
 $ storage    : chr  "16" "16" "16" "16" ...
 $ productline: chr  "iPad 2" "iPad 2" "iPad 4" "iPad mini 2" ...
 $ sold       : int  0 1 1 0 0 1 1 0 1 1 ...
 $ UniqueID   : int  10001 10002 10003 10004 10005 10006 10007 10008 10009 10010 ...
#+end_example

** Preprocessing the data

In this part we can try with different types for the data in order to
have a better understanding of the data and to have the probability to
improve the models. We can assume that some default values must be
changed to the right type.

*** Training data set

#+begin_src R :session :results output :exports all
  eBayDS$condition <- as.factor(eBayDS$condition)
  eBayDS$cellular <- as.integer(eBayDS$cellular)
  eBayDS$carrier <- as.factor(eBayDS$carrier)
  eBayDS$color <- as.factor(eBayDS$color)
  eBayDS$storage <- as.factor(eBayDS$storage)
  eBayDS$productline <- as.factor(eBayDS$productline)
  ## eBayDS$sold <- as.factor(eBayDS$sold)

  writeLines("\n :: New structure of the original training set:")
  str(eBayDS)
#+end_src

#+RESULTS:
#+begin_example
Warning message:
NAs introduced by coercion

 :: New structure of the original training set:
'data.frame':	1861 obs. of  11 variables:
 $ description: chr  "iPad is in 8.5+ out of 10 cosmetic condition!" "Previously used, please read description. May show signs of use such as scratches to the screen and " "" "" ...
 $ biddable   : int  0 1 0 0 0 1 1 0 1 1 ...
 $ startprice : num  159.99 0.99 199.99 235 199.99 ...
 $ condition  : Factor w/ 6 levels "For parts or not working",..: 6 6 6 4 5 6 3 3 6 6 ...
 $ cellular   : int  0 1 0 0 NA 1 0 0 1 0 ...
 $ carrier    : Factor w/ 7 levels "AT&T","None",..: 2 7 2 2 6 1 2 2 6 2 ...
 $ color      : Factor w/ 5 levels "Black","Gold",..: 1 4 5 4 4 3 3 5 5 5 ...
 $ storage    : Factor w/ 5 levels "128","16","32",..: 2 2 2 2 5 3 2 2 4 3 ...
 $ productline: Factor w/ 12 levels "Unknown","iPad 1",..: 3 3 5 10 1 10 9 11 2 5 ...
 $ sold       : int  0 1 1 0 0 1 1 0 1 1 ...
 $ UniqueID   : int  10001 10002 10003 10004 10005 10006 10007 10008 10009 10010 ...
#+end_example

*** Validation data set

#+begin_src R :session :results output :exports all
  eBayValidation$condition <- as.factor(eBayValidation$condition)
  eBayValidation$cellular <- as.integer(eBayValidation$cellular)
  eBayValidation$carrier <- as.factor(eBayValidation$carrier)
  eBayValidation$color <- as.factor(eBayValidation$color)
  eBayValidation$storage <- as.factor(eBayValidation$storage)
  eBayValidation$productline <- as.factor(eBayValidation$productline)
  ## eBayValidation$sold <- as.factor(eBayValidation$sold)

  writeLines("\n :: New structure of the original training set:")
  str(eBayValidation)
#+end_src

#+RESULTS:
#+begin_example
Warning message:
NAs introduced by coercion

 :: New structure of the original training set:
'data.frame':	798 obs. of  10 variables:
 $ description: chr  "like new" "Item is in great shape. I upgraded to the iPad Air 2 and don&#039;t need the mini any longer, even though " "This iPad is working and is tested 100%. It runs great. It is in good condition. Cracked digitizer." "" ...
 $ biddable   : int  0 0 0 1 0 0 0 0 0 1 ...
 $ startprice : num  105 195 220 100 211 ...
 $ condition  : Factor w/ 6 levels "For parts or not working",..: 6 6 6 6 2 4 5 6 6 6 ...
 $ cellular   : int  1 0 0 0 0 0 0 0 0 0 ...
 $ carrier    : Factor w/ 7 levels "AT&T","None",..: 1 2 2 2 2 2 2 2 2 2 ...
 $ color      : Factor w/ 5 levels "Black","Gold",..: 4 4 4 4 1 2 1 4 1 4 ...
 $ storage    : Factor w/ 5 levels "128","16","32",..: 3 2 4 2 3 4 3 2 2 3 ...
 $ productline: Factor w/ 10 levels "Unknown","iPad 1",..: 2 9 4 8 4 7 2 5 4 2 ...
 $ UniqueID   : int  11862 11863 11864 11865 11866 11867 11868 11869 11870 11871 ...
#+end_example

*** Imputing the NA values in the training dataset

Lets research about the NA values and their impact in the ML road map

#+begin_src R :session :results output :exports all
  writeLines("\n :: Summary of the original training data set:")
  summary(eBayDS)
#+end_src

#+RESULTS:
#+begin_example

 :: Summary of the original training data set:
 description           biddable        startprice
 Length:1861        Min.   :0.0000   Min.   :  0.01
 Class :character   1st Qu.:0.0000   1st Qu.: 80.00
 Mode  :character   Median :0.0000   Median :179.99
                    Mean   :0.4498   Mean   :211.18
                    3rd Qu.:1.0000   3rd Qu.:300.00
                    Max.   :1.0000   Max.   :999.00

                    condition       cellular          carrier
 For parts or not working: 181   Min.   :0.0000   AT&T    : 206
 Manufacturer refurbished:  39   1st Qu.:0.0000   None    :1111
 New                     : 289   Median :0.0000   Other   :   3
 New other (see details) :  85   Mean   :0.3196   Sprint  :  30
 Seller refurbished      : 109   3rd Qu.:1.0000   T-Mobile:  19
 Used                    :1158   Max.   :1.0000   Unknown : 348
                                 NA's   :234      Verizon : 144
        color        storage        productline       sold
 Black     :425   128    : 90   iPad 2    :286   Min.   :0.0000
 Gold      : 77   16     :934   iPad mini :277   1st Qu.:0.0000
 Space Gray:202   32     :340   iPad 1    :227   Median :0.0000
 Unknown   :708   64     :314   Unknown   :204   Mean   :0.4621
 White     :449   Unknown:183   iPad Air  :180   3rd Qu.:1.0000
                                iPad Air 2:171   Max.   :1.0000
                                (Other)   :516
    UniqueID
 Min.   :10001
 1st Qu.:10466
 Median :10931
 Mean   :10931
 3rd Qu.:11396
 Max.   :11861
#+end_example

The exist NA values have some serious problems in the CSV generation.

We can work with some imputation algorithms in order to substitute the
NA values.

#+begin_src R :session :results output :exports all
  writeLines("\n :: Multiple imputation")
  eBaySimple <- eBayDS[c("UniqueID", "biddable", "startprice",
                         "condition", "cellular", "storage",
                         "productline")]
  summary(eBaySimple)
#+end_src

#+RESULTS:
#+begin_example

 :: Multiple imputation
    UniqueID        biddable        startprice
 Min.   :10001   Min.   :0.0000   Min.   :  0.01
 1st Qu.:10466   1st Qu.:0.0000   1st Qu.: 80.00
 Median :10931   Median :0.0000   Median :179.99
 Mean   :10931   Mean   :0.4498   Mean   :211.18
 3rd Qu.:11396   3rd Qu.:1.0000   3rd Qu.:300.00
 Max.   :11861   Max.   :1.0000   Max.   :999.00

                    condition       cellular         storage
 For parts or not working: 181   Min.   :0.0000   128    : 90
 Manufacturer refurbished:  39   1st Qu.:0.0000   16     :934
 New                     : 289   Median :0.0000   32     :340
 New other (see details) :  85   Mean   :0.3196   64     :314
 Seller refurbished      : 109   3rd Qu.:1.0000   Unknown:183
 Used                    :1158   Max.   :1.0000
                                 NA's   :234
     productline
 iPad 2    :286
 iPad mini :277
 iPad 1    :227
 Unknown   :204
 iPad Air  :180
 iPad Air 2:171
 (Other)   :516
#+end_example

Lets impute the data in order to have a better response.

#+begin_src R :session :results output :exports all
  set.seed(pi)
  imputed <- complete(mice(eBaySimple))
  summary(imputed)
#+end_src

#+RESULTS:
#+begin_example

 iter imp variable
  1   1  cellular
  1   2  cellular
  1   3  cellular
  1   4  cellular
  1   5  cellular
  2   1  cellular
  2   2  cellular
  2   3  cellular
  2   4  cellular
  2   5  cellular
  3   1  cellular
  3   2  cellular
  3   3  cellular
  3   4  cellular
  3   5  cellular
  4   1  cellular
  4   2  cellular
  4   3  cellular
  4   4  cellular
  4   5  cellular
  5   1  cellular
  5   2  cellular
  5   3  cellular
  5   4  cellular
  5   5  cellular
    UniqueID        biddable        startprice
 Min.   :10001   Min.   :0.0000   Min.   :  0.01
 1st Qu.:10466   1st Qu.:0.0000   1st Qu.: 80.00
 Median :10931   Median :0.0000   Median :179.99
 Mean   :10931   Mean   :0.4498   Mean   :211.18
 3rd Qu.:11396   3rd Qu.:1.0000   3rd Qu.:300.00
 Max.   :11861   Max.   :1.0000   Max.   :999.00

                    condition       cellular         storage
 For parts or not working: 181   Min.   :0.0000   128    : 90
 Manufacturer refurbished:  39   1st Qu.:0.0000   16     :934
 New                     : 289   Median :0.0000   32     :340
 New other (see details) :  85   Mean   :0.3041   64     :314
 Seller refurbished      : 109   3rd Qu.:1.0000   Unknown:183
 Used                    :1158   Max.   :1.0000

     productline
 iPad 2    :286
 iPad mini :277
 iPad 1    :227
 Unknown   :204
 iPad Air  :180
 iPad Air 2:171
 (Other)   :516
#+end_example

Lets substitute the imputed values in the original dataframe

#+begin_src R :session :results output :exports all
  writeLines("\n :: Substitute the original values of storage with the imputed values:")
  eBayDS$storage <- imputed$storage
  eBayDS$cellular <- imputed$cellular
  summary(eBayDS)
#+end_src

#+RESULTS:
#+begin_example

 :: Substitute the original values of storage with the imputed values:
 description           biddable        startprice
 Length:1861        Min.   :0.0000   Min.   :  0.01
 Class :character   1st Qu.:0.0000   1st Qu.: 80.00
 Mode  :character   Median :0.0000   Median :179.99
                    Mean   :0.4498   Mean   :211.18
                    3rd Qu.:1.0000   3rd Qu.:300.00
                    Max.   :1.0000   Max.   :999.00

                    condition       cellular          carrier
 For parts or not working: 181   Min.   :0.0000   AT&T    : 206
 Manufacturer refurbished:  39   1st Qu.:0.0000   None    :1111
 New                     : 289   Median :0.0000   Other   :   3
 New other (see details) :  85   Mean   :0.3041   Sprint  :  30
 Seller refurbished      : 109   3rd Qu.:1.0000   T-Mobile:  19
 Used                    :1158   Max.   :1.0000   Unknown : 348
                                                  Verizon : 144
        color        storage        productline       sold
 Black     :425   128    : 90   iPad 2    :286   Min.   :0.0000
 Gold      : 77   16     :934   iPad mini :277   1st Qu.:0.0000
 Space Gray:202   32     :340   iPad 1    :227   Median :0.0000
 Unknown   :708   64     :314   Unknown   :204   Mean   :0.4621
 White     :449   Unknown:183   iPad Air  :180   3rd Qu.:1.0000
                                iPad Air 2:171   Max.   :1.0000
                                (Other)   :516
    UniqueID
 Min.   :10001
 1st Qu.:10466
 Median :10931
 Mean   :10931
 3rd Qu.:11396
 Max.   :11861
#+end_example

*** Imputing the NA values in the validation dataset

Lets create a dataframe with the factor/character features

#+begin_src R :session :results output :exports all
  writeLines("\n :: Multiple imputation")
  eBaySimple <- eBayValidation[c("UniqueID", "biddable", "startprice",
                         "condition", "cellular", "storage",
                         "productline")]
  summary(eBaySimple)
#+end_src

#+RESULTS:
#+begin_example

 :: Multiple imputation
    UniqueID        biddable        startprice
 Min.   :11862   Min.   :0.0000   Min.   :   0.01
 1st Qu.:12061   1st Qu.:0.0000   1st Qu.:  89.24
 Median :12260   Median :0.0000   Median : 179.00
 Mean   :12260   Mean   :0.4712   Mean   : 208.64
 3rd Qu.:12460   3rd Qu.:1.0000   3rd Qu.: 289.00
 Max.   :12659   Max.   :1.0000   Max.   : 999.99

                    condition      cellular         storage       productline
 For parts or not working: 83   Min.   :0.0000   128    : 38   iPad 2   :154
 Manufacturer refurbished: 16   1st Qu.:0.0000   16     :394   iPad mini:111
 New                     :113   Median :0.0000   32     :138   Unknown  : 92
 New other (see details) : 43   Mean   :0.2938   64     :147   iPad 1   : 88
 Seller refurbished      : 52   3rd Qu.:1.0000   Unknown: 81   iPad Air : 74
 Used                    :491   Max.   :1.0000                 iPad 4   : 68
                                NA's   :107                    (Other)  :211
#+end_example

Lets impute the data in order to have a better response.

#+begin_src R :session :results output :exports all
  set.seed(pi)
  imputed <- complete(mice(eBaySimple))
  summary(imputed)
#+end_src

#+RESULTS:
#+begin_example

 iter imp variable
  1   1  cellular
  1   2  cellular
  1   3  cellular
  1   4  cellular
  1   5  cellular
  2   1  cellular
  2   2  cellular
  2   3  cellular
  2   4  cellular
  2   5  cellular
  3   1  cellular
  3   2  cellular
  3   3  cellular
  3   4  cellular
  3   5  cellular
  4   1  cellular
  4   2  cellular
  4   3  cellular
  4   4  cellular
  4   5  cellular
  5   1  cellular
  5   2  cellular
  5   3  cellular
  5   4  cellular
  5   5  cellular
    UniqueID        biddable        startprice
 Min.   :11862   Min.   :0.0000   Min.   :   0.01
 1st Qu.:12061   1st Qu.:0.0000   1st Qu.:  89.24
 Median :12260   Median :0.0000   Median : 179.00
 Mean   :12260   Mean   :0.4712   Mean   : 208.64
 3rd Qu.:12460   3rd Qu.:1.0000   3rd Qu.: 289.00
 Max.   :12659   Max.   :1.0000   Max.   : 999.99

                    condition      cellular        storage       productline
 For parts or not working: 83   Min.   :0.000   128    : 38   iPad 2   :154
 Manufacturer refurbished: 16   1st Qu.:0.000   16     :394   iPad mini:111
 New                     :113   Median :0.000   32     :138   Unknown  : 92
 New other (see details) : 43   Mean   :0.282   64     :147   iPad 1   : 88
 Seller refurbished      : 52   3rd Qu.:1.000   Unknown: 81   iPad Air : 74
 Used                    :491   Max.   :1.000                 iPad 4   : 68
                                                              (Other)  :211
#+end_example

#+begin_src R :session :results output :exports all
  writeLines("\n :: Substitute the original values of storage with the imputed values:")
  eBayValidation$storage <- imputed$storage
  eBayValidation$cellular <- imputed$cellular
  summary(eBayValidation)
#+end_src

#+RESULTS:
#+begin_example

 :: Substitute the original values of storage with the imputed values:
 description           biddable        startprice
 Length:798         Min.   :0.0000   Min.   :   0.01
 Class :character   1st Qu.:0.0000   1st Qu.:  89.24
 Mode  :character   Median :0.0000   Median : 179.00
                    Mean   :0.4712   Mean   : 208.64
                    3rd Qu.:1.0000   3rd Qu.: 289.00
                    Max.   :1.0000   Max.   : 999.99

                    condition      cellular         carrier           color
 For parts or not working: 83   Min.   :0.000   AT&T    : 86   Black     :173
 Manufacturer refurbished: 16   1st Qu.:0.000   None    :488   Gold      : 33
 New                     :113   Median :0.000   Other   :  3   Space Gray: 83
 New other (see details) : 43   Mean   :0.282   Sprint  :  6   Unknown   :323
 Seller refurbished      : 52   3rd Qu.:1.000   T-Mobile:  8   White     :186
 Used                    :491   Max.   :1.000   Unknown :155
                                                Verizon : 52
    storage       productline     UniqueID
 128    : 38   iPad 2   :154   Min.   :11862
 16     :394   iPad mini:111   1st Qu.:12061
 32     :138   Unknown  : 92   Median :12260
 64     :147   iPad 1   : 88   Mean   :12260
 Unknown: 81   iPad Air : 74   3rd Qu.:12460
               iPad 4   : 68   Max.   :12659
               (Other)  :211
#+end_example

** Understanding each type and distribution of the data

In this part we will research about the data and the interactions
between it.

#+begin_src R :session :results output :exports all
  writeLines("\n :: Summary of the data:")
  summary(eBayDS)
#+end_src

#+RESULTS:
#+begin_example

 :: Summary of the data:
 description           biddable        startprice
 Length:1861        Min.   :0.0000   Min.   :  0.01
 Class :character   1st Qu.:0.0000   1st Qu.: 80.00
 Mode  :character   Median :0.0000   Median :179.99
                    Mean   :0.4498   Mean   :211.18
                    3rd Qu.:1.0000   3rd Qu.:300.00
                    Max.   :1.0000   Max.   :999.00

                    condition       cellular          carrier
 For parts or not working: 181   Min.   :0.0000   AT&T    : 206
 Manufacturer refurbished:  39   1st Qu.:0.0000   None    :1111
 New                     : 289   Median :0.0000   Other   :   3
 New other (see details) :  85   Mean   :0.3041   Sprint  :  30
 Seller refurbished      : 109   3rd Qu.:1.0000   T-Mobile:  19
 Used                    :1158   Max.   :1.0000   Unknown : 348
                                                  Verizon : 144
        color        storage        productline       sold
 Black     :425   128    : 90   iPad 2    :286   Min.   :0.0000
 Gold      : 77   16     :934   iPad mini :277   1st Qu.:0.0000
 Space Gray:202   32     :340   iPad 1    :227   Median :0.0000
 Unknown   :708   64     :314   Unknown   :204   Mean   :0.4621
 White     :449   Unknown:183   iPad Air  :180   3rd Qu.:1.0000
                                iPad Air 2:171   Max.   :1.0000
                                (Other)   :516
    UniqueID
 Min.   :10001
 1st Qu.:10466
 Median :10931
 Mean   :10931
 3rd Qu.:11396
 Max.   :11861
#+end_example

*** Summaries of the probable factor variables

#+begin_src R :session :results output :exports all
  writeLines("\n :: The condition feature summary:")
  table(eBayDS$condition)

  writeLines("\n :: Any NA values:")
  anyNA(eBayDS$condition)

  writeLines("\n :: The carrier feature supplier summary:")
  table(eBayDS$carrier)

  writeLines("\n :: Any NA values:")
  anyNA(eBayDS$carrier)

  writeLines("\n :: The color of iPads:")
  table(eBayDS$color)

  writeLines("\n :: Any NA values:")
  anyNA(eBayDS$color)

  writeLines("\n :: The product line:")
  table(eBayDS$productline)

  writeLines("\n :: Any NA values:")
  anyNA(eBayDS$productline)
#+end_src

#+RESULTS:
#+begin_example

 :: The condition feature summary:

For parts or not working Manufacturer refurbished                      New
                     181                       39                      289
 New other (see details)       Seller refurbished                     Used
                      85                      109                     1158

 :: Any NA values:
[1] FALSE

 :: The carrier feature supplier summary:

    AT&T     None    Other   Sprint T-Mobile  Unknown  Verizon
     206     1111        3       30       19      348      144

 :: Any NA values:
[1] FALSE

 :: The color of iPads:

     Black       Gold Space Gray    Unknown      White
       425         77        202        708        449

 :: Any NA values:
[1] FALSE

 :: The product line:

         Unknown           iPad 1           iPad 2           iPad 3
             204              227              286              153
          iPad 4           iPad 5         iPad Air       iPad Air 2
             157                1              180              171
       iPad mini      iPad mini 2      iPad mini 3 iPad mini Retina
             277              107               90                8

 :: Any NA values:
[1] FALSE
#+end_example

*** Correlation between original variables

#+BEGIN_SRC R :var basename="eBayFeaturePlot" :session :results none silent :exports none
  filename <- paste("../graphs/", basename, ".png", sep = "")

  png(filename = filename, bg = "white", width = 640, height = 480, units = "px")

  ## ----- Plot code begin here
  featurePlot(x = eBayDS[, c("biddable", "startprice", "condition",
                                "cellular", "carrier", "color",
                                "storage", "productline")], y =
                                       eBayDS$sold, plot = "pairs")
  ## ----- Plot code ends here

  ## Close the PNG device and plots
  dev.off()
#+END_SRC

#+CAPTION:  eBay feature plot
#+NAME:     fig:eBayFeaturePlot
#+ATTR_LaTeX: placement: [H]
[[../graphs/eBayFeaturePlot.png]]

For the selected features we can try to understand the behavior vs the
~sold~ feature.

#+BEGIN_SRC R :var basename="eBaySoldVsBiddableCor" :session :results none silent :exports none
  filename <- paste("../graphs/", basename, ".png", sep = "")

  png(filename = filename, bg = "white", width = 640, height = 480, units = "px")

  ## ----- Plot code begin here
  ggplot(eBayDS, aes(x = biddable, y = sold, color = productline)) + geom_point()
  ## ----- Plot code ends here

  ## Close the PNG device and plots
  dev.off()
#+END_SRC

#+CAPTION:  Correlation between the sold and biddable features
#+NAME:     fig:eBaySoldVsBiddableCor
#+ATTR_LaTeX: placement: [H]
[[../graphs/eBaySoldVsBiddableCor.png]]

*** What type of deal (auction) is better sold?

#+begin_src R :session :results output :exports all
  writeLines("\n :: Is an auction a better deal for customers?")
  ## biddable as rows and sold as columns
  m <- table(eBayDS$biddable, eBayDS$sold)
  m

  writeLines("\n :: The proportion of auctions sold:")
  m[2, 2] / (m[1, 2] + m[2, 2])
#+end_src

#+RESULTS:
:
:  :: Is an auction a better deal for customers?
:
:       0   1
:   0 804 220
:   1 197 640
:
:  :: The proportion of auctions sold:
: [1] 0.744186

We understand that the auctions have a proportion of $74.4\%$ of
*success in sales*.

*** What is the sold products vs condition?

#+begin_src R :session :results output :exports all
  writeLines("\n :: The condiction of the product vs. the sold outcome:")
  table(eBayDS$condition, eBayDS$sold)
#+end_src

#+RESULTS:
#+begin_example

 :: The condiction of the product vs. the sold outcome:

                             0   1
  For parts or not working  75 106
  Manufacturer refurbished  25  14
  New                      204  85
  New other (see details)   51  34
  Seller refurbished        74  35
  Used                     572 586
#+end_example

The most sold product by condition is *used*. Now if we can see what is
the proportion of used products as an auction.

#+begin_src R :session :results output :exports all
  writeLines("\n :: Proportion of used vs auction:")
  table(eBayDS$condition, eBayDS$biddable)
#+end_src

#+RESULTS:
#+begin_example

 :: Proportion of used vs auction:

                             0   1
  For parts or not working  75 106
  Manufacturer refurbished  29  10
  New                      206  83
  New other (see details)   55  30
  Seller refurbished        77  32
  Used                     582 576
#+end_example

We can see that the people prefer to sell their products with an fixed
*expected price*. Besides, all the used offers as auctions was *sold*,
and *only 10 non auction offers was sold*.

*** Is the cellular feature important for the customer?

#+begin_src R :session :results output :exports all
  writeLines("\n :: Cellular feature vs. the sold outcome:")
  m <- table(eBayDS$cellular, eBayDS$sold)
  m

  writeLines("\n :: The proportion of products with cellular feature sold is:")
  m[2, 2] / (m[2, 1] + m[2, 2])
#+end_src

#+RESULTS:
:
:  :: Cellular feature vs. the sold outcome:
:
:       0   1
:   0 674 621
:   1 327 239
:
:  :: The proportion of products with cellular feature sold is:
: [1] 0.4222615

This result said us that the *cellular feature it is NOT the most
important* feature for customers.

*** Is the color important for the customer?

#+begin_src R :session :results output :exports all
  writeLines("\n :: How much is the importance of the color?")
  table(eBayDS$color, eBayDS$sold)
#+end_src

#+RESULTS:
:
:  :: How much is the importance of the color?
:
:                0   1
:   Black      205 220
:   Gold        55  22
:   Space Gray 111  91
:   Unknown    375 333
:   White      255 194

The vast majority prefer products in *black and white or don't care*.

*** Is the capacity an important feature to buy?

#+begin_src R :session :results output :exports all
  writeLines("\n :: Storage capacity vs. sold:")
  m <- table(eBayDS$storage, eBayDS$sold)
  m

  writeLines("\n :: The proportion of 16GB storage sold:")
  m[2, 2] / (m[1, 2] + m[2, 2] + m[3, 2] + m [4, 2])
#+end_src

#+RESULTS:
#+begin_example

 :: Storage capacity vs. sold:

            0   1
  128      68  22
  16      473 461
  32      183 157
  64      167 147
  Unknown 110  73

 :: The proportion of 16GB storage sold:
[1] 0.5857687
#+end_example

*The majority of people has bought their equipment with 16GB of ram*.

*** What is the most sold product?

#+begin_src R :session :results output :exports all
  writeLines("\n :: Products sold:")
  table(eBayDS$productline, eBayDS$sold)
#+end_src

#+RESULTS:
#+begin_example

 :: Products sold:

                     0   1
  Unknown          122  82
  iPad 1           102 125
  iPad 2           139 147
  iPad 3            73  80
  iPad 4            93  64
  iPad 5             0   1
  iPad Air         102  78
  iPad Air 2       100  71
  iPad mini        145 132
  iPad mini 2       58  49
  iPad mini 3       63  27
  iPad mini Retina   4   4
#+end_example

The best sold product is the *iPad 2*.

** Bags of word for the description feature

*** BoW in the training and testing sets

Lets begin to create a bag of words for the ~description~ feature

#+begin_src R :session :results output :exports all
  writeLines("\n :: Isolating the interest features:")
  eBayBW <- eBayDS[, c(1, 10)]
  str(eBayBW)
#+end_src

#+RESULTS:
:
:  :: Isolating the interest features:
: 'data.frame':	1861 obs. of  2 variables:
:  $ description: chr  "iPad is in 8.5+ out of 10 cosmetic condition!" "Previously used, please read description. May show signs of use such as scratches to the screen and " "" "" ...
:  $ sold       : int  0 1 1 0 0 1 1 0 1 1 ...

Now we can know what proportion of articles was not sold

#+begin_src R :session :results output :exports all
  writeLines("\n :: NOT SOLD articles proportion")
  eBayBW$Negative <- as.factor(eBayBW$sold == 0)
  m <- table(eBayBW$Negative)
  m
  m[2] / (m[1] + m[2])
#+end_src

#+RESULTS:
:
:  :: NOT SOLD articles proportion
:
: FALSE  TRUE
:   860  1001
:      TRUE
: 0.5378829

We now can create a corpus in order to analyze the description feature
in detail

#+begin_src R :session
  writeLines("\n :: Create a corpus for analysis:")
  corpus <- Corpus(VectorSource(eBayBW$description))
  corpus
  corpus[[1]]

  writeLines("\n :: Cleanning the text data:")
  corpus <- tm_map(corpus, tolower)
  corpus[[1]]

  corpus <- tm_map(corpus, PlainTextDocument)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeWords, c("ipad", stopwords("english")))
  corpus[[1]]

  corpus <- tm_map(corpus, stemDocument)
  corpus[[1]]

  frequencies <- DocumentTermMatrix(corpus)
  frequencies

  inspect(frequencies[1:20, ])

  findFreqTerms(frequencies, lowfreq = 20)
  sparse <- removeSparseTerms(frequencies, 0.995)
  sparse

  eBaySparse <- as.data.frame(as.matrix(sparse))
  colnames(eBaySparse) <- make.names(colnames(eBaySparse))

  writeLines("\n :: Number of words in the Bag of Words:")
  length(colnames(eBaySparse))
#+end_src

#+RESULTS:
: 128

Now we can use the bag of word of the ~eBaySparse~ data frame and join
it with the other dummy parts of the data set.

*** BoW for the validation dataset

Lets begin to create a bag of words for the validation dataset

#+begin_src R :session :results output :exports all
  writeLines("\n :: Isolating the interest features:")
  eBayValidationBW <- eBayValidation[, c(10, 1)]
  str(eBayValidationBW)
#+end_src

#+RESULTS:
#+begin_example
     0       0    0    0    0     0    0    0    0     0     0
  character(0)       0       0    0    0    0     0    0    0    0     0     0
  character(0)       0       0    1    0    0     0    0    0    0     0     0
  character(0)       0       0    0    0    0     0    0    0    0     0     0
  character(0)       0       0    0    0    0     0    0    0    0     0     0
  character(0)       0       0    0    0    0     0    0    0    0     0     0
 [1] "100"       "accessori" "amp"       "appl"      "back"      "blemish"
 [7] "box"       "brand"     "case"      "charger"   "clean"     "come"
[13] "condit"    "corner"    "cosmet"    "cover"     "crack"     "dent"
[19] "descript"  "devic"     "excel"     "fulli"     "function"  "good"
[25] "great"     "hous"      "icloud"    "includ"    "item"      "light"
[31] "like"      "list"      "lock"      "may"       "mini"      "minim"
[37] "minor"     "mint"      "near"      "new"       "normal"    "one"
[43] "open"      "origin"    "packag"    "perfect"   "pictur"    "pleas"
[49] "power"     "read"      "refurbish" "scratch"   "screen"    "scuff"
[55] "see"       "show"      "sign"      "small"     "still"     "tear"
[61] "test"      "unit"      "use"       "wear"      "wifi"      "will"
[67] "work"
<<DocumentTermMatrix (documents: 1861, terms: 128)>>
Non-/sparse entries: 4431/233777
Sparsity           : 98%
Maximal term length: 10
Weighting          : term frequency (tf)

 :: Number of words in the Bag of Words:
[1] 128

 :: Isolating the interest features:
'data.frame':	798 obs. of  2 variables:
 $ UniqueID   : int  11862 11863 11864 11865 11866 11867 11868 11869 11870 11871 ...
 $ description: chr  "like new" "Item is in great shape. I upgraded to the iPad Air 2 and don&#039;t need the mini any longer, even though " "This iPad is working and is tested 100%. It runs great. It is in good condition. Cracked digitizer." "" ...
#+end_example

We now can create a corpus in order to analyze the description feature
in detail

#+begin_src R :session
  writeLines("\n :: Create a corpus for analysis:")
  corpus <- Corpus(VectorSource(eBayValidationBW$description))
  corpus
  corpus[[1]]

  writeLines("\n :: Cleanning the text data:")
  corpus <- tm_map(corpus, tolower)
  corpus[[1]]

  corpus <- tm_map(corpus, PlainTextDocument)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeWords, c("ipad", stopwords("english")))
  corpus[[1]]

  corpus <- tm_map(corpus, stemDocument)
  corpus[[1]]

  frequencies <- DocumentTermMatrix(corpus)
  frequencies

  inspect(frequencies[1:20, ])

  findFreqTerms(frequencies, lowfreq = 20)
  sparse <- removeSparseTerms(frequencies, 0.995)
  sparse

  eBayValidationSparse <- as.data.frame(as.matrix(sparse))
  colnames(eBayValidationSparse) <- make.names(colnames(eBayValidationSparse))

  writeLines("\n :: Number of words in the Bag of Words:")
  length(colnames(eBayValidationSparse))
#+end_src

#+RESULTS:
: 136

Now we have a BoW dataframe from the ~description~ feature in the
validation dataset.

** The dummy variable creation

Lets convert the factor/character variables to dummy variables

*** Dummy variables creation for the training/testing dataset

#+begin_src R :session :results output :exports all
  writeLines("\n :: Dummy variables for factors/characters...")

  eBayDS2 <- eBayDS[, -1]
  eBayDummy <- dummyVars("~.", data = eBayDS2, fullRank = F)
  eBayDS2 <- as.data.frame(predict(eBayDummy, eBayDS))
  names(eBayDS2)

  writeLines("\n :: Re-work the feature names...")
  names(eBayDS2) <- make.names(names(eBayDS2), unique = FALSE, allow_ = TRUE)
  colnames(eBayDS2)[38] <- "eBay.sold"
  names(eBayDS2)
#+end_src

#+RESULTS:
#+begin_example

 :: Dummy variables for factors/characters...
 [1] "biddable"                           "startprice"
 [3] "condition.For parts or not working" "condition.Manufacturer refurbished"
 [5] "condition.New"                      "condition.New other (see details)"
 [7] "condition.Seller refurbished"       "condition.Used"
 [9] "cellular"                           "carrier.AT&T"
[11] "carrier.None"                       "carrier.Other"
[13] "carrier.Sprint"                     "carrier.T-Mobile"
[15] "carrier.Unknown"                    "carrier.Verizon"
[17] "color.Black"                        "color.Gold"
[19] "color.Space Gray"                   "color.Unknown"
[21] "color.White"                        "storage.2"
[23] "storage.3"                          "storage.4"
[25] "storage.5"                          "productline.Unknown"
[27] "productline.iPad 1"                 "productline.iPad 2"
[29] "productline.iPad 3"                 "productline.iPad 4"
[31] "productline.iPad 5"                 "productline.iPad Air"
[33] "productline.iPad Air 2"             "productline.iPad mini"
[35] "productline.iPad mini 2"            "productline.iPad mini 3"
[37] "productline.iPad mini Retina"       "sold"
[39] "UniqueID"

 :: Re-work the feature names...
 [1] "biddable"                           "startprice"
 [3] "condition.For.parts.or.not.working" "condition.Manufacturer.refurbished"
 [5] "condition.New"                      "condition.New.other..see.details."
 [7] "condition.Seller.refurbished"       "condition.Used"
 [9] "cellular"                           "carrier.AT.T"
[11] "carrier.None"                       "carrier.Other"
[13] "carrier.Sprint"                     "carrier.T.Mobile"
[15] "carrier.Unknown"                    "carrier.Verizon"
[17] "color.Black"                        "color.Gold"
[19] "color.Space.Gray"                   "color.Unknown"
[21] "color.White"                        "storage.2"
[23] "storage.3"                          "storage.4"
[25] "storage.5"                          "productline.Unknown"
[27] "productline.iPad.1"                 "productline.iPad.2"
[29] "productline.iPad.3"                 "productline.iPad.4"
[31] "productline.iPad.5"                 "productline.iPad.Air"
[33] "productline.iPad.Air.2"             "productline.iPad.mini"
[35] "productline.iPad.mini.2"            "productline.iPad.mini.3"
[37] "productline.iPad.mini.Retina"       "eBay.sold"
[39] "UniqueID"
#+end_example

Remember do not use the GBM algorithm because needs the exact same set
of features, *Bag of Words (BoW) generated completely different set* of
features for the training/test and validation datasets.

*** Dummy variables creation for the validation dataset

#+begin_src R :session :results output :exports all
  writeLines("\n :: Dummy variables for factors/characters...")

  eBayValidation2 <- eBayValidation[, -1]
  eBayDummy <- dummyVars("~.", data = eBayValidation2, fullRank = F)
  eBayValidation2 <- as.data.frame(predict(eBayDummy, eBayValidation))
  print(names(eBayValidation2))

  writeLines("\n :: Re-work the feature names:")
  names(eBayValidation2) <- make.names(names(eBayValidation2), unique =
                                                     FALSE, allow_ = TRUE)

  print(names(eBayValidation2))
#+end_src

#+RESULTS:
#+begin_example

 :: Dummy variables for factors/characters...
 [1] "biddable"                           "startprice"
 [3] "condition.For parts or not working" "condition.Manufacturer refurbished"
 [5] "condition.New"                      "condition.New other (see details)"
 [7] "condition.Seller refurbished"       "condition.Used"
 [9] "cellular"                           "carrier.AT&T"
[11] "carrier.None"                       "carrier.Other"
[13] "carrier.Sprint"                     "carrier.T-Mobile"
[15] "carrier.Unknown"                    "carrier.Verizon"
[17] "color.Black"                        "color.Gold"
[19] "color.Space Gray"                   "color.Unknown"
[21] "color.White"                        "storage.2"
[23] "storage.3"                          "storage.4"
[25] "storage.5"                          "productline.Unknown"
[27] "productline.iPad 1"                 "productline.iPad 2"
[29] "productline.iPad 3"                 "productline.iPad 4"
[31] "productline.iPad Air"               "productline.iPad Air 2"
[33] "productline.iPad mini"              "productline.iPad mini 2"
[35] "productline.iPad mini 3"            "UniqueID"

 :: Re-work the feature names:
 [1] "biddable"                           "startprice"
 [3] "condition.For.parts.or.not.working" "condition.Manufacturer.refurbished"
 [5] "condition.New"                      "condition.New.other..see.details."
 [7] "condition.Seller.refurbished"       "condition.Used"
 [9] "cellular"                           "carrier.AT.T"
[11] "carrier.None"                       "carrier.Other"
[13] "carrier.Sprint"                     "carrier.T.Mobile"
[15] "carrier.Unknown"                    "carrier.Verizon"
[17] "color.Black"                        "color.Gold"
[19] "color.Space.Gray"                   "color.Unknown"
[21] "color.White"                        "storage.2"
[23] "storage.3"                          "storage.4"
[25] "storage.5"                          "productline.Unknown"
[27] "productline.iPad.1"                 "productline.iPad.2"
[29] "productline.iPad.3"                 "productline.iPad.4"
[31] "productline.iPad.Air"               "productline.iPad.Air.2"
[33] "productline.iPad.mini"              "productline.iPad.mini.2"
[35] "productline.iPad.mini.3"            "UniqueID"
#+end_example

** Join the sparse datasets with their respective dummy part

*** Training/testing datasets

Lets join the training/testing dataset all together

#+begin_src R :session :results output :exports all
  writeLines("\n :: Joining all together:")
  eBayDS3 <- cbind(eBaySparse, eBayDS2)

  writeLines("\n :: Number of new features:")
  length(names(eBayDS3))
#+end_src

#+RESULTS:
:
:  :: Joining all together:
: Warning message:
: In data.row.names(row.names, rowsi, i) :
:   some row.names duplicated: 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271 [... truncated]
:
:  :: Number of new features:
: [1] 167

*** Validation dataset

Lets join the validation dataset all together

#+begin_src R :session :results output :exports all
  writeLines("\n :: Joining all together:")
  eBayValidation3 <- cbind(eBayValidationSparse, eBayValidation2)

  writeLines("\n :: Number of new features:")
  length(names(eBayValidation3))
#+end_src

#+RESULTS:
:
:  :: Joining all together:
: Warning message:
: In data.row.names(row.names, rowsi, i) :
:   some row.names duplicated: 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271 [... truncated]
:
:  :: Number of new features:
: [1] 172

** Partitioning the data

*What are the right steps for the best model generation?*

The problem of the NA existence in the submission CSV file must be
addressed.

We need more information about the behavior and performance of the
models, then a reasonable decision is subdivide the training data set
in a new training data set plus a testing set

#+begin_src R :session :results output :exports all
  writeLines("\n :: Split the data:")
  set.seed(pi)

  spl <- sample.split(eBayDS3$sold, SplitRatio = 0.75)

  eBayTrain <- subset(eBayDS3, spl == TRUE)
  eBayTest <- subset(eBayDS3, spl == FALSE)

  writeLines("\n :: Dimensions of the training set:")
  dim(eBayTrain)

  writeLines("\n :: Dimensions of the testing set:")
  dim(eBayTest)
#+end_src

#+RESULTS:
:
:  :: Split the data:
:
:  :: Dimensions of the training set:
: [1] 1396  167
:
:  :: Dimensions of the testing set:
: [1] 465 167

** Centering and scale the data

#+begin_src R :session :results output :exports all
  ## preProcValues <- preProcess(eBayTrain, method = c("center", "scale"))

  ## eBayTrain <- predict(preProcValues, eBayTrain)
  ## eBayTest <- predict(preProcValues, eBayTest)
#+end_src

#+RESULTS:

** Correlation between created covariates

#+BEGIN_SRC R :var basename="DummyCorrelationPlot" :session :results none silent :exports none
  filename <- paste("../graphs/", basename, ".png", sep = "")

  png(filename = filename, bg = "white", width = 800, height = 600, units = "px")

  ## ----- Plot code begin here
  corrplot(cor(eBayTrain))
  ## ----- Plot code ends here

  ## Close the PNG device and plots
  dev.off()
#+END_SRC

#+CAPTION:  Created dummy variables correlation plot
#+NAME:     fig:DummyCorrelationPlot
#+ATTR_LaTeX: placement: [H]
[[../graphs/DummyCorrelationPlot.png]]

* Machine Learning Models

** Model general variables generation

We can prepare the general variables for all models

#+begin_src R :session :results output :exports all
  writeLines("\n :: What is the proportion of your outcome variable?")
  prop.table(table(eBayTrain$eBay.sold))
  table(eBayTrain$eBay.sold)
#+end_src

#+RESULTS:
:
:  :: What is the proportion of your outcome variable?
:
:         0         1
: 0.5436963 0.4563037
:
:   0   1
: 759 637

Lets save some important variables in order to use it as arguments for
the modeling functions

#+begin_src R :session :results output :exports all
  writeLines("\n :: Generalize outcome and predictor variables...")
  outcomeName <- 'eBay.sold'
  predictorsNames <- names(eBayTrain)[names(eBayTrain) != outcomeName]

  writeLines("\n :: Number of predictors name:s")
  length(predictorsNames)
#+end_src

#+RESULTS:
:
:  :: Generalize outcome and predictor variables...
:
:  :: Number of predictors name:s
: [1] 166

The ~caret~ package support a multitude of models

#+begin_src R :session :results output :exports all
  writeLines("\n :: The total caret supported models:")
  length(names(getModelInfo()))
#+end_src

#+RESULTS:
:
:  :: The total caret supported models:
: [1] 192

What is the type of the ~gdm~ algorithm

#+begin_src R :session :results output :exports all
  writeLines("\n :: Pick model glm and find out what type of model it is:")
  getModelInfo()$glm$type
#+end_src

#+RESULTS:
:
:  :: Pick model glm and find out what type of model it is:
: [1] "Regression"     "Classification"

The train control object will allow us to control the number of cross
validations performed for the synthesis of the model

#+begin_src R :session :results output :exports all
  writeLines("\n :: Create caret trainControl object to control the number of
      cross-validations performed...")
  objControl <- trainControl(method = 'cv', number = 10, returnResamp =
                    'none', summaryFunction = twoClassSummary,
                    classProbs = TRUE)
#+end_src

#+RESULTS:
:
:  :: Create caret trainControl object to control the number of
:     cross-validations performed...

** ML model generation

In this part we will generate the ML models

#+begin_src R :session
  writeLines("\n :: ----------- LG7 model -----------")
  eBayLR7 <- glm(eBay.sold ~ ., data = eBayTrain, family = binomial)

  writeLines("\n :: Selecting sig. variables...")
  toselect.x <- summary(eBayLR7)$coeff[-1,4] < 0.05 # credit to kith
  relevant.x <- names(toselect.x)[toselect.x == TRUE]
  # formula with only sig variables
  sig.formula <- as.formula(paste("eBay.sold ~",paste(relevant.x, collapse= "+")))

  writeLines("\n :: ----------- LG8 model -----------")
  eBayLR8 <- glm(formula = sig.formula, data = eBayTrain, family = binomial)

  writeLines("\n :: ---------- CART1 model ----------")
  eBayCART1 <- rpart(eBay.sold ~ ., data = eBayTrain, method = "class")

  writeLines("\n :: ----------- RF1 model -----------")
  eBayRF1 <- randomForest(eBay.sold ~ ., data = eBayTrain, method = "class")
#+end_src

#+RESULTS:

** Testing ML model

#+begin_src R :session :results output :exports all
  writeLines("\n :: ------------ LR8 AUC ------------")
  predictTest <- predict(eBayLR7, newdata = eBayTest, type = "response")
  ROCRpred <- prediction(predictTest, eBayTest$eBay.sold)
  as.numeric(performance(ROCRpred, "auc")@y.values)

  writeLines("\n :: ----------- CART1 AUC -----------")
  PredTestCART1 <- predict(eBayCART1, newdata = eBayTest)[, 2]
  ROCRpredCART1 <- prediction(PredTestCART1, eBayTest$eBay.sold)
  as.numeric(performance(ROCRpredCART1, "auc")@y.values)

  writeLines("\n :: ------------ RF1 AUC ------------")
  predTestRF1 <- predict(eBayRF1, newdata = eBayTest)
  ROCRpredRF1 <- prediction(predTestRF1, eBayTest$eBay.sold)
  as.numeric(performance(ROCRpredRF1, "auc")@y.values)
#+end_src

#+RESULTS:
#+begin_example

 :: ------------ LR8 AUC ------------
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
[1] 0.8189786

 :: ----------- CART1 AUC -----------
[1] 0.8153652

 :: ------------ RF1 AUC ------------
[1] 0.8448838
#+end_example

* Prepare the CSV file for submission

** Validation dataset structure

And then make predictions on the test set. We will change the type for
the testing set:

#+begin_src R :session :results output :exports all
  writeLines("\n :: eBayValidation new structure:")
  str(eBayValidation2)
#+end_src

#+RESULTS:
#+begin_example

 :: eBayValidation new structure:
'data.frame':	798 obs. of  36 variables:
 $ biddable                          : num  0 0 0 1 0 0 0 0 0 1 ...
 $ startprice                        : num  105 195 220 100 211 ...
 $ condition.For.parts.or.not.working: num  0 0 0 0 0 0 0 0 0 0 ...
 $ condition.Manufacturer.refurbished: num  0 0 0 0 1 0 0 0 0 0 ...
 $ condition.New                     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ condition.New.other..see.details. : num  0 0 0 0 0 1 0 0 0 0 ...
 $ condition.Seller.refurbished      : num  0 0 0 0 0 0 1 0 0 0 ...
 $ condition.Used                    : num  1 1 1 1 0 0 0 1 1 1 ...
 $ cellular                          : num  1 0 0 0 0 0 0 0 0 0 ...
 $ carrier.AT.T                      : num  1 0 0 0 0 0 0 0 0 0 ...
 $ carrier.None                      : num  0 1 1 1 1 1 1 1 1 1 ...
 $ carrier.Other                     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ carrier.Sprint                    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ carrier.T.Mobile                  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ carrier.Unknown                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ carrier.Verizon                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ color.Black                       : num  0 0 0 0 1 0 1 0 1 0 ...
 $ color.Gold                        : num  0 0 0 0 0 1 0 0 0 0 ...
 $ color.Space.Gray                  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ color.Unknown                     : num  1 1 1 1 0 0 0 1 0 1 ...
 $ color.White                       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ storage.2                         : num  0 1 0 1 0 0 0 1 1 0 ...
 $ storage.3                         : num  1 0 0 0 1 0 1 0 0 1 ...
 $ storage.4                         : num  0 0 1 0 0 1 0 0 0 0 ...
 $ storage.5                         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ productline.Unknown               : num  0 0 0 0 0 0 0 0 0 0 ...
 $ productline.iPad.1                : num  1 0 0 0 0 0 1 0 0 1 ...
 $ productline.iPad.2                : num  0 0 0 0 0 0 0 0 0 0 ...
 $ productline.iPad.3                : num  0 0 1 0 1 0 0 0 1 0 ...
 $ productline.iPad.4                : num  0 0 0 0 0 0 0 1 0 0 ...
 $ productline.iPad.Air              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ productline.iPad.Air.2            : num  0 0 0 0 0 1 0 0 0 0 ...
 $ productline.iPad.mini             : num  0 0 0 1 0 0 0 0 0 0 ...
 $ productline.iPad.mini.2           : num  0 1 0 0 0 0 0 0 0 0 ...
 $ productline.iPad.mini.3           : num  0 0 0 0 0 0 0 0 0 0 ...
 $ UniqueID                          : num  11862 11863 11864 11865 11866 ...
#+end_example

** Submission files generation

Now we will apply the new model to the validation data and proceed to
generate the submission file for Kaggle

#+begin_src R :session :results output :exports all
  writeLines("\n :: Probabilites prediction:")
  predTest <- predict(object = eBayLR6, eBayValidation2, type = 'prob')
  head(predTest$yes)
  myYesPredTest <- predTest$yes

  MySubmission <- data.frame(UniqueID = eBayValidation2$UniqueID, Probability1 = myYesPredTest)
  write.csv(MySubmission, "../data/SubmissionLR6.csv", row.names = FALSE)

  writeLines("\n :: Submission LR6 file generated...")
#+end_src

#+RESULTS:
#+begin_example

 :: Probabilites prediction:
Error in predict(object = eBayLR6, eBayValidation2, type = "prob") :
  object 'eBayLR6' not found
Error in head(predTest$yes) : object 'predTest' not found
Error: object 'predTest' not found
Error in data.frame(UniqueID = eBayValidation2$UniqueID, Probability1 = myYesPredTest) :
  object 'myYesPredTest' not found
Error in is.data.frame(x) : object 'MySubmission' not found

 :: Submission LR6 file generated...
#+end_example
