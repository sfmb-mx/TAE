<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2015-08-30 Sun 06:48 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>Week 4. Classification and Regression Trees</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Sergio-Feliciano Mendoza-Barrera" />
<meta  name="description" content="The random forest and regression trees methods for more interpretable models"
 />
<meta  name="keywords" content="R, data science, emacs, ESS, org-mode, random forest, classification and regression trees" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/bigblow/css/hideshow.css"/>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/bigblow.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/bigblow/js/hideshow.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Week 4. Classification and Regression Trees</h1>
<div class="ABSTRACT">
<p>
Regression trees and Random forest are more interpretable methods used
in binary (clustering) applications.
</p>

</div>

<div id="outline-container-orgheadline48" class="outline-2">
<h2 id="orgheadline48"><span class="section-number-2">1</span> Judge, Jury, and Classifier: An Introduction to Trees</h2>
<div class="outline-text-2" id="text-1">
<p>
<i>Sources</i>
</p>

<p>
The images in this video of the Scales of Justice, the United States
Supreme Court Building, and the United States Supreme Court Justices
all come from Wikimedia Commons.
</p>

<p>
<b>Introduction</b>
</p>

<p>
This seems like a very unconventional use of analytics, but in 2002 a
group of political science and law academics decided to test if a
model can do better than a group of experts at predicting the
decisions of the Supreme Court. In this case, a very interpretable
analytics method was used, called classification and regression
trees.
</p>


<div class="figure">
<p><img src="../graphs/AmericanLegalSystem.png" alt="AmericanLegalSystem.png" />
</p>
</div>

<p>
Cases start at the district courts, where an initial decision is made
about the case. The circuit courts hear appeals from the district
courts, and can change the decision that was made. The Supreme Court
is the highest level in the American legal system and makes the final
decision on cases.
</p>


<div class="figure">
<p><img src="../graphs/SupremeCourt.png" alt="SupremeCourt.png" />
</p>
</div>

<p>
This image shows the nine Supreme Court justices from the time period
1994 through 2005. This was the longest period of time with the same
set of justices in over 180 years.
</p>

<p>
There have been many significant and groundbreaking decisions made by
the Supreme Court. These are a few notable decisions that were made.
</p>


<div class="figure">
<p><img src="../graphs/SCOTUS.png" alt="SCOTUS.png" />
</p>
</div>

<p>
In <b>1942</b>, the Supreme Court decided on the <b>Wickard v. Filburn</b>
case. This case recognized the power of the federal government to
regulate economic activity.
</p>

<p>
Filburn was a farmer, who was growing wheat for on-farm
consumption. However, the US had established limits on wheat
production, and Filburn was exceeding those limits. So even though the
extra wheat he was producing was for his own use and he had no
intention of selling it, he was forced to destroy it.
</p>

<p>
In <b>1973</b>, the Supreme Court decided on the <b>Roe v. Wade</b> case, one of the
most well-known cases to this day. They decided to legalize abortion,
and by doing this, prompted a national debate that continues today
about the legality of abortion.
</p>

<p>
In <b>2000</b>, the Supreme Court actually decided the outcome of the
presidential election. The race was so close in the state of Florida,
that a recount of the ballots was required. But the Florida Secretary
of State certified that President Bush was the winner before the
recount could be completed.
</p>

<p>
The case then went to the Supreme Court where it was ruled that all
ballots needed to be recounted. But since this could not be done
before the winner had to be declared, President Bush won the state of
Florida, and thus, the presidency.
</p>

<p>
A very recent case from <b>2012</b> dealt with the <b>Patient Protection and
Affordable Care Act</b>, commonly called ObamaCare, which requires most
Americans to have health insurance. The Supreme Court upheld this
requirement.
</p>


<div class="figure">
<p><img src="../graphs/PredictingSCOTUS.png" alt="PredictingSCOTUS.png" />
</p>
</div>

<p>
Since non-profits, voters, and anybody interested in long-term
planning can benefit from knowing the outcomes of the Supreme Court
cases before they happen, legal academics and political scientists
regularly make predictions of Supreme Court decisions from detailed
studies of the cases and individual justices.
</p>

<p>
They wanted to see if an analytical model could outperform the
expertise and intuition of a large group of experts. Martin used a
method called classification and regression trees, or CART. In this
case, the outcome is binary.
</p>


<div class="figure">
<p><img src="../graphs/PredictingSCOTUS02.png" alt="PredictingSCOTUS02.png" />
</p>
</div>
</div>

<div id="outline-container-orgheadline2" class="outline-3">
<h3 id="orgheadline2"><span class="section-number-3">1.1</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-1-1">
<p>
How much data do you think Andrew Martin should use to build his
model?
</p>
</div>

<div id="outline-container-orgheadline1" class="outline-4">
<h4 id="orgheadline1"><span class="section-number-4">1.1.1</span> Answer</h4>
<div class="outline-text-4" id="text-1-1-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Information from all cases with the same set of justices as
those he is trying to predict. Data from cases where the justices
were different might just add noise to our problem.</li>

<li class="off"><code>[&#xa0;]</code> Only information from the most recent year. Since the justices
change every year, only this information would be useful.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
Andrew Martin should use all data from the cases with the same set of
justices. The justices do not change every year, and typically you
want to use as much data as you have available.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline6" class="outline-3">
<h3 id="orgheadline6"><span class="section-number-3">1.2</span> Video 2: CART</h3>
<div class="outline-text-3" id="text-1-2">
<p>
To predict the outcomes of the Supreme Court, Martin used cases from
1994 through 2001. He chose this period of time because the Supreme
Court was composed of the same nine justices that were justices when
he made his predictions in 2002.
</p>


<div class="figure">
<p><img src="../graphs/DataSCOTUS.png" alt="DataSCOTUS.png" />
</p>
</div>

<p>
This was a very rare data set, since as I mentioned earlier, this was
the longest period of time with the same set of justices in over 180
years. This allowed Martin to use a larger data set then might have
been available if he was doing this experiment at a different time.
</p>


<div class="figure">
<p><img src="../graphs/VariablesSCOTUS.png" alt="VariablesSCOTUS.png" />
</p>
</div>

<ul class="org-ul">
<li>The <b>circuit court of origin</b> is the circuit or lower court where the
case came from. There are 13 different circuit courts in the United
States. The 1st through 11th and Washington, DC courts are defined
by region. And the federal court is defined by the subject matter of
the case.</li>

<li>The <b>issue area of the case</b> gives each case a category, like civil
rights or federal taxation.</li>

<li>The <b>type of petitioner and type of respondent</b> define two parties
in the case. Some examples are the United States, an employer, or an
employee.</li>

<li>The <b>ideological direction of the lower court decision</b> describes
whether the lower court made what was considered a liberal or a
conservative decision.</li>

<li>The last variable indicates <b>whether or not the petitioner argued
that a law or practice was unconstitutional</b>.</li>
</ul>

<p>
To collect this data, Martin and his colleagues read through all of
the cases and coded the information. Some of it, like the circuit
court, is straightforward. But other information required a judgment
call, like the ideological direction of the lower court.
</p>
</div>

<div id="outline-container-orgheadline3" class="outline-4">
<h4 id="orgheadline3"><span class="section-number-4">1.2.1</span> Logistic regression interpretation issues</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
Now that we have our data and variables, we are ready to predict the
decisions of Justice Stevens.
</p>


<div class="figure">
<p><img src="../graphs/LRStevens.png" alt="LRStevens.png" />
</p>
</div>

<p>
We can use logistic regression, and we get a model where some of the
most significant variables are:
</p>

<p>
whether or not the case is from the 2nd circuit court, with a
coefficient of 1.66; whether or not the case is from the 4th circuit
court, with a coefficient of 2.82; and whether or not the lower court
decision was liberal, with a coefficient of (negative) -1.22.
</p>

<p>
While this tells us that the case being from the 2nd or 4th circuit
courts is predictive of Justice Stevens reversing the case, and the
lower court decision being liberal is predictive of Justice Stevens
affirming the case, it's difficult to understand which factors are
more important due to things like the scales of the variables, and the
possibility of multicollinearity.
</p>

<p>
It's also difficult to quickly evaluate what the prediction would be
for a new case. So instead of logistic regression, Martin and his
colleagues used a method called <b>classification and regression trees</b>,
or <b>CART</b>.
</p>
</div>
</div>

<div id="outline-container-orgheadline4" class="outline-4">
<h4 id="orgheadline4"><span class="section-number-4">1.2.2</span> CART</h4>
<div class="outline-text-4" id="text-1-2-2">

<div class="figure">
<p><img src="../graphs/CARTDef.png" alt="CARTDef.png" />
</p>
</div>

<p>
This method builds what is called a tree by splitting on the values of
the independent variables. To predict the outcome for a new
observation or case, you can follow the splits in the tree and at the
end, you predict the most frequent outcome in the training set that
followed the same path.
</p>

<p>
Some advantages of CART are that it does not assume a linear model,
like logistic regression or linear regression, and it's a very
interpretable model.
</p>
</div>
</div>

<div id="outline-container-orgheadline5" class="outline-4">
<h4 id="orgheadline5"><span class="section-number-4">1.2.3</span> Example</h4>
<div class="outline-text-4" id="text-1-2-3">

<div class="figure">
<p><img src="../graphs/CARTexample.png" alt="CARTexample.png" />
</p>
</div>

<p>
This plot shows sample data for two independent variables, x and y,
and each data point is colored by the outcome variable, red or gray.
</p>

<p>
CART tries to split this data into subsets so that each subset is as
pure or homogeneous as possible. The first three splits that CART
would create are shown here. <b>Then the standard prediction made by a
CART model is just the majority in each subset</b>.
</p>

<p>
If a new observation fell into one of these two subsets (RED), then we
would predict red, since the majority of the observations in those
subsets are red.
</p>

<p>
However, if a new observation fell into one of these two subsets
(GRAY), we would predict gray, since the majority of the observations
in those two subsets are gray.
</p>


<div class="figure">
<p><img src="../graphs/CARTtreeExample.png" alt="CARTtreeExample.png" />
</p>
</div>

<p>
A CART model is represented by what we call a tree. The tree for the
splits we just generated is shown on the right. The first split tests
whether the variable x is less than 60.
</p>

<p>
If yes, the model says to predict red, and if no, the model moves on
to the next split. Then, the second split checks whether or not the
variable y is less than 20.
</p>

<p>
If no, the model says to predict gray, but if yes, the model moves on
to the next split. The third split checks whether or not the variable
x is less than 85.
</p>

<p>
If yes, then the model says to predict red, and if no, the model says
to predict gray. There are a couple things to keep in mind when
reading trees.
</p>

<p>
<b>Important</b>
</p>

<p>
There are a couple things to keep in mind when reading trees. In this
tree, and for the trees we'll generate in R, a yes response is always
to the left and a no response is always to the right. Also, make sure
you always start at the top of the tree. The x less than 85 split only
counts for observations for which x is greater than 60 and y is less
than 20.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline11" class="outline-3">
<h3 id="orgheadline11"><span class="section-number-3">1.3</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Suppose that you have the following CART tree:
</p>


<div class="figure">
<p><img src="../graphs/QQ2_SupremeCourt.png" alt="QQ2_SupremeCourt.png" />
</p>
</div>
</div>

<div id="outline-container-orgheadline8" class="outline-4">
<h4 id="orgheadline8"><span class="section-number-4">1.3.1</span> Question a</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
How many splits are in this tree?
</p>
</div>

<div id="outline-container-orgheadline7" class="outline-5">
<h5 id="orgheadline7"><span class="section-number-5">1.3.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-3-1-1">
<p>
<b>3 splits</b>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline10" class="outline-4">
<h4 id="orgheadline10"><span class="section-number-4">1.3.2</span> Question b</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
For which data observations should we predict "Red", according to this
tree? Select all that apply.
</p>
</div>

<div id="outline-container-orgheadline9" class="outline-5">
<h5 id="orgheadline9"><span class="section-number-5">1.3.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-3-2-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> If X is less than 60, and Y is any value.</li>

<li class="off"><code>[&#xa0;]</code> If X is greater than or equal to 60, and Y is greater than or
equal to 20.</li>

<li class="off"><code>[&#xa0;]</code> If X is greater than or equal to 85, and Y is less than 20.</li>

<li class="on"><code>[X]</code> If X is greater than or equal to 60 and less than 85, and Y is
less than 20.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<ul class="org-ul">
<li>This tree has three splits.</li>

<li>The first split says to predict "Red" if X is less than 60,
regardless of the value of Y.</li>

<li>Otherwise, we move to the second split. The second split says to
check the value of Y

<ul class="org-ul">
<li>if it is greater than or equal to 20, predict "Gray".</li>
</ul></li>

<li>Otherwise, we move to the third split. This split checks the value
of X again.

<ul class="org-ul">
<li>If X is less than 85 (and greater than or equal to 60 by
the first split) and Y is less than 20, then we predict
"Red". Otherwise, we predict "Gray".</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline12" class="outline-3">
<h3 id="orgheadline12"><span class="section-number-3">1.4</span> Video 3: Splitting and Predictions</h3>
<div class="outline-text-3" id="text-1-4">

<div class="figure">
<p><img src="../graphs/NumberSplitsCART.png" alt="NumberSplitsCART.png" />
</p>
</div>

<p>
In R, this is called the <b>minbucket</b> parameter, for the minimum number
of observations in each bucket or subset.
</p>

<p>
The smaller minbucket is, the more splits will be generated. But if
it's too small, overfitting will occur. This means that CART will fit
the training set almost perfectly. But this is bad because then the
model will probably not perform well on test set data or new data.
</p>

<p>
On the other hand, if the minbucket parameter is too large, the model
will be too simple and the accuracy will be poor.
</p>

<p>
<b>We will learn about a nice method for selecting the stopping
 parameter</b>.
</p>


<div class="figure">
<p><img src="../graphs/PredictionsCART.png" alt="PredictionsCART.png" />
</p>
</div>

<p>
In the Supreme Court case, we'll be classifying observations as either
affirm or reverse. Instead of just taking the majority outcome to be
the prediction, we can compute the percentage of data in a subset of
each type of outcome.
</p>

<p>
As an example, if we have a subset with 10 affirms and two reverses,
then 87% of the data is affirm. Then, just like in logistic
regression, we can use a threshold value to obtain our prediction.
</p>

<p>
For this example, we would predict affirm with a threshold of 0.5
since the majority is affirm. But if we increase that threshold to
0.9, we would predict reverse for this example.
</p>

<p>
Then by varying the threshold value, we can compute an ROC curve and
compute an AUC value to evaluate our model.
</p>


<div class="figure">
<p><img src="../graphs/ROC-CART.png" alt="ROC-CART.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline14" class="outline-3">
<h3 id="orgheadline14"><span class="section-number-3">1.5</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Suppose you have a subset of 20 observations, where 14 have outcome A
and 6 have outcome B. What proportion of observations have outcome A?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Proportion of observations of A:"</span>)
A <span style="color: #db7093;">&lt;-</span> 14; B <span style="color: #db7093;">&lt;-</span> 6;
A / (A + B)
</pre>
</div>

<pre class="example">
 :: Proportion of observations of A:
[1] 0.7
</pre>
</div>

<div id="outline-container-orgheadline13" class="outline-4">
<h4 id="orgheadline13"><span class="section-number-4">1.5.1</span> Answer</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
<b>Explanation</b>
</p>

<p>
The fraction of observations that have outcome A is
</p>

<p>
\($
\frac{14}{14 + 6} = 0.7.
$\)
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline21" class="outline-3">
<h3 id="orgheadline21"><span class="section-number-3">1.6</span> Quick Question (3 points possible)</h3>
<div class="outline-text-3" id="text-1-6">
<p>
The following questions ask about the subset of 20 observations from
the previous question.
</p>
</div>

<div id="outline-container-orgheadline16" class="outline-4">
<h4 id="orgheadline16"><span class="section-number-4">1.6.1</span> Question</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
If we set the threshold to 0.25 when computing predictions of outcome
A, will we predict A or B for these observations?
</p>
</div>

<div id="outline-container-orgheadline15" class="outline-5">
<h5 id="orgheadline15"><span class="section-number-5">1.6.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-6-1-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> A</li>
<li class="off"><code>[&#xa0;]</code> B</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgheadline18" class="outline-4">
<h4 id="orgheadline18"><span class="section-number-4">1.6.2</span> Question</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
If we set the threshold to 0.5 when computing predictions of outcome
A, will we predict A or B for these observations?
</p>
</div>

<div id="outline-container-orgheadline17" class="outline-5">
<h5 id="orgheadline17"><span class="section-number-5">1.6.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-6-2-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> A</li>
<li class="off"><code>[&#xa0;]</code> B</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgheadline20" class="outline-4">
<h4 id="orgheadline20"><span class="section-number-4">1.6.3</span> Question</h4>
<div class="outline-text-4" id="text-1-6-3">
<p>
If we set the threshold to 0.75 when computing predictions of outcome
A, will we predict A or B for these observations?
</p>
</div>

<div id="outline-container-orgheadline19" class="outline-5">
<h5 id="orgheadline19"><span class="section-number-5">1.6.3.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-6-3-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> A</li>
<li class="on"><code>[X]</code> B</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline26" class="outline-3">
<h3 id="orgheadline26"><span class="section-number-3">1.7</span> Video 4: CART in R</h3>
<div class="outline-text-3" id="text-1-7">
<p>
In the next few videos, we'll be using the dataset <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/stevens.csv">stevens.csv</a> to
build trees in R. Please download the dataset to follow along. This
data comes from the <a href="http://wusct.wustl.edu/data.php">Supreme Court Forecasting Project</a> website.
</p>

<p>
An R script file with all of the R commands used in this lecture can
be downloaded <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/Unit4_SupremeCourt.R">here</a>.
</p>
</div>

<div id="outline-container-orgheadline22" class="outline-4">
<h4 id="orgheadline22"><span class="section-number-4">1.7.1</span> Download the data sets</h4>
<div class="outline-text-4" id="text-1-7-1">
<p>
In this part we can download the data
</p>

<div class="org-src-container">

<pre class="src src-R"><span style="color: #db7093;">library</span>(parallel)

<span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #ff6a6a;">"../data"</span>)) {
        dir.create(<span style="color: #ff6a6a;">"../data"</span>)
}

fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/stevens.csv"</span>

fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"stevens.csv"</span>

dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"../data"</span>

filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #ff6a6a;">"/"</span>)

<span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = <span style="color: #ff6a6a;">"curl"</span>)
}

list.files(<span style="color: #ff6a6a;">"../data"</span>)
</pre>
</div>

<pre class="example">
 [1] "AirlinesCluster.csv"       "AnonymityPoll.csv"
 [3] "baseball.csv"              "BoeingStock.csv"
 [5] "boston.csv"                "ClaimsData.csv"
 [7] "ClaimsData.csv.zip"        "climate_change.csv"
 [9] "clinical_trial.csv"        "ClusterMeans.ods"
[11] "CocaColaStock.csv"         "CountryCodes.csv"
[13] "CPSData.csv"               "dailykos.csv"
[15] "eBayAll.RData"             "eBayiPadTest.csv"
[17] "eBayiPadTrain.csv"         "edges.csv"
[19] "emails.csv"                "energy_bids.csv"
[21] "federalFundsRate.csv"      "finalExam-Households.csv"
[23] "flower.csv"                "FluTest.csv"
[25] "FluTrain.csv"              "framingham.csv"
[27] "gerber.csv"                "GEStock.csv"
[29] "healthy.csv"               "households.csv"
[31] "IBMStock.csv"              "intl.csv"
[33] "intlall.csv"               "loans_imputed.csv"
[35] "loans.csv"                 "MetroAreaCodes.csv"
[37] "movieLens.txt"             "MoviesP1Final.csv"
[39] "murders.csv"               "mvt.csv"
[41] "mvtWeek1.csv"              "NBA_test.csv"
[43] "NBA_train.csv"             "parole.csv"
[45] "pisa2009test.csv"          "pisa2009train.csv"
[47] "PollingData_Imputed.csv"   "PollingData.csv"
[49] "PollingImputed.csv"        "ProcterGambleStock.csv"
[51] "quality.csv"               "README.md"
[53] "SampleSubmission.csv"      "songs.csv"
[55] "stevens.csv"               "StocksCluster.csv"
[57] "stopwords.txt"             "SubmissionGBM1.csv"
[59] "SubmissionGBM2.csv"        "SubmissionLR2.csv"
[61] "SubmissionLR3.csv"         "SubmissionLR4.csv"
[63] "SubmissionLR5.csv"         "SubmissionLR8.csv"
[65] "SubmissionLR9.csv"         "SubmissionRF1.csv"
[67] "SubmissionSimpleLogV1.csv" "tumor.csv"
[69] "tweets.csv"                "tweetsU7.csv"
[71] "USDA.csv"                  "users.csv"
[73] "WHO_Europe.csv"            "WHO.csv"
[75] "WHOu7.csv"                 "wiki.csv"
[77] "wine_test.csv"             "wine.csv"
</pre>
</div>
</div>

<div id="outline-container-orgheadline23" class="outline-4">
<h4 id="orgheadline23"><span class="section-number-4">1.7.2</span> Load the data set</h4>
<div class="outline-text-4" id="text-1-7-2">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"    Loading data into their data frames."</span>)
stevens <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #ff6a6a;">"../data/stevens.csv"</span>, sep = <span style="color: #ff6a6a;">","</span>, header = <span style="color: #3cb371;">TRUE</span>)

str(stevens)
summary(stevens)
</pre>
</div>

<pre class="example">
    Loading data into their data frames.
'data.frame':	566 obs. of  9 variables:
 $ Docket    : Factor w/ 566 levels "00-1011","00-1045",..: 63 69 70 145 97 181 242 289 334 436 ...
 $ Term      : int  1994 1994 1994 1994 1995 1995 1996 1997 1997 1999 ...
 $ Circuit   : Factor w/ 13 levels "10th","11th",..: 4 11 7 3 9 11 13 11 12 2 ...
 $ Issue     : Factor w/ 11 levels "Attorneys","CivilRights",..: 5 5 5 5 9 5 5 5 5 3 ...
 $ Petitioner: Factor w/ 12 levels "AMERICAN.INDIAN",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ Respondent: Factor w/ 12 levels "AMERICAN.INDIAN",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ LowerCourt: Factor w/ 2 levels "conser","liberal": 2 2 2 1 1 1 1 1 1 1 ...
 $ Unconst   : int  0 0 0 0 0 1 0 1 0 0 ...
 $ Reverse   : int  1 1 1 1 1 0 1 1 1 1 ...
     Docket         Term         Circuit                  Issue
 00-1011:  1   Min.   :1994   9th    :122   CriminalProcedure:132
 00-1045:  1   1st Qu.:1995   5th    : 53   JudicialPower    :102
 00-1072:  1   Median :1997   11th   : 49   EconomicActivity : 98
 00-1073:  1   Mean   :1997   7th    : 47   CivilRights      : 74
 00-1089:  1   3rd Qu.:1999   4th    : 46   DueProcess       : 43
 00-121 :  1   Max.   :2001   8th    : 44   FirstAmendment   : 39
 (Other):560                  (Other):205   (Other)          : 78
               Petitioner               Respondent    LowerCourt
 OTHER              :175   OTHER             :177   conser :293
 CRIMINAL.DEFENDENT : 89   BUSINESS          : 80   liberal:273
 BUSINESS           : 79   US                : 69
 STATE              : 48   CRIMINAL.DEFENDENT: 58
 US                 : 48   STATE             : 56
 GOVERNMENT.OFFICIAL: 38   EMPLOYEE          : 28
 (Other)            : 89   (Other)           : 98
    Unconst          Reverse
 Min.   :0.0000   Min.   :0.0000
 1st Qu.:0.0000   1st Qu.:0.0000
 Median :0.0000   Median :1.0000
 Mean   :0.2473   Mean   :0.5459
 3rd Qu.:0.0000   3rd Qu.:1.0000
 Max.   :1.0000   Max.   :1.0000
</pre>

<p>
Now, let's take a look at our data using the <code>str</code> function. We have
566 observations, or Supreme Court cases, and nine different
variables.
</p>

<p>
<b>Docket</b> is just a unique identifier for each case, and <b>Term</b> is the
year of the case. Then we have our six independent variables: the <b>Circuit</b>
court of origin, the <b>Issue</b> area of the case, the type of
<b>Petitioner</b>, the type of <b>Respondent</b>, the lower court <b>LowerCourt</b>
direction, and whether or not the petitioner argued that a law or
practice was unconstitutional <b>Unconst</b>. The last variable is our
dependent variable, whether or not Justice Stevens voted to <b>reverse</b>
the case: 1 for reverse, and 0 for affirm.
</p>

<p>
Now before building models, we need to split our data into a training
set and a testing set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Split the data:"</span>)
<span style="color: #db7093;">library</span>(caTools)
set.seed(3000)

spl <span style="color: #db7093;">&lt;-</span> sample.split(stevens$Reverse, SplitRatio = 0.7)
Train <span style="color: #db7093;">&lt;-</span> subset(stevens, spl == <span style="color: #3cb371;">TRUE</span>)
Test <span style="color: #db7093;">&lt;-</span> subset(stevens, spl == <span style="color: #3cb371;">FALSE</span>)

writeLines(<span style="color: #ff6a6a;">"\n :: Dimensions of the training set:"</span>)
dim(Train)

writeLines(<span style="color: #ff6a6a;">"\n :: Dimensions of the testing set:"</span>)
dim(Test)
</pre>
</div>

<pre class="example">
 :: Split the data:

 :: Dimensions of the training set:
[1] 396   9

 :: Dimensions of the testing set:
[1] 170   9
</pre>

<p>
Now, we're ready to build our <b>CART</b> model. First we need to install and
load the <code>rpart</code> package and the <code>rpart</code> plotting package.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Install new package: rpart ..."</span>)
<span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('rpart', repos='http://cran.rstudio.com/')</span>

<span style="color: #9932cc;">## </span><span style="color: #ba55d3;">writeLines("\n :: Install new package: rpart.plot ...")</span>
<span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('rpart.plot', repos='http://cran.rstudio.com/')</span>
writeLines(<span style="color: #ff6a6a;">"\n :: NOTE: Please comment after install once..."</span>)

writeLines(<span style="color: #ff6a6a;">"\n :: Loading rpart and rpart.plot..."</span>)
<span style="color: #db7093;">library</span>(rpart)
<span style="color: #db7093;">library</span>(rpart.plot)

writeLines(<span style="color: #ff6a6a;">"\n :: rpart and r.part.plot libraries loaded..."</span>)
</pre>
</div>

<pre class="example">
:: Install new package: rpart ...

:: NOTE: Please comment after install once...

:: Loading rpart and rpart.plot...

:: rpart and r.part.plot libraries loaded...
</pre>
</div>
</div>

<div id="outline-container-orgheadline24" class="outline-4">
<h4 id="orgheadline24"><span class="section-number-4">1.7.3</span> Building the CART model</h4>
<div class="outline-text-4" id="text-1-7-3">
<p>
Now we can create our CART model using the rpart function.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: CART model DONE..."</span>)
StevensTree <span style="color: #db7093;">&lt;-</span> rpart(Reverse ~ Circuit + Issue + Petitioner +
            Respondent + LowerCourt + Unconst, data =
            Train, method = <span style="color: #ff6a6a;">"class"</span>, minbucket = 25)
</pre>
</div>

<pre class="example">
:: CART model DONE...
</pre>


<div id="orgparagraph1" class="figure">
<p><img src="../graphs/CARTcourtModel.png" alt="CARTcourtModel.png" />
</p>
<p><span class="figure-number">Figure 16:</span> CART model for the Stevens prediction.</p>
</div>

<p>
The last argument we'll give is <code>minbucket = 25</code>. This limits the tree
so that it doesn't overfit to our training set. We selected a value of
25, but we could pick a smaller or larger value.
</p>

<p>
If you're not sure what the abbreviations are, you could create a
table of the variable to see all of the possible values.
</p>
</div>
</div>

<div id="outline-container-orgheadline25" class="outline-4">
<h4 id="orgheadline25"><span class="section-number-4">1.7.4</span> Making predictions in the testing set</h4>
<div class="outline-text-4" id="text-1-7-4">
<p>
Comparing this to a logistic regression model, we can see that it's
very interpretable. A CART tree is a series of decision rules which
can easily be explained. Now let's see how well our CART model does at
making predictions for the test set.
</p>

<p>
And we'll add a third argument here, which is ~type = "class"~. We
need to give this argument when making predictions for our CART model
if we want the majority class predictions. This is like using a
threshold of \(0.5\).
</p>

<p>
We'll see in a few minutes how we can leave this argument out and
still get probabilities from our CART model.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions:"</span>)
PredictCART <span style="color: #db7093;">&lt;-</span> predict(StevensTree, newdata = Test, type = <span style="color: #ff6a6a;">"class"</span>)
table(Test$Reverse, PredictCART)

writeLines(<span style="color: #ff6a6a;">"\n :: Overall accuracy:"</span>)
(41+71)/(41+36+22+71)
</pre>
</div>

<pre class="example">
 :: Make predictions:
   PredictCART
     0  1
  0 41 36
  1 22 71

 :: Overall accuracy:
[1] 0.6588235
</pre>

<p>
Now let's compute the accuracy of our model by building a confusion
matrix. So we'll use the table function, and first give the true
outcome values&#x2013; <code>Test$Reverse</code>, and then our predictions,
<code>PredictCART</code>.
</p>

<p>
So the accuracy of our CART model is \(0.659\).
</p>

<p>
If you were to build a logistic regression model, you would get an
accuracy of 0.665 and a baseline model that always predicts Reverse,
the most common outcome, has an accuracy of 0.547. So our CART model
significantly beats the baseline and is competitive with logistic
regression.
</p>

<p>
Lastly, to evaluate our model, let's generate an ROC curve for our
CART model using the ROCR package.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: ROC curve:"</span>)
<span style="color: #db7093;">library</span>(ROCR)

PredictROC <span style="color: #db7093;">&lt;-</span> predict(StevensTree, newdata = Test)
head(PredictROC)

pred <span style="color: #db7093;">&lt;-</span> prediction(PredictROC[,2], Test$Reverse)
perf <span style="color: #db7093;">&lt;-</span> performance(pred, <span style="color: #ff6a6a;">"tpr"</span>, <span style="color: #ff6a6a;">"fpr"</span>)
</pre>
</div>

<pre class="example">
 :: ROC curve:
Loading required package: gplots

Attaching package: ‘gplots’

The following object is masked from ‘package:stats’:

    lowess
           0         1
1  0.3035714 0.6964286
3  0.3035714 0.6964286
4  0.4000000 0.6000000
6  0.4000000 0.6000000
8  0.4000000 0.6000000
21 0.3035714 0.6964286
</pre>

<p>
<b>PredictROC</b>
</p>

<p>
For each observation in the test set, it gives two numbers which can
be thought of as the probability of outcome 0 and the probability of
outcome 1. More concretely, each test set observation is classified
into a subset, or bucket, of our CART tree.
</p>

<p>
These numbers give the percentage of training set data in that subset
with outcome 0 and the percentage of data in the training set in that
subset with outcome 1.
</p>

<p>
Now we need to use the performance function, where the first argument
is the outcome of the prediction function, and then the next two
arguments are true positive rate and false positive rate, what we want
on the x and y-axes of our ROC curve.
</p>


<div id="orgparagraph2" class="figure">
<p><img src="../graphs/ROCtestingStevens.png" alt="ROCtestingStevens.png" />
</p>
<p><span class="figure-number">Figure 17:</span> The ROC curve for the justice Stevens.</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline32" class="outline-3">
<h3 id="orgheadline32"><span class="section-number-3">1.8</span> Quick Question (3 points possible)</h3>
<div class="outline-text-3" id="text-1-8">
</div><div id="outline-container-orgheadline27" class="outline-4">
<h4 id="orgheadline27"><span class="section-number-4">1.8.1</span> Question a</h4>
<div class="outline-text-4" id="text-1-8-1">
<p>
Compute the AUC of the CART model from the previous video, using the
following command in your R console:
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The AUC for the CART:"</span>)
as.numeric(performance(pred, <span style="color: #ff6a6a;">"auc"</span>)@y.values)
</pre>
</div>

<pre class="example">
 :: The AUC for the CART:
[1] 0.6927105
</pre>

<p>
What is the AUC?
</p>

<p>
<b>The AUC for the CART = 0.6927105</b>.
</p>
</div>
</div>

<div id="outline-container-orgheadline29" class="outline-4">
<h4 id="orgheadline29"><span class="section-number-4">1.8.2</span> Question b</h4>
<div class="outline-text-4" id="text-1-8-2">
<p>
Now, recall that in Video 4, our tree had 7 splits. Let's see how this
changes if we change the value of minbucket.
</p>

<p>
First build a CART model that is similar to the one we built in Video
4, except change the minbucket parameter to 5. Plot the tree.
</p>

<div class="org-src-container">

<pre class="src src-R">StevensTree2 <span style="color: #db7093;">&lt;-</span> rpart(Reverse ~ Circuit + Issue + Petitioner +
            Respondent + LowerCourt + Unconst, data =
            Train, method = <span style="color: #ff6a6a;">"class"</span>, minbucket = 5)

writeLines(<span style="color: #ff6a6a;">"\n :: CART model 2 DONE..."</span>)
</pre>
</div>

<pre class="example">
:: CART model 2 DONE...
</pre>


<div id="orgparagraph3" class="figure">
<p><img src="../graphs/CARTcourtModel2.png" alt="CARTcourtModel2.png" />
</p>
<p><span class="figure-number">Figure 18:</span> CART court model with a minbucket of 5.</p>
</div>

<p>
How many splits does the tree have?
</p>
</div>

<div id="outline-container-orgheadline28" class="outline-5">
<h5 id="orgheadline28"><span class="section-number-5">1.8.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-8-2-1">
<p>
<b>The tree have 16 splits</b>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline31" class="outline-4">
<h4 id="orgheadline31"><span class="section-number-4">1.8.3</span> Question c</h4>
<div class="outline-text-4" id="text-1-8-3">
<p>
Now build a CART model that is similar to the one we built in Video 4,
except change the minbucket parameter to 100. Plot the tree.
</p>

<div class="org-src-container">

<pre class="src src-R">StevensTree3 <span style="color: #db7093;">&lt;-</span> rpart(Reverse ~ Circuit + Issue + Petitioner +
            Respondent + LowerCourt + Unconst, data =
            Train, method = <span style="color: #ff6a6a;">"class"</span>, minbucket = 100)

writeLines(<span style="color: #ff6a6a;">"\n :: CART model 3 DONE..."</span>)
</pre>
</div>

<pre class="example">
:: CART model 3 DONE...
</pre>


<div id="orgparagraph4" class="figure">
<p><img src="../graphs/CARTcourtModel3.png" alt="CARTcourtModel3.png" />
</p>
<p><span class="figure-number">Figure 19:</span> CART court model with a minbucket of 5.</p>
</div>


<p>
How many splits does the tree have?
</p>
</div>

<div id="outline-container-orgheadline30" class="outline-5">
<h5 id="orgheadline30"><span class="section-number-5">1.8.3.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-8-3-1">
<p>
<b>This tree have only 1 split</b>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline33" class="outline-3">
<h3 id="orgheadline33"><span class="section-number-3">1.9</span> Video 5: Random Forests</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Important Note: In this video, we install the package
<b>randomForest</b>. If you get an installation warning that says:
</p>

<p>
"Warning: cannot remove prior installation of packages
'randomForest'", please try quitting and re-starting R.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Install new package: randomForest ..."</span>)
<span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages('randomForest', repos='http://cran.rstudio.com/')</span>
writeLines(<span style="color: #ff6a6a;">"\n :: NOTE: Please comment after install once..."</span>)

<span style="color: #db7093;">library</span>(randomForest)
writeLines(<span style="color: #ff6a6a;">"\n :: Library randomForest loaded..."</span>)
</pre>
</div>

<pre class="example">
 :: Install new package: randomForest ...

 :: NOTE: Please comment after install once...
randomForest 4.6-10
Type rfNews() to see new features/changes/bug fixes.

 :: Library randomForest loaded...
</pre>

<p>
We'll introduce a method that is similar to CART called random
forests. This method was designed to improve the prediction accuracy
of CART and works by building a large number of CART
trees. Unfortunately, this makes the method less interpretable than
CART, so often you need to decide if you value the interpretability or
the increase in accuracy more.
</p>

<p>
To make a prediction for a new observation, each tree in the forest
votes on the outcome and we pick the outcome that receives the
majority of the votes.
</p>


<div class="figure">
<p><img src="../graphs/RandomForest.png" alt="RandomForest.png" />
</p>
</div>

<p>
So how does random forests build many CART trees?
</p>

<p>
Random forests only allows each tree to split on a random subset of
the available independent variables, and each tree is built from what
we call a bagged or bootstrapped sample of the data. This just means
that the data used as the training data for each tree is selected
randomly with replacement.
</p>


<div class="figure">
<p><img src="../graphs/BuildingManyTrees.png" alt="BuildingManyTrees.png" />
</p>
</div>

<p>
Suppose we have five data points in our training set. We'll call them
1, 2, 3, 4, and 5. For the first tree, we'll randomly pick five data
points randomly sampled with replacement.
</p>

<p>
So the data could be 2, 4, 5, 2, and 1. Each time we pick one of the
five data points regardless of whether or not it's been selected
already. These would be the five data points we would use when
constructing the first CART tree.
</p>

<p>
Then we repeat this process for the second tree. This time the data
set might be 3, 5, 1, 5, and 2. And we would use this data when
building the second CART tree. Then we would repeat this process for
each additional tree we want to create.
</p>

<p>
So <b>since each tree sees a different set of variables</b> and a different
set of data, we get what's called a <b>forest</b> of many different
trees. Just like CART, <b>random forests</b> has some parameter values that
need to be selected. The first is the minimum number of observations
in a subset, or the minbucket parameter from CART.
</p>


<div class="figure">
<p><img src="../graphs/RFParameters.png" alt="RFParameters.png" />
</p>
</div>

<p>
When we create a random forest in R, this will be called <b>nodesize</b>. A
<b>smaller value of nodesize</b>, which <b>leads to bigger trees</b>, may take
longer in R. Random forests is much more computationally intensive
than CART. The second parameter is the number of trees to build, which
is called <b>ntree</b> in R. This should not be set too small, but the larger
it is the longer it will take. A couple hundred trees is typically
plenty. A nice thing about random forests is that it's not as
sensitive to the parameter values as CART is.
</p>

<p>
For random forests, as long as the selection is reasonable, it's OK.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Build random forest model:"</span>)
StevensForest <span style="color: #db7093;">&lt;-</span> randomForest(Reverse ~ Circuit + Issue + Petitioner +
                                      Respondent + LowerCourt +
                              Unconst, data = Train, ntree = 200,
                              nodesize = 25 )
summary(StevensForest)
</pre>
</div>

<pre class="example">
 :: Build random forest model:
 Warning message:
In randomForest.default(m, y, ...) :
  The response has five or fewer unique values.  Are you sure you want to do regression?
                Length Class  Mode
call              5    -none- call
type              1    -none- character
predicted       396    -none- numeric
mse             200    -none- numeric
rsq             200    -none- numeric
oob.times       396    -none- numeric
importance        6    -none- numeric
importanceSD      0    -none- NULL
localImportance   0    -none- NULL
proximity         0    -none- NULL
ntree             1    -none- numeric
mtry              1    -none- numeric
forest           11    -none- list
coefs             0    -none- NULL
y               396    -none- numeric
test              0    -none- NULL
inbag             0    -none- NULL
terms             3    terms  call
</pre>

<p>
You should see an interesting warning message here. In CART, we added
the argument ~method = "class"~, so that it was clear that we're doing
a classification problem. As I mentioned earlier, trees can also be
used for regression problems, which you'll see in the recitation.
</p>

<p>
The randomForest function does not have a method argument. So when we
<b>want to do a classification problem</b>, we need to make sure <b>outcome
is a factor</b>. Let's convert the variable Reverse to a factor variable in
both our training and our testing sets.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Converting outcome to factor..."</span>)
Train$Reverse <span style="color: #db7093;">&lt;-</span> as.factor(Train$Reverse)
Test$Reverse <span style="color: #db7093;">&lt;-</span> as.factor(Test$Reverse)
</pre>
</div>

<pre class="example">
:: Converting outcome to factor...
</pre>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Try again to build the RF model:"</span>)
StevensForest <span style="color: #db7093;">&lt;-</span> randomForest(Reverse ~ Circuit + Issue + Petitioner +
                                      Respondent + LowerCourt +
                              Unconst, data = Train, ntree = 200,
                              nodesize = 25 )
summary(StevensForest)
</pre>
</div>

<pre class="example">
 :: Try again to build the RF model:
                Length Class  Mode
call              5    -none- call
type              1    -none- character
predicted       396    factor numeric
err.rate        600    -none- numeric
confusion         6    -none- numeric
votes           792    matrix numeric
oob.times       396    -none- numeric
classes           2    -none- character
importance        6    -none- numeric
importanceSD      0    -none- NULL
localImportance   0    -none- NULL
proximity         0    -none- NULL
ntree             1    -none- numeric
mtry              1    -none- numeric
forest           14    -none- list
y               396    factor numeric
test              0    -none- NULL
inbag             0    -none- NULL
terms             3    terms  call
</pre>

<p>
Let's compute predictions on our test set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions in the test set:"</span>)
PredictForest <span style="color: #db7093;">&lt;-</span> predict(StevensForest, newdata = Test)

writeLines(<span style="color: #ff6a6a;">"\n :: Build the confusion matrix (random component in RF):"</span>)
table(Test$Reverse, PredictForest)

writeLines(<span style="color: #ff6a6a;">"\n :: Calculate the overall accuracy:"</span>)
(40 + 74) / (40 + 37 + 19 + 74)
</pre>
</div>

<pre class="example">
 :: Make predictions in the test set:

 :: Build the confusion matrix (random component in RF):
   PredictForest
     0  1
  0 40 37
  1 19 74

 :: Calculate the overall accuracy:
[1] 0.6705882
</pre>

<p>
So the accuracy of our Random Forest model is about \(67\%\). Recall that
our logistic regression model had an accuracy of \(66.5\%\) and our CART
model had an accuracy of \(65.9\%\).
</p>

<p>
So our random forest model improved our accuracy a little bit over
CART. Sometimes you'll see a smaller improvement in accuracy and
sometimes you'll see that random forests can significantly improve in
accuracy over CART.
</p>

<p>
Keep in mind that Random Forests has a random component. You may have
gotten a different confusion matrix than me because there's a random
component to this method.
</p>

<p>
Keep in mind that Random Forests has a random component. You may have
gotten a different confusion matrix than the instructor because
there's a random component to this method.
</p>
</div>
</div>

<div id="outline-container-orgheadline38" class="outline-3">
<h3 id="orgheadline38"><span class="section-number-3">1.10</span> QUICK QUESTION  (2 points possible)</h3>
<div class="outline-text-3" id="text-1-10">
<p>
<b>IMPORTANT NOTE</b>: When creating random forest models, you might still
get different answers from the ones you see here even if you set the
random seed. This has to do with different operating systems and the
random forest implementation.
</p>

<p>
Let's see what happens if we set the seed to two different values and
create two different random forest models.
</p>

<p>
First, set the seed to 100, and the re-build the random forest model,
exactly like we did in the previous video (Video 5). Then make
predictions on the test set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Try again to build the RF model:"</span>)
set.seed(100)
StevensForest2 <span style="color: #db7093;">&lt;-</span> randomForest(Reverse ~ Circuit + Issue + Petitioner +
                                      Respondent + LowerCourt +
                              Unconst, data = Train, ntree = 200,
                              nodesize = 25 )

writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions in the test set:"</span>)
PredictForest2 <span style="color: #db7093;">&lt;-</span> predict(StevensForest2, newdata = Test)

writeLines(<span style="color: #ff6a6a;">"\n :: Build the confusion matrix (random component in RF):"</span>)
table(Test$Reverse, PredictForest2)

writeLines(<span style="color: #ff6a6a;">"\n :: Calculate the overall accuracy:"</span>)
(43 + 74) / (43 + 34 + 19 + 74)
</pre>
</div>

<pre class="example">
 :: Try again to build the RF model:

 :: Make predictions in the test set:

 :: Build the confusion matrix (random component in RF):
   PredictForest2
     0  1
  0 43 34
  1 19 74

 :: Calculate the overall accuracy:
[1] 0.6882353
</pre>
</div>

<div id="outline-container-orgheadline35" class="outline-4">
<h4 id="orgheadline35"><span class="section-number-4">1.10.1</span> Question a</h4>
<div class="outline-text-4" id="text-1-10-1">
<p>
What is the accuracy of the model on the test set?
</p>
</div>

<div id="outline-container-orgheadline34" class="outline-5">
<h5 id="orgheadline34"><span class="section-number-5">1.10.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-10-1-1">
<p>
0.6882353
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline37" class="outline-4">
<h4 id="orgheadline37"><span class="section-number-4">1.10.2</span> Question b</h4>
<div class="outline-text-4" id="text-1-10-2">
<p>
Now, set the seed to 200, and then re-build the random forest model,
exactly like we did in the previous video (Video 5). Then make
predictions on the test set. What is the accuracy of this model on the
test set?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Try again to build the RF model:"</span>)
set.seed(200)
StevensForest3 <span style="color: #db7093;">&lt;-</span> randomForest(Reverse ~ Circuit + Issue + Petitioner +
                                      Respondent + LowerCourt +
                              Unconst, data = Train, ntree = 200,
                              nodesize = 25 )

writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions in the test set:"</span>)
PredictForest3 <span style="color: #db7093;">&lt;-</span> predict(StevensForest3, newdata = Test)

writeLines(<span style="color: #ff6a6a;">"\n :: Build the confusion matrix (random component in RF):"</span>)
table(Test$Reverse, PredictForest3)

writeLines(<span style="color: #ff6a6a;">"\n :: Calculate the overall accuracy:"</span>)
(44 + 76) / (44 + 33 + 17 + 76)
</pre>
</div>

<pre class="example">
 :: Try again to build the RF model:

 :: Make predictions in the test set:

 :: Build the confusion matrix (random component in RF):
   PredictForest3
     0  1
  0 44 33
  1 17 76

 :: Calculate the overall accuracy:
[1] 0.7058824
</pre>
</div>

<div id="outline-container-orgheadline36" class="outline-5">
<h5 id="orgheadline36"><span class="section-number-5">1.10.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-10-2-1">
<p>
0.7058824
</p>

<p>
<b>EXPLANATION</b>
</p>

<p>
You can create the models and compute the accurracies with the
following commands in R:
</p>

<p>
<code>set.seed(100)</code>
</p>

<p>
<code>StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner +</code>
</p>

<p>
<code>Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25)</code>
</p>

<p>
<code>PredictForest = predict(StevensForest, newdata = Test)</code>
</p>

<p>
<code>table(Test$Reverse, PredictForest)</code>
</p>

<p>
and then repeat it, but with set.seed(200) first.
</p>

<p>
As we see here, the <b>random component</b> of the random forest method
<b>can change the accuracy</b>. The accuracy for a more stable dataset will not
change very much, but a noisy dataset can be significantly affected by
the random samples.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline45" class="outline-3">
<h3 id="orgheadline45"><span class="section-number-3">1.11</span> VIDEO 6: Cross-Validation</h3>
<div class="outline-text-3" id="text-1-11">
<p>
<b>IMPORTANT NOTE ABOUT THIS VIDEO</b>
</p>

<p>
In this video, we install and load two new packages so that we can
perform cross-validation: "caret", and "e1071". You may need to
additionally install and load the following packages for
cross-validation to work on your computer: "class" and "ggplot2". If
you receive an error message after trying to load caret and e1071,
please try installing and loading these two additional packages.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Install new package: Caret and e1071 ..."</span>)
<span style="color: #9932cc;">## </span><span style="color: #ba55d3;">install.packages(c("caret", "e1071"), repos='http://cran.rstudio.com/')</span>
writeLines(<span style="color: #ff6a6a;">"\n :: NOTE: Please comment after install once..."</span>)

<span style="color: #db7093;">library</span>(caret)
<span style="color: #db7093;">library</span>(e1071)
writeLines(<span style="color: #ff6a6a;">"\n :: Library Caret and e1071 loaded..."</span>)
</pre>
</div>

<pre class="example">
 :: Install new package: Caret and e1071 ...

 :: NOTE: Please comment after install once...
Loading required package: lattice
Loading required package: ggplot2

 :: Library Caret and e1071 loaded...
</pre>


<div class="figure">
<p><img src="../graphs/ParameterSelectionCART.png" alt="ParameterSelectionCART.png" />
</p>
</div>

<p>
if minbucket is too small, over-fitting might occur. But if minbucket
is too large, the model might be too simple. So how should we set this
parameter value?
</p>

<p>
We could select the value that gives the best testing set accuracy,
but this isn't right. The idea of the testing set is to measure model
performance on data the model has never seen before.
</p>

<p>
By picking the value of <b>minbucket</b> to get the best test set
performance, the testing set was implicitly used to generate the
model.
</p>

<p>
Instead, we'll use a method called <b>K-fold Cross Validation</b>, which is
one way to properly select the parameter value.
</p>

<p>
This method works by going through the following steps:
</p>
</div>

<div id="outline-container-orgheadline39" class="outline-4">
<h4 id="orgheadline39"><span class="section-number-4">1.11.1</span> First</h4>
<div class="outline-text-4" id="text-1-11-1">
<p>
We split the training set into k equally sized subsets, or folds. In
this example, k equals 5.
</p>


<div class="figure">
<p><img src="../graphs/K-FoldCrossValidation.png" alt="K-FoldCrossValidation.png" />
</p>
</div>


<div class="figure">
<p><img src="../graphs/K-FoldCrossValidation02.png" alt="K-FoldCrossValidation02.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline40" class="outline-4">
<h4 id="orgheadline40"><span class="section-number-4">1.11.2</span> Second</h4>
<div class="outline-text-4" id="text-1-11-2">
<p>
Then we select \(k - 1\), or four folds, to estimate the model, and
compute predictions on the remaining one fold, which is often referred
to as the validation set. We build a model and make predictions for
each possible parameter value we're considering.
</p>


<div class="figure">
<p><img src="../graphs/K-FoldCrossValidation03.png" alt="K-FoldCrossValidation03.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline41" class="outline-4">
<h4 id="orgheadline41"><span class="section-number-4">1.11.3</span> Third</h4>
<div class="outline-text-4" id="text-1-11-3">
<p>
Then we repeat this for each of the other folds, or pieces of our
training set. So we would build a model using folds 1, 2, 3, and 5 to
make predictions on fold 4.
</p>


<div class="figure">
<p><img src="../graphs/K-FoldCrossValidation04.png" alt="K-FoldCrossValidation04.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline42" class="outline-4">
<h4 id="orgheadline42"><span class="section-number-4">1.11.4</span> Fourth</h4>
<div class="outline-text-4" id="text-1-11-4">
<p>
And then we would build a model using folds 1, 2, 4, and 5 to make
predictions on fold 3, etc.
</p>


<div class="figure">
<p><img src="../graphs/K-FoldCrossValidation05.png" alt="K-FoldCrossValidation05.png" />
</p>
</div>

<p>
So ultimately, cross validation builds many models, one for each fold
and possible parameter value.
</p>
</div>
</div>

<div id="outline-container-orgheadline43" class="outline-4">
<h4 id="orgheadline43"><span class="section-number-4">1.11.5</span> Output K-Fold Cross Validation</h4>
<div class="outline-text-4" id="text-1-11-5">
<p>
This plot shows the possible parameter values on the x-axis, and the
accuracy of the model on the y-axis. This line shows the accuracy of
our model on fold 1. We can also compute the accuracy of the model
using each of the other folds as the validation sets.
</p>


<div class="figure">
<p><img src="../graphs/OutputK-FoldCrossValidation.png" alt="OutputK-FoldCrossValidation.png" />
</p>
</div>

<p>
We then average the accuracy over the k folds to determine the final
parameter value that we want to use. Typically, the behavior looks
like this&#x2013; if the parameter value is too small, then the accuracy is
lower, because the model is probably over-fit to the training set.
</p>

<p>
But if the parameter value is too large, then the accuracy is also
lower, because the model is too simple. In this case, we would pick a
parameter value around six, because it leads to the maximum average
accuracy over all parameter values.
</p>


<div class="figure">
<p><img src="../graphs/OutputK-FoldCrossValidation02.png" alt="OutputK-FoldCrossValidation02.png" />
</p>
</div>

<p>
So far, we've used the parameter <b>minbucket</b> to limit our tree in
R. <b>When we use cross validation in R</b>, we'll use a parameter called
<b>cp</b> instead.
</p>


<div class="figure">
<p><img src="../graphs/CP-parameter.png" alt="CP-parameter.png" />
</p>
</div>

<p>
<b>A smaller cp value leads to a bigger tree</b>, so a smaller cp value might
<b>over-fit</b> the model to the training set. But a <b>cp value that's too
large</b> might build a model that's too simple.
</p>
</div>
</div>

<div id="outline-container-orgheadline44" class="outline-4">
<h4 id="orgheadline44"><span class="section-number-4">1.11.6</span> Cross validation in R for the example of RF</h4>
<div class="outline-text-4" id="text-1-11-6">
<p>
First, we need to define how many folds we want. We can do this using
the <code>trainControl</code> function. So we'll say <code>numFolds = trainControl</code>, and
then in parentheses, <code>(method = "cv")</code>, for cross validation, and then
<code>number = 10</code>, for 10 folds.
</p>

<p>
Then we need to pick the possible values for our <code>cp</code> parameter, using
the <code>expand.grid</code> function. So we'll call it <code>cpGrid</code>, and then use
<code>expand.grid</code>, where the only argument is <code>.cp = seq(0.01, 0.5, 0.01)</code>. This
will define our <code>cp</code> parameters to test as numbers from 0.01 to 0.5, in
increments of 0.01.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Define cross-validation experiment:"</span>)
numFolds <span style="color: #db7093;">&lt;-</span> trainControl( method = <span style="color: #ff6a6a;">"cv"</span>, number = 10 )
cpGrid <span style="color: #db7093;">&lt;-</span> expand.grid(.cp = seq(0.01, 0.5, 0.01))
</pre>
</div>

<pre class="example">
:: Define cross-validation experiment:
</pre>

<p>
Now, we're ready to perform cross validation. We'll do this using the
train function, where the first argument is similar to that when we're
building models.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Perform the cross validation:"</span>)
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt
      + Unconst, data = Train, method = <span style="color: #ff6a6a;">"rpart"</span>, trControl = numFolds,
      tuneGrid = cpGrid)
</pre>
</div>

<pre class="example">
 :: Perform the cross validation:
 CART

396 samples
  8 predictor
  2 classes: '0', '1'

No pre-processing
Resampling: Cross-Validated (10 fold)
Summary of sample sizes: 357, 356, 357, 356, 356, 356, ...
Resampling results across tuning parameters:

  cp    Accuracy   Kappa        Accuracy SD  Kappa SD
  0.01  0.6365385  0.252522710  0.045831216  0.10138314
  0.02  0.6337179  0.248281522  0.061267954  0.12752003
  0.03  0.6314103  0.251796733  0.053552823  0.11468412
  0.04  0.6314103  0.253786180  0.053552823  0.11438075
  0.05  0.6440385  0.282995035  0.062472910  0.13104160
  0.06  0.6440385  0.282995035  0.062472910  0.13104160
  0.07  0.6440385  0.282995035  0.062472910  0.13104160
  0.08  0.6440385  0.282995035  0.062472910  0.13104160
  0.09  0.6440385  0.282995035  0.062472910  0.13104160
  0.10  0.6440385  0.282995035  0.062472910  0.13104160
  0.11  0.6440385  0.282995035  0.062472910  0.13104160
  0.12  0.6440385  0.282995035  0.062472910  0.13104160
  0.13  0.6440385  0.282995035  0.062472910  0.13104160
  0.14  0.6440385  0.282995035  0.062472910  0.13104160
  0.15  0.6440385  0.282995035  0.062472910  0.13104160
  0.16  0.6440385  0.282995035  0.062472910  0.13104160
  0.17  0.6440385  0.282995035  0.062472910  0.13104160
  0.18  0.6440385  0.282995035  0.062472910  0.13104160
  0.19  0.6440385  0.282995035  0.062472910  0.13104160
  0.20  0.6085897  0.193703966  0.058244587  0.14192310
  0.21  0.5807692  0.121202966  0.046444754  0.12714614
  0.22  0.5605128  0.062732119  0.032700267  0.09526381
  0.23  0.5428846  0.003553299  0.008506582  0.01123652
  0.24  0.5428846  0.003553299  0.008506582  0.01123652
  0.25  0.5453846  0.000000000  0.005958436  0.00000000
  0.26  0.5453846  0.000000000  0.005958436  0.00000000
  0.27  0.5453846  0.000000000  0.005958436  0.00000000
  0.28  0.5453846  0.000000000  0.005958436  0.00000000
  0.29  0.5453846  0.000000000  0.005958436  0.00000000
  0.30  0.5453846  0.000000000  0.005958436  0.00000000
  0.31  0.5453846  0.000000000  0.005958436  0.00000000
  0.32  0.5453846  0.000000000  0.005958436  0.00000000
  0.33  0.5453846  0.000000000  0.005958436  0.00000000
  0.34  0.5453846  0.000000000  0.005958436  0.00000000
  0.35  0.5453846  0.000000000  0.005958436  0.00000000
  0.36  0.5453846  0.000000000  0.005958436  0.00000000
  0.37  0.5453846  0.000000000  0.005958436  0.00000000
  0.38  0.5453846  0.000000000  0.005958436  0.00000000
  0.39  0.5453846  0.000000000  0.005958436  0.00000000
  0.40  0.5453846  0.000000000  0.005958436  0.00000000
  0.41  0.5453846  0.000000000  0.005958436  0.00000000
  0.42  0.5453846  0.000000000  0.005958436  0.00000000
  0.43  0.5453846  0.000000000  0.005958436  0.00000000
  0.44  0.5453846  0.000000000  0.005958436  0.00000000
  0.45  0.5453846  0.000000000  0.005958436  0.00000000
  0.46  0.5453846  0.000000000  0.005958436  0.00000000
  0.47  0.5453846  0.000000000  0.005958436  0.00000000
  0.48  0.5453846  0.000000000  0.005958436  0.00000000
  0.49  0.5453846  0.000000000  0.005958436  0.00000000
  0.50  0.5453846  0.000000000  0.005958436  0.00000000

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was cp = 0.19.
</pre>

<p>
This is the cp value we want to use in our CART model. So now let's
create a new CART model with this value of cp, instead of the
minbucket parameter.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Create a new CART model:"</span>)
StevensTreeCV <span style="color: #db7093;">&lt;-</span> rpart(Reverse ~ Circuit + Issue + Petitioner +
                               Respondent + LowerCourt + Unconst, data
                       = Train, method=<span style="color: #ff6a6a;">"class"</span>, cp = 0.19)
</pre>
</div>

<pre class="example">
:: Create a new CART model:
</pre>

<p>
We'll call this model <b>StevensTreeCV</b>, and we'll use the rpart
function, like we did earlier, to predict Reverse using all of our
independent variables: Circuit, Issue, Petitioner, Respondent,
LowerCourt, and Unconst.
</p>

<p>
Our data set here is <b>Train</b>, and then we want method = "class",
since we're building a classification tree, and cp = 0.18.
</p>

<p>
Let's make predictions on our test set using this model.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions:"</span>)
PredictCV <span style="color: #db7093;">&lt;-</span> predict(StevensTreeCV, newdata = Test, type = <span style="color: #ff6a6a;">"class"</span>)

table(Test$Reverse, PredictCV)
writeLines(<span style="color: #ff6a6a;">"\n :: Calculate the overall accuracy:"</span>)
(59 + 64)/(59 + 18 + 29 + 64)
</pre>
</div>

<pre class="example">
 :: Make predictions:
   PredictCV
     0  1
  0 59 18
  1 29 64

 :: Calculate the overall accuracy:
[1] 0.7235294
</pre>

<p>
Remember that the accuracy of our previous CART model was
\(0.659\). Cross validation helps us make sure we're selecting a good
parameter value, and often this will significantly increase the
accuracy.
</p>

<p>
If we had already happened to select a good parameter value, then the
accuracy might not of increased that much. But by using cross
validation, we can be sure that we're selecting a smart parameter
value.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline46" class="outline-3">
<h3 id="orgheadline46"><span class="section-number-3">1.12</span> QUICK QUESTION  (1 point possible)</h3>
<div class="outline-text-3" id="text-1-12">
<p>
Plot the tree that we created using cross-validation. How many splits
does it have?
</p>


<div id="orgparagraph5" class="figure">
<p><img src="../graphs/CARTcourtModelCV.png" alt="CARTcourtModelCV.png" />
</p>
<p><span class="figure-number">Figure 32:</span> CART model for the Stevens prediction with Cross Validation.</p>
</div>

<p>
<b>EXPLANATION</b>
</p>

<p>
If you follow the R commands from the previous video, you can plot the
tree with <code>prp(StevensTreeCV)</code>.
</p>

<p>
The tree with the best accuracy only has one split! When we were
picking different minbucket parameters before, it seemed like this
tree was probably not doing a good job of fitting the data. However,
this tree with one split gives us the best out-of-sample
accuracy. This reminds us that sometimes the simplest models are the
best!
</p>
</div>
</div>

<div id="outline-container-orgheadline47" class="outline-3">
<h3 id="orgheadline47"><span class="section-number-3">1.13</span> Video 7: The Model V. The Experts</h3>
<div class="outline-text-3" id="text-1-13">
<p>
Can a CART model actually predict Supreme Court case outcomes better
than a group of experts? Martin and his colleagues used 628 previous
Supreme Court cases between 1994 and 2001 to build their model. They
made predictions for the 68 cases that would be decided in October,
2002, before the term started.
</p>


<div class="figure">
<p><img src="../graphs/Martin_sModel.png" alt="Martin_sModel.png" />
</p>
</div>

<p>
Their model had two stages of CART trees. The first stage involved
making predictions using two CART trees. One to predict a unanimous
liberal decision and one to predict a unanimous conservative decision.
</p>

<p>
If the trees gave conflicting responses or both predicted no, then
they moved on to the next stage. It turns out that about 50% of
Supreme Court cases result in a unanimous decision, so this was a nice
first step to detect the easier cases.
</p>

<p>
The second stage consisted of predicting the decision of each
individual justice, and then use the majority decision of all nine
justices as a final prediction for the case.
</p>

<p>
Here's a different tree, this one for Justice O'Connor. The first
split is whether or not the lower court decision is liberal. If yes,
then we predict that she will reverse the case. This makes sense
because Justice O'Connor is generally viewed as a conservative judge.
</p>

<p>
On the other hand, if the lower court decision is conservative, we
check for the circuit court of origin. We predict that she will affirm
the case. If it's not one of these courts, we move on to the next
split. The remaining two splits are for the respondent and the primary
issue.
</p>


<div class="figure">
<p><img src="../graphs/OConnor.png" alt="OConnor.png" />
</p>
</div>

<p>
Here's another tree, this one for Justice Souter. This shows an
unusual property of the CART trees that Martin and his colleagues
developed. They use predictions for some trees as independent
variables for other trees.
</p>

<p>
In this tree, the first split is whether or not Justice Ginsburg's
predicted decision is liberal. So we have to run Justice Ginsburg's
CART tree first, see what the prediction is, and then use that as
input for Justice Souter's tree.
</p>


<div class="figure">
<p><img src="../graphs/Souter.png" alt="Souter.png" />
</p>
</div>

<p>
If Justice Ginsburg's predicted decision is liberal and the lower
court decision is liberal, then we predict that Justice Souter will
affirm the case. But if the lower court decision is conservative, then
we predict that Justice Souter will reverse the case.
</p>

<p>
On the other side of the tree, if Justice Ginsburg's predicted
decision is conservative, but the lower court decision is liberal,
then we predict that Justice Souter will reverse the case. But if the
lower court decision is conservative, then we predict that Justice
Souter will affirm the case.
</p>

<p>
In summary, if we predict that Justice Ginsburg will make a liberal
decision, then Justice Souter will probably make a liberal decision
too.
</p>

<p>
But if we predict that Justice Ginsburg will make a conservative
decision, then we predict that Justice Souter will probably make a
conservative decision too.
</p>


<div class="figure">
<p><img src="../graphs/TheExperts.png" alt="TheExperts.png" />
</p>
</div>

<p>
So this was really a dream team of experts. Additionally, the experts
were only asked to predict within their area of expertise. So not all
experts predicted all cases, but there was more than one expert making
predictions for each case.
</p>

<p>
For the 68 cases in October 2002, the predictions were made, and at
the end of the month the results were computed.
</p>


<div class="figure">
<p><img src="../graphs/CARTResults.png" alt="CARTResults.png" />
</p>
</div>

<p>
For predicting the overall decision that was made by the Supreme
Court, the models had an accuracy of 75%, while the experts only had
an accuracy of 59%. So the models had a significant edge over the
experts in predicting the overall case outcomes.
</p>

<p>
However, when the predictions were run for individual justices, the
model and the experts performed very similarly.
</p>

<p>
For some justices, the model performed better, and for some justices,
the experts performed better.
</p>


<div class="figure">
<p><img src="../graphs/CARTAnalyticsEdge.png" alt="CARTAnalyticsEdge.png" />
</p>
</div>

<p>
We saw in this lecture that a model that predicts overall Supreme
Court decisions is both more accurate than experts and can be run much
faster than experts can make their predictions.
</p>

<p>
The CART models that we built were based on very high level components
of the cases, compared to the experts who can process much more
detailed and complex information.
</p>

<p>
This example really shows the edge that analytics can provide in
traditionally qualitative applications.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline81" class="outline-2">
<h2 id="orgheadline81"><span class="section-number-2">2</span> Keeping an Eye on Healthcare Costs: The D2Hawkeye Story</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-orgheadline49" class="outline-3">
<h3 id="orgheadline49"><span class="section-number-3">2.1</span> Video 1: The Story of D2Hawkeye</h3>
<div class="outline-text-3" id="text-2-1">
<p>
This is a story of D2Hawkeye, a medical data mining company located in
Waltham, Massachusetts.
</p>


<div class="figure">
<p><img src="../graphs/D2Hawkeye.png" alt="D2Hawkeye.png" />
</p>
</div>

<p>
It grew very fast and was sold to Verisk Analytics in 2009. The
overall process that D2Hawkeye uses is as follows.
</p>

<p>
It starts with medical claims that consist of diagnoses, procedures,
and drugs. These medical claims are then processed via process of
aggregation, cleaning, and normalization. This data then enters secure
databases on which predictive models are applied.
</p>

<p>
The output of predictive models are specific reports that give insight
to the various questions that D2Hawkeye aspires to answer.
</p>


<div class="figure">
<p><img src="../graphs/D2Hawkeye02.png" alt="D2Hawkeye02.png" />
</p>
</div>

<p>
The company tries to improve health care case
management. Specifically, it tries to identify high-risk patients,
work with patients to manage treatment and associated costs, and
arrange specialist care.
</p>


<div class="figure">
<p><img src="../graphs/HealthcareCaseManagement.png" alt="HealthcareCaseManagement.png" />
</p>
</div>

<p>
The overall goal of D2Hawkeye is to improve the quality of cost
predictions.
</p>

<p>
<b>D2Hawkeye had many different types of clients</b>.
</p>


<div class="figure">
<p><img src="../graphs/D2HEImpact.png" alt="D2HEImpact.png" />
</p>
</div>


<p>
To analyze the data, the company used what we call a pre-analytics
approach. This was based on the human judgment of physicians who
manually analyze patient histories and developed medical rules.
</p>

<p>
Of course, this involved human judgment, utilized a limited set of
data, it was often costly, and somewhat inefficient. The key question
we analyze in this lecture is <b>Can we use analytics instead?</b>
</p>


<div class="figure">
<p><img src="../graphs/Pre-AnalyticsApproach.png" alt="Pre-AnalyticsApproach.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline50" class="outline-3">
<h3 id="orgheadline50"><span class="section-number-3">2.2</span> Video 2: Claims Data</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Let us discuss data sources in the health care industry. Hospitals in
southern Massachusetts versus California might use different
technologies and different platforms.
</p>

<p>
Finally there are strong privacy laws, HIPAA, around health care data
sharing.
</p>


<div class="figure">
<p><img src="../graphs/DataSources.png" alt="DataSources.png" />
</p>
</div>

<p>
Claims data is a major source. Claims data are requests for
reimbursement submitted to insurance companies or state-provided
insurance from doctors, hospitals and pharmacies.
</p>

<p>
Another source of data is the eligibility information for
employees. And finally demographic information: gender and age.
</p>


<div class="figure">
<p><img src="../graphs/DataSources02.png" alt="DataSources02.png" />
</p>
</div>

<p>
Let me give you some examples on claims data. So this shows six
different claims. Let's consider this one.
</p>

<p>
So this is the provider's name. The corresponding diagnostic
code. This is about upper respiratory disorders. This is another code
associated with the diagnosis. This is the scientific term for the
diagnosis. The specific code again. This was an office visit, and it's
an established patient. The date.
</p>

<p>
And the amount of money that was claimed by the physician. Others
claims are similar.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ClaimsData.png" alt="D2HE-ClaimsData.png" />
</p>
</div>

<p>
As we see, the claims data is a rich, structured data source. It is
very high dimensional. For example, claims involving diagnosis involve
thousands of different codes.
</p>

<p>
Similarly with drugs, where there are tens of thousands, and
procedures.
</p>

<p>
However, this collection of data does not capture all aspects of a
person's treatment or health. Many things must be inferred. Unlike
electronic medical records, we do not know the results of a test, only
that the test was administered.
</p>

<p>
For example, we do not know the results of a blood test, but we do
know that the blood test was administered.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ClaimsData02.png" alt="D2HE-ClaimsData02.png" />
</p>
</div>

<p>
The specific exercise we are going to see in this lecture is an
analytics approach to building models starting with 2.4 million people
over a three year span.
</p>

<p>
The observation period was 2001 to 2003. This is where this data is
coming from. And then out of sample, we make predictions for the
period of 2003 and 2004.
</p>

<p>
This was in the early years of D2Hawkeye. Out of the 2.4 million
people, we included only people with data for at least 10 months in
both periods, both in the observation period and the results period.
</p>

<p>
This decreased the data to 400,000 people.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ClaimsData03.png" alt="D2HE-ClaimsData03.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline54" class="outline-3">
<h3 id="orgheadline54"><span class="section-number-3">2.3</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-3">
<p>
A common problem in analytics is that you have some data available,
but it's not the ideal dataset. This is the case for this problem,
where we only have claims data. Which of the following pieces of
information would we ideally like to have in our dataset, but are not
included in claims data? (Select all that apply.)
</p>
</div>

<div id="outline-container-orgheadline51" class="outline-4">
<h4 id="orgheadline51"><span class="section-number-4">2.3.1</span> Download the data sets</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
In this part we can download the data
</p>

<div class="org-src-container">

<pre class="src src-R"><span style="color: #db7093;">library</span>(parallel)

<span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #ff6a6a;">"../data"</span>)) {
        dir.create(<span style="color: #ff6a6a;">"../data"</span>)
}

fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/ClaimsData.csv.zip"</span>

fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"ClaimsData.csv.zip"</span>

dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"../data"</span>

filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #ff6a6a;">"/"</span>)

<span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = <span style="color: #ff6a6a;">"curl"</span>)
}

list.files(<span style="color: #ff6a6a;">"../data"</span>)
</pre>
</div>

<pre class="example">
 [1] "AirlinesCluster.csv"       "AnonymityPoll.csv"
 [3] "baseball.csv"              "BoeingStock.csv"
 [5] "boston.csv"                "ClaimsData.csv"
 [7] "ClaimsData.csv.zip"        "climate_change.csv"
 [9] "clinical_trial.csv"        "ClusterMeans.ods"
[11] "CocaColaStock.csv"         "CountryCodes.csv"
[13] "CPSData.csv"               "dailykos.csv"
[15] "eBayAll.RData"             "eBayiPadTest.csv"
[17] "eBayiPadTrain.csv"         "edges.csv"
[19] "emails.csv"                "energy_bids.csv"
[21] "federalFundsRate.csv"      "finalExam-Households.csv"
[23] "flower.csv"                "FluTest.csv"
[25] "FluTrain.csv"              "framingham.csv"
[27] "gerber.csv"                "GEStock.csv"
[29] "healthy.csv"               "households.csv"
[31] "IBMStock.csv"              "intl.csv"
[33] "intlall.csv"               "loans_imputed.csv"
[35] "loans.csv"                 "MetroAreaCodes.csv"
[37] "movieLens.txt"             "MoviesP1Final.csv"
[39] "murders.csv"               "mvt.csv"
[41] "mvtWeek1.csv"              "NBA_test.csv"
[43] "NBA_train.csv"             "parole.csv"
[45] "pisa2009test.csv"          "pisa2009train.csv"
[47] "PollingData_Imputed.csv"   "PollingData.csv"
[49] "PollingImputed.csv"        "ProcterGambleStock.csv"
[51] "quality.csv"               "README.md"
[53] "SampleSubmission.csv"      "songs.csv"
[55] "stevens.csv"               "StocksCluster.csv"
[57] "stopwords.txt"             "SubmissionGBM1.csv"
[59] "SubmissionGBM2.csv"        "SubmissionLR2.csv"
[61] "SubmissionLR3.csv"         "SubmissionLR4.csv"
[63] "SubmissionLR5.csv"         "SubmissionLR8.csv"
[65] "SubmissionLR9.csv"         "SubmissionRF1.csv"
[67] "SubmissionSimpleLogV1.csv" "tumor.csv"
[69] "tweets.csv"                "tweetsU7.csv"
[71] "USDA.csv"                  "users.csv"
[73] "WHO_Europe.csv"            "WHO.csv"
[75] "WHOu7.csv"                 "wiki.csv"
[77] "wine_test.csv"             "wine.csv"
</pre>
</div>
</div>

<div id="outline-container-orgheadline53" class="outline-4">
<h4 id="orgheadline53"><span class="section-number-4">2.3.2</span> Load the data set</h4>
<div class="outline-text-4" id="text-2-3-2">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"    Loading data into their data frames."</span>)
Claims <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #ff6a6a;">"../data/ClaimsData.csv"</span>, sep = <span style="color: #ff6a6a;">","</span>, header = <span style="color: #3cb371;">TRUE</span>)
</pre>
</div>

<pre class="example">
Loading data into their data frames.
</pre>
</div>

<div id="outline-container-orgheadline52" class="outline-5">
<h5 id="orgheadline52"><span class="section-number-5">2.3.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-3-2-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Blood test results</li>

<li class="off"><code>[&#xa0;]</code> Drugs prescribed to the patient</li>

<li class="on"><code>[X]</code> Physical exam results (weight, height, blood pressure, etc.)</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
In claims data, we have drugs prescribed to the patient, but we don't
have blood test results or physical exam results.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline55" class="outline-3">
<h3 id="orgheadline55"><span class="section-number-3">2.4</span> Video 3: The Variables</h3>
<div class="outline-text-3" id="text-2-4">
<p>
To build an analytics model, let us discuss the variables we
used. First, we used the 13,000 diagnoses. It's for the codes for
diagnosis that claims data utilize.
</p>

<p>
There were also 22,000 different codes for procedures and 45,000 codes
for prescription drugs. To work with this massive amount of variables,
we aggregated the variables as follows.
</p>

<p>
Out of the 13,000 diagnoses, we defined 217 diagnosis groups. Out of
the 20,000 procedures, we aggregated the data to develop 213 procedure
groups. And, finally, from 45,000 prescription drugs, we developed 189
therapeutic groups.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ClaimsData04.png" alt="D2HE-ClaimsData04.png" />
</p>
</div>

<p>
To illustrate an example of how we infer further information from the
data, the graph here shows on the horizontal axis, time, and on the
vertical axis, costs in thousands of dollars.
</p>

<p>
So patient one is a patient who, on a monthly basis, has costs on the
order of $10,000 to $15,000, a fairly significant cost but fairly
constant in time. Patient two has also an annual cost of a similar
size to patient one.
</p>

<p>
But in all but the third month, the costs are almost $0. Whereas in
the third month, it cost about $70,000. In fact, this is additional
data we defined indicating whether the patient has a chronic or an
acute condition.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Variables.png" alt="D2HE-Variables.png" />
</p>
</div>

<p>
In addition to the initial variables, the 217 procedure groups, and
189 drugs, and so forth, we also defined in collaboration with medical
doctors, 269 medically-defined rules.
</p>

<p>
For example, the first type of rule indicates the interaction between
various illnesses. For example, obesity and depression. Then new
variables regarding interaction between diagnosis and age. For
example, more than 65 years old and coronary artery disease.
</p>

<p>
Noncompliance with treatment. For example, non-fulfillment of a
particular drug order. And, finally, illness severity. For example,
severe depression as opposed to regular depression.
</p>

<p>
And the last set of variables involve demographic information like
gender and age.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Variables02.png" alt="D2HE-Variables02.png" />
</p>
</div>

<p>
An important aspect of the variables are the variables related to
cost. So rather than using costs directly, we bucketed costs and
considered everyone in the group equally.
</p>

<p>
So we defined five buckets. So the buckets were partitioned in such a
way so that 20% of all costs is in bucket five, 20% is in bucket four,
and so forth. So the partitions were from 0 to 3,000, from 3,000 to
8,000, from 8,000 to 19,000, from 19,000 to 55,000, and above 55,000.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-CostVariables00.png" alt="D2HE-CostVariables00.png" />
</p>
</div>

<p>
The number of patients that were below 3,000 was&#x2013; 78% of the patients
had costs below 3,000. Just to remind you, we created a bucket so that
the total cost in each bucket was 20% of the total. But the number of
patients in bucket one, for example, is very high (78%).
</p>


<div class="figure">
<p><img src="../graphs/D2HE-CostVariables.png" alt="D2HE-CostVariables.png" />
</p>
</div>

<p>
Let us interpret the buckets medically. So this shows the various
levels of risk. Bucket one consists of patients that have rather low
risk. Bucket two has what is called emerging risk. In bucket three,
moderate level of risk. Bucket four, high risk. And bucket five, very
high risk.
</p>

<p>
So from a medical perspective, buckets two and three, the medical and
the moderate risk patients, are candidates for wellness
programs. Whereas bucket four, the high risk patients, are candidates
for disease management programs. And finally bucket five, the very
high risk patients, are candidates for case management.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-MInterpretation.png" alt="D2HE-MInterpretation.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline57" class="outline-3">
<h3 id="orgheadline57"><span class="section-number-3">2.5</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-5">
<p>
While we don't have all of the data we would ideally like to have in
this problem (like test results), we can define new variables using
the data we do have. Which of the following were new variables defined
to help predict healthcare cost? Select all that apply.
</p>

<ul class="org-ul">
<li class="on"><code>[X]</code> Variables to capture chronic conditions</li>

<li class="on"><code>[X]</code> Noncompliance to treatment</li>

<li class="on"><code>[X]</code> Illness severity</li>

<li class="on"><code>[X]</code> Interactions between illnesses</li>
</ul>
</div>

<div id="outline-container-orgheadline56" class="outline-4">
<h4 id="orgheadline56"><span class="section-number-4">2.5.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
<b>Explanation</b>
</p>

<p>
All of these variables were defined using the claims data to improve
cost predictions. This shows how the intuition of experts can be used
to define new variables and improve the model.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline58" class="outline-3">
<h3 id="orgheadline58"><span class="section-number-3">2.6</span> Video 4: Error Measures</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Let us introduce the error measures we used in building the analytics
models.
</p>

<p>
Next measure, the so-called <b>penalty error</b>, is motivated by the fact
that if you classify a very high-risk patient as a low-risk patient,
this is more costly than the reverse, namely classifying a low-risk
patient as a very high-risk patient. Motivated by this, we developed a
penalty error.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ErrorMeasures.png" alt="D2HE-ErrorMeasures.png" />
</p>
</div>

<p>
And the idea is to use asymmetric penalties. The graph here&#x2013; shows a
matrix&#x2013; where this is the outcome and this is the forecast.
</p>

<p>
For example, whenever we classify a low-risk patient as high-risk, we
pay a penalty of 2, which is a difference of 3 minus 1, the difference
in the error. But inversely, when you classify a bucket 3 patient as
bucket 1 patient, this is double.
</p>

<p>
The cost&#x2013; the penalty&#x2013; is double the amount. So you observe that the
off diagonal penalties are double the corresponding penalties in the
lower diagonal.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-PenaltyError.png" alt="D2HE-PenaltyError.png" />
</p>
</div>

<p>
To judge the quality of the analytics models we developed, we compare
it with a baseline. And the baseline is to simply predict that the
cost in the next "period" will be the cost in the current period.
</p>

<p>
We have observed that as far as identification of buckets is
concerned, the accuracy was \(75\%\). So namely, whenever we predict that
the risk is bucket 3&#x2013; indeed it is bucket 3&#x2013; this happens \(75\%\) of
the time, and the penalty error&#x2013; the average penalty error of the
baseline&#x2013; was \(0.56\).
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Baseline.png" alt="D2HE-Baseline.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline63" class="outline-3">
<h3 id="orgheadline63"><span class="section-number-3">2.7</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-2-7">
<p>
The image below shows the penalty error matrix that we discussed in
the previous video.
</p>


<div class="figure">
<p><img src="../graphs/QQ4_PenaltyError.png" alt="QQ4_PenaltyError.png" />
</p>
</div>

<p>
We can interpret this matrix as follows. Suppose the actual outcome
for an observation is 3, and we predict 2. We find 3 on the top of the
matrix, and go down to the second row (since we forecasted 2). The
penalty error for this mistake is 2. If for another observation we
predict (forecast) 4, but the actual outcome is 1, that is a penalty
error of 3.
</p>
</div>

<div id="outline-container-orgheadline60" class="outline-4">
<h4 id="orgheadline60"><span class="section-number-4">2.7.1</span> Question a</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
What is the worst mistake we can make, according to the penalty error
matrix?
</p>
</div>

<div id="outline-container-orgheadline59" class="outline-5">
<h5 id="orgheadline59"><span class="section-number-5">2.7.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-7-1-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> We predict 5 (very high cost), but the actual outcome is 1 (very
low cost).</li>

<li class="on"><code>[X]</code> We predict 1 (very low cost), but the actual outcome is 5 (very
high cost).</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The highest cost is 8, which occurs when the forecast is 1 (very low
cost), but the actual cost is 5 (very high cost). It would be much
worse for us to ignore an actual high cost observation than to
accidentally predict high cost for someone who turns out to be low
cost.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline62" class="outline-4">
<h4 id="orgheadline62"><span class="section-number-4">2.7.2</span> Question b</h4>
<div class="outline-text-4" id="text-2-7-2">
<p>
What are the "best" types of mistakes we can make, according to the
penalty error matrix?
</p>
</div>

<div id="outline-container-orgheadline61" class="outline-5">
<h5 id="orgheadline61"><span class="section-number-5">2.7.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-7-2-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Mistakes where we predict one cost bucket HIGHER than the actual
outcome.</li>

<li class="off"><code>[&#xa0;]</code> Mistakes where we predict one cost bucket LOWER than the actual
outcome.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
We are happier with mistakes where we predict one cost bucket higher
than the actual outcome, since this just means we are being a little
overly cautious.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline64" class="outline-3">
<h3 id="orgheadline64"><span class="section-number-3">2.8</span> Video 5: CART to Predict Cost</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Let us introduce the method we used for predicting the bucket
number. It is called&#x2013; it is a method called classification and
regression trees.
</p>

<p>
In this case, we use multi-class classification. There are five
classes, buckets one to five. To give you an example, let us consider
patients that have two types of diagnosis:
</p>

<ul class="org-ul">
<li>coronary artery disease and diabetes.</li>

<li>So if a patient does not have a coronary artery disease, we'd
classify the patient as bucket one.</li>

<li>If it has coronary artery disease, then we check whether the person
has diabetes or doesn't have diabetes.

<ul class="org-ul">
<li>If it has diabetes, then it's bucket five, very high risk.</li>

<li>And if it doesn't have diabetes, but given it has coronary
artery disease, it is classified as bucket three.</li>
</ul></li>
</ul>


<div class="figure">
<p><img src="../graphs/D2HE-MultiClass Classification.png" alt="D2HE-MultiClass Classification.png" />
</p>
</div>

<p>
So this is an example in which we only have two diagnoses and we will
state how the method works.
</p>

<p>
In the application of Hawkeye, the most important factors were related
to cost in the beginning. So in the beginning, the classification tree
involved divisions based on cost.
</p>

<p>
For example,
</p>

<ul class="org-ul">
<li>if the patient had paid less than $4,000&#x2013; so this is bucket one
classification</li>

<li>if it paid more than $4,000, then we further investigate whether the
patient pays less than $40,000 or more than $40,000 and so forth.</li>
</ul>


<div class="figure">
<p><img src="../graphs/D2HE-ImportantFactors.png" alt="D2HE-ImportantFactors.png" />
</p>
</div>

<p>
As the tree grows, then the secondary factor is utilized later in the
classification tree involve various chronic illnesses and some of the
medical rules we discussed earlier.
</p>

<p>
For example,
</p>

<ul class="org-ul">
<li>whether or not the patient has asthma and depression or not (Q146).</li>

<li>If it has asthma and depression, then it's bucket five.</li>

<li>If it doesn't, then we consider a particular indicator indicating
hylan injection, which is an indication of a possible knee
replacement or arthroscopy. So if this indicator is equal to 1, then
it's bucket three.</li>

<li>If it's indicator is equal to 0, it's not present, then it's bucket
one.</li>
</ul>

<p>
So let us give some examples of bucket five.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-SecondaryFactors.png" alt="D2HE-SecondaryFactors.png" />
</p>
</div>

<p>
So let us give some examples of bucket five.
</p>

<ul class="org-ul">
<li>So an example is as follows. The patient is under 35 years old, he
has between 3,300 and 3,900 in claims, coronary artery disease as a
diagnosis, but no office visits in the last year.</li>

<li>Another example of a category of a patient that is classified as
bucket five are claims between $3,900 and $43,000 with at least
$8,000 paid in the last 12 months, $4,300 in pharmacy claims, and
acute cost profile and cancer diagnosis.</li>

<li>And another final example is more than $58,000 in claims, but at
least $50,000 paid in the last 12 months, but not an acute profile.</li>
</ul>

<p>
Classification trees have the major advantage as being interpretable
by the physicians who observe them and judge them.
</p>

<p>
In other words, people were able to identify these cases as
reasonable. In other words, the human intuition agreed with the output
of the analytics model.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-ExampleBuck5.png" alt="D2HE-ExampleBuck5.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline66" class="outline-3">
<h3 id="orgheadline66"><span class="section-number-3">2.9</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-9">
<p>
What were the most important factors in the CART trees to predict
cost?
</p>
</div>

<div id="outline-container-orgheadline65" class="outline-4">
<h4 id="orgheadline65"><span class="section-number-4">2.9.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-9-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Cost ranges from the previous year</li>

<li class="off"><code>[&#xa0;]</code> Risk factors</li>

<li class="off"><code>[&#xa0;]</code> Chronic conditions</li>

<li class="off"><code>[&#xa0;]</code> Number of office visits last year</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The most important variables in a CART tree are at the top of the
tree - in this case, they are the cost ranges from the previous year.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline67" class="outline-3">
<h3 id="orgheadline67"><span class="section-number-3">2.10</span> Video 6: Claims Data in R</h3>
<div class="outline-text-3" id="text-2-10">
<p>
In the next few videos, we'll be using the dataset
<a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/ClaimsData.csv.zip">ClaimsData.csv.zip</a>. Please download the dataset to follow along. Note
that this file is in ZIP format due to its large size. You will need to
decompress (or unzip) the file before loading it into R.
</p>

<p>
This data comes from the <a href="http://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DE_Syn_PUF.html">DE-SynPUF dataset</a>, published by the United
States Centers for Medicare and Medicaid Services (CMS).
</p>

<p>
An R script file with all of the R commands used in this lecture can
be downloaded <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/Unit4_D2Hawkeye.R">here</a>.
</p>

<p>
We'll be using a data set published by the United States Centers for
Medicare and Medicaid Services to practice creating CART models to
predict health care cost. We unfortunately can't use the D2Hawkeye
data due to privacy issues.
</p>

<p>
The data set we'll be using instead, ClaimsData.csv, is structured to
represent a sample of patients in the Medicare program, which provides
health insurance to Americans aged 65 and older, as well as some
younger people with certain medical conditions.
</p>

<p>
To protect the privacy of patients represented in this publicly
available data set, a number of steps are performed to anonymize the
data. So we would need to retrain the models we develop in this
lecture on de-anonymized data if we wanted to apply our models in the
real world.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The summary of the claims data set:"</span>)
str(Claims)
</pre>
</div>

<pre class="example">
 :: The summary of the claims data set:
'data.frame':	458005 obs. of  16 variables:
 $ age              : int  85 59 67 52 67 68 75 70 67 67 ...
 $ alzheimers       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ arthritis        : int  0 0 0 0 0 0 0 0 0 0 ...
 $ cancer           : int  0 0 0 0 0 0 0 0 0 0 ...
 $ copd             : int  0 0 0 0 0 0 0 0 0 0 ...
 $ depression       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ diabetes         : int  0 0 0 0 0 0 0 0 0 0 ...
 $ heart.failure    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ ihd              : int  0 0 0 0 0 0 0 0 0 0 ...
 $ kidney           : int  0 0 0 0 0 0 0 0 0 0 ...
 $ osteoporosis     : int  0 0 0 0 0 0 0 0 0 0 ...
 $ stroke           : int  0 0 0 0 0 0 0 0 0 0 ...
 $ reimbursement2008: int  0 0 0 0 0 0 0 0 0 0 ...
 $ bucket2008       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ reimbursement2009: int  0 0 0 0 0 0 0 0 0 0 ...
 $ bucket2009       : int  1 1 1 1 1 1 1 1 1 1 ...
</pre>

<p>
The observations represent a \(1\%\) random sample of Medicare
beneficiaries, limited to those still alive at the end of 2008.
</p>

<p>
Our independent variables are from 2008, and we will be predicting
cost in 2009. Our independent variables are the patient's age in years
at the end of 2008, and then several binary variables indicating
whether or not the patient had diagnosis codes for a particular
disease or related disorder in 2008: alzheimers, arthritis, cancer,
chronic obstructive pulmonary disease, or copd, depression, diabetes,
heart.failure, ischemic heart disease, or ihd, kidney disease,
osteoporosis, and stroke.
</p>

<p>
Each of these variables will take value \(1\) if the patient had a
diagnosis code for the particular disease and value \(0\) otherwise.
</p>

<p>
<b>Reimbursement2008</b> is the total amount of Medicare reimbursements for
this patient in 2008. And <b>reimbursement2009</b> is the total value of all
Medicare reimbursements for the patient in 2009. <b>bucket2008</b> is the
cost bucket the patient fell into in 2008, and <b>bucket2009</b> is the cost
bucket the patient fell into in 2009.
</p>

<p>
These cost buckets are defined using the thresholds determined by
D2Hawkeye.
</p>

<p>
So the first cost bucket contains patients with costs less than
$3,000, the second cost bucket contains patients with costs between
$3,000 and $8,000, and so on.
</p>

<p>
We can verify that the number of patients in each cost bucket has the
same structure as what we saw for D2Hawkeye by computing the
percentage of patients in each cost bucket.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Percentage of patients in each cost bucket:"</span>)
table(Claims$bucket2009)/nrow(Claims)
</pre>
</div>

<pre class="example">
 :: Percentage of patients in each cost bucket:

          1           2           3           4           5
0.671267781 0.190170413 0.089466272 0.043324855 0.005770679
</pre>

<p>
The first cost bucket has almost 70% of the patients. The second cost
bucket has about 20% of the patients. And the remaining 10% are split
between the final three cost buckets.
</p>

<p>
<b>So the vast majority of patients in this data set have low cost</b>.
</p>

<p>
Our goal will be to predict the cost bucket the patient fell into in
2009 using a CART model.
</p>

<p>
But before we build our model, we need to split our data into a
training set and a testing set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Split the data..."</span>)
<span style="color: #db7093;">library</span>(caTools)
set.seed(88)

spl <span style="color: #db7093;">&lt;-</span> sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain <span style="color: #db7093;">&lt;-</span> subset(Claims, spl==<span style="color: #3cb371;">TRUE</span>)
ClaimsTest <span style="color: #db7093;">&lt;-</span> subset(Claims, spl==<span style="color: #3cb371;">FALSE</span>)

writeLines(<span style="color: #ff6a6a;">"\n :: Dimensions of the training set:"</span>)
dim(ClaimsTrain)

writeLines(<span style="color: #ff6a6a;">"\n :: Dimensions of the testing set:"</span>)
dim(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: Split the data...

 :: Dimensions of the training set:
[1] 274803     16

 :: Dimensions of the testing set:
[1] 183202     16
</pre>
</div>
</div>

<div id="outline-container-orgheadline72" class="outline-3">
<h3 id="orgheadline72"><span class="section-number-3">2.11</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-2-11">
</div><div id="outline-container-orgheadline69" class="outline-4">
<h4 id="orgheadline69"><span class="section-number-4">2.11.1</span> Question</h4>
<div class="outline-text-4" id="text-2-11-1">
<p>
What is the average age of patients in the training set, <b>ClaimsTrain</b>?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The average age of the training set is:"</span>)
mean(ClaimsTrain$age)
</pre>
</div>

<pre class="example">
 :: The average age of the training set is:
[1] 72.63773
</pre>
</div>

<div id="outline-container-orgheadline68" class="outline-5">
<h5 id="orgheadline68"><span class="section-number-5">2.11.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-11-1-1">
<p>
The average age of the training set is:
72.63773
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline71" class="outline-4">
<h4 id="orgheadline71"><span class="section-number-4">2.11.2</span> Question</h4>
<div class="outline-text-4" id="text-2-11-2">
<p>
What proportion of people in the training set (ClaimsTrain) had at
least one diagnosis code for diabetes?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The proportion of patients that have equal or more than a diabetes code:"</span>)
nrow(ClaimsTrain[ClaimsTrain$diabetes == 1, ]) / nrow(ClaimsTrain)
</pre>
</div>

<pre class="example">
 :: The proportion of patients that have equal or more than a diabetes code:
[1] 0.3808983
</pre>
</div>

<div id="outline-container-orgheadline70" class="outline-5">
<h5 id="orgheadline70"><span class="section-number-5">2.11.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-11-2-1">
<p>
The proportion of patients that have equal or more than a diabetes code:
0.3808983
</p>

<p>
<b>Explanation</b>
</p>

<p>
Both of these answers can be found by looking at
summary(ClaimsTrain). The mean age should be listed under the age
variable, and since diabetes is a binary variable, the mean value of
diabetes gives the proportion of people with at least one diagnosis
code for diabetes.
</p>

<p>
Alternatively, you could use the mean, table, and nrow functions:
</p>

<p>
<code>mean(ClaimsTrain$age)</code>
</p>

<p>
<code>table(ClaimsTrain$diabetes)/nrow(ClaimsTrain)</code>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline73" class="outline-3">
<h3 id="orgheadline73"><span class="section-number-3">2.12</span> Video 7: Baseline Method and Penalty Matrix</h3>
<div class="outline-text-3" id="text-2-12">
<p>
Let's now see how the baseline method used by D2Hawkeye would perform
on this data set. The baseline method would predict that the cost
bucket for a patient in 2009 will be the same as it was in 2008.
</p>

<p>
So let's create a classification matrix to compute the accuracy for
the baseline method on the test set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Baseline method:"</span>)
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)

writeLines(<span style="color: #ff6a6a;">"\n :: Baseline accuracy:"</span>)
(110138 + 10721 + 2774 + 1539 + 104)/nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: Baseline method:

         1      2      3      4      5
  1 110138   7787   3427   1452    174
  2  16000  10721   4629   2931    559
  3   7006   4629   2774   1621    360
  4   2688   1943   1415   1539    352
  5    293    191    160    309    104

 :: Baseline accuracy:
[1] 0.6838135
</pre>

<p>
The accuracy is the sum of the diagonal, the observations that were
classified correctly, divided by the total number of observations in
our test set.
</p>

<p>
So the accuracy of the baseline method is \(0.68\). Now how about the
penalty error?
</p>

<p>
To compute this, we need to first create a penalty matrix in R. Keep
in mind that we'll put the actual outcomes on the left, and the
predicted outcomes on the top.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Penalty Matrix:"</span>)
PenaltyMatrix <span style="color: #db7093;">&lt;-</span> matrix(c(0, 1, 2, 3, 4, 2, 0, 1, 2, 3, 4, 2, 0, 1, 2,
                         6, 4, 2, 0, 1, 8, 6, 4, 2, 0), byrow = <span style="color: #3cb371;">TRUE</span>,
                       nrow = 5)
PenaltyMatrix
</pre>
</div>

<pre class="example">
 :: Penalty Matrix:
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    1    2    3    4
[2,]    2    0    1    2    3
[3,]    4    2    0    1    2
[4,]    6    4    2    0    1
[5,]    8    6    4    2    0
</pre>

<p>
The actual outcomes are on the left, and the predicted outcomes are on
the top. So as we saw in the slides, the worst outcomes are when we
predict a low cost bucket, but the actual outcome is a high cost
bucket.
</p>

<p>
We still give ourselves a penalty when we predict a high cost bucket
and it's actually a low cost bucket, but it's not as bad.
</p>

<p>
So now to compute the penalty error of the baseline method, we can
multiply our classification matrix by the penalty matrix.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Penalty Error of Baseline Method:"</span>)
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix
</pre>
</div>

<pre class="example">
:: Penalty Error of Baseline Method:

       1     2     3     4     5
 1     0  7787  6854  4356   696
 2 32000     0  4629  5862  1677
 3 28024  9258     0  1621   720
 4 16128  7772  2830     0   352
 5  2344  1146   640   618     0
</pre>

<p>
So what this does is it takes each number in the classification matrix
and multiplies it by the corresponding number in the penalty matrix.
</p>

<p>
So now to compute the <b>penalty error</b>, we just need to sum it up and
divide by the number of observations in our test set.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Overall accuracy of the baseline model:"</span>)
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix)/nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: Overall accuracy of the baseline model:
[1] 0.7386055
</pre>

<p>
Our goal will be to create a CART model that has an <b>accuracy higher</b>
than \(68\%\) and a <b>penalty error</b> lower than \(0.74\).
</p>
</div>
</div>

<div id="outline-container-orgheadline77" class="outline-3">
<h3 id="orgheadline77"><span class="section-number-3">2.13</span> Quick Question (2 points possible)</h3>
<div class="outline-text-3" id="text-2-13">
<p>
Suppose that instead of the baseline method discussed in the previous
video, we used the baseline method of predicting the most frequent
outcome for all observations. This new baseline method would predict
cost bucket 1 for everyone.
</p>
</div>

<div id="outline-container-orgheadline75" class="outline-4">
<h4 id="orgheadline75"><span class="section-number-4">2.13.1</span> Question a</h4>
<div class="outline-text-4" id="text-2-13-1">
<p>
What would the accuracy of this baseline method be on the test set?
</p>
</div>

<div id="outline-container-orgheadline74" class="outline-5">
<h5 id="orgheadline74"><span class="section-number-5">2.13.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-13-1-1">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The baseline accuracy is:"</span>)
table(ClaimsTest$bucket2009)[1] / nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: The baseline accuracy is:
      1
0.67127
</pre>
</div>
</div>
</div>

<div id="outline-container-orgheadline76" class="outline-4">
<h4 id="orgheadline76"><span class="section-number-4">2.13.2</span> Question b</h4>
<div class="outline-text-4" id="text-2-13-2">
<p>
What would the penalty error of this baseline method be on the test
set?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Penalty Matrix:"</span>)
PenaltyMatrix2 <span style="color: #db7093;">&lt;-</span> c(0, 2, 4, 6, 8)
PenaltyMatrix2

writeLines(<span style="color: #ff6a6a;">"\n :: The penalty error for the Naive Baseline model:"</span>)
sum(as.matrix(table(ClaimsTest$bucket2009)) * PenaltyMatrix2) / nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: Penalty Matrix:
[1] 0 2 4 6 8

 :: The penalty error for the Naive Baseline model:
[1] 1.044301
</pre>

<p>
<b>Explanation</b>
</p>

<p>
To compute the accuracy, you can create a table of the variable
ClaimsTest$bucket2009:
</p>

<p>
<code>table(ClaimsTest$bucket2009)</code>
</p>

<p>
According to the table output, this baseline method would get 122978
observations correct, and all other observations wrong. So the
accuracy of this baseline method is
</p>

<p>
<code>122978/nrow(ClaimsTest) = 0.67127</code>.
</p>

<p>
For the penalty error, since this baseline method predicts 1 for all
observations, it would have a penalty error of:
</p>

<p>
<code>(0*122978 + 2*34840 + 4*16390 + 6*7937 + 8*1057)/nrow(ClaimsTest) = 1.044301</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline78" class="outline-3">
<h3 id="orgheadline78"><span class="section-number-3">2.14</span> Video 8: Predicting Healthcare Costs in R</h3>
<div class="outline-text-3" id="text-2-14">
<p>
We'll build a CART model to predict healthcare cost.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Load necessary libraries..."</span>)
<span style="color: #db7093;">library</span>(rpart)
<span style="color: #db7093;">library</span>(rpart.plot)
</pre>
</div>

<pre class="example">
:: Load necessary libraries...
</pre>

<p>
Now, let's build our CART model.
</p>

<p>
We'll call it <b>ClaimsTree</b>. And we'll use the <b>rpart</b> function to
predict <b>bucket2009</b>, using as independent variables: age, arthritis,
alzheimers, cancer, copd, depression, diabetes, heart.failure, ihd,
kidney, osteoporosis, and stroke. We'll also use bucket2008 and
reimbursement2008.
</p>

<p>
The data set we'll use to build our model is <b>ClaimsTrain</b>. And then
we'll add the arguments, method = "class", since we have a
classification problem here, and cp = 0.00005.
</p>

<p>
Note that even though we have a multi-class classification problem
here, we build our tree in the same way as a binary classification
problem.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: CART model:"</span>)
ClaimsTree <span style="color: #db7093;">&lt;-</span> rpart(bucket2009 ~ age + alzheimers + arthritis + cancer +
                    copd + depression + diabetes + heart.failure +
                              ihd + kidney + osteoporosis + stroke +
                              bucket2008 + reimbursement2008,
                    data = ClaimsTrain, method = <span style="color: #ff6a6a;">"class"</span>, cp = 0.00005)
</pre>
</div>

<pre class="example">
:: CART model:
</pre>

<p>
The cp value we're using here was selected through cross-validation on
the training set. We won't perform the cross-validation here, because
it takes a significant amount of time on a data set of this size.
</p>

<p>
Remember that we have almost 275,000 observations in our training
set.
</p>

<p>
But keep in mind that the R commands needed for cross-validation here
are the same as those used in the previous lecture on predicting
Supreme Court decisions.
</p>


<div id="orgparagraph6" class="figure">
<p><img src="../graphs/ClaimsCartModel.png" alt="ClaimsCartModel.png" />
</p>
<p><span class="figure-number">Figure 63:</span> CART model for the Quality Health Care Analysis</p>
</div>

<p>
It might take a while to load, because we have a huge tree here. This
makes sense for a few reasons. One is the large number of observations
in our training set.
</p>

<p>
Another is that we have a five-class classification problem, so the
classification is more complex than a binary classification case, like
the one we saw in the previous lecture.
</p>

<p>
The trees used by D2Hawkeye were also very large CART trees. While
this hurts the interpretability of the model, it's still possible to
describe each of the buckets of the tree according to the splits.
</p>

<p>
We'll call our predictions PredictTest, where we'll use the predict
function for our model.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions:"</span>)
PredictTest <span style="color: #db7093;">&lt;-</span> predict(ClaimsTree, newdata = ClaimsTest, type = <span style="color: #ff6a6a;">"class"</span>)

writeLines(<span style="color: #ff6a6a;">"\n :: Building the confusion matrix for the testing set:"</span>)
table(ClaimsTest$bucket2009, PredictTest)

writeLines(<span style="color: #ff6a6a;">"\n :: Calculate the overall accuracy for the testing set:"</span>)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: Make predictions:

 :: Building the confusion matrix for the testing set:
   PredictTest
         1      2      3      4      5
  1 114141   8610    124    103      0
  2  18409  16102    187    142      0
  3   8027   8146    118     99      0
  4   3099   4584     53    201      0
  5    351    657      4     45      0

 :: Calculate the overall accuracy for the testing set:
[1] 0.7126669
</pre>

<p>
So the accuracy of our model is 0.713.
</p>

<p>
For the penalty error, we can use our penalty matrix like we did in
the previous video.
</p>

<div class="org-src-container">

<pre class="src src-R">as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix

writeLines(<span style="color: #ff6a6a;">"\n :: The testing set penalty error:"</span>)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
   PredictTest
        1     2     3     4     5
  1     0  8610   248   309     0
  2 36818     0   187   284     0
  3 32108 16292     0    99     0
  4 18594 18336   106     0     0
  5  2808  3942    16    90     0

 :: The testing set penalty error:
[1] 0.7578902
</pre>

<p>
So our penalty error is \(0.758\). In the previous video, we saw that our
baseline method had an accuracy of \(68\%\) and a penalty error of \(0.74\). So
while we increased the accuracy, the penalty error also went up. Why?
</p>

<p>
By default, rpart will try to maximize the overall accuracy, and every
type of error is seen as having a penalty of one.
</p>

<p>
Our CART model predicts 3, 4, and 5 so rarely because there are very
few observations in these classes. So we don't really expect this
model to do better on the penalty error than the baseline method.
</p>

<p>
So how can we fix this? The rpart function allows us to specify a
parameter called <b>loss</b>. This is the penalty matrix we want to use
when building our model.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: New CART model with loss matrix:"</span>)
ClaimsTree <span style="color: #db7093;">&lt;-</span> rpart(bucket2009 ~ age + alzheimers + arthritis + cancer +
                   copd + depression + diabetes + heart.failure +
                             ihd + kidney + osteoporosis + stroke +
                             bucket2008 + reimbursement2008,
                   data = ClaimsTrain, method = <span style="color: #ff6a6a;">"class"</span>, cp = 0.00005,
                   parms = list(loss = PenaltyMatrix))
</pre>
</div>

<pre class="example">
:: New CART model with loss matrix:
</pre>

<p>
So while our model is being built, let's think about what we expect to
happen. If the rpart function knows that we'll be giving a higher
penalty to some types of errors over others, it might choose different
splits when building the model to minimize the worst types of errors.
</p>

<p>
We'll probably get a lower overall accuracy with this new model. But
hopefully, the penalty error will be much lower too.
</p>

<p>
So now that our model is done, let's regenerate our test set
predictions.
</p>

<div class="org-src-container">

<pre class="src src-R"><span style="color: #9932cc;"># </span><span style="color: #ba55d3;">Redo predictions and penalty error</span>
PredictTest <span style="color: #db7093;">&lt;-</span> predict(ClaimsTree, newdata = ClaimsTest, type = <span style="color: #ff6a6a;">"class"</span>)

writeLines(<span style="color: #ff6a6a;">"\n :: The classification matrix is:"</span>)
table(ClaimsTest$bucket2009, PredictTest)

writeLines(<span style="color: #ff6a6a;">"\n :: The overall accuracy is:"</span>)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)

writeLines(<span style="color: #ff6a6a;">"\n :: The penalty error is:"</span>)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
</pre>
</div>

<pre class="example">
 :: The classification matrix is:
   PredictTest
        1     2     3     4     5
  1 94310 25295  3087   286     0
  2  7176 18942  8079   643     0
  3  3590  7706  4692   401     1
  4  1304  3193  2803   636     1
  5   135   356   408   156     2

 :: The overall accuracy is:
[1] 0.6472746

 :: The penalty error is:
[1] 0.6418161
</pre>

<p>
Our accuracy is now lower than the baseline method, but our penalty
error is also much lower. Note that we have significantly fewer
independent variables than D2Hawkeye had.
</p>

<p>
Note that we have significantly fewer independent variables than
D2Hawkeye had. If we had the hundreds of codes and risk factors
available to D2Hawkeye, we would hopefully do even better.
</p>
</div>
</div>

<div id="outline-container-orgheadline79" class="outline-3">
<h3 id="orgheadline79"><span class="section-number-3">2.15</span> Quick Question (1 point possible)</h3>
<div class="outline-text-3" id="text-2-15">
<p>
In the previous video, we constructed two CART models. The first CART
model, without the loss matrix, predicted bucket 1 for \(78.6\%\) of the
observations in the test set. Did the second CART model, with the loss
matrix, predict bucket 1 for more or fewer of the observations, and
why?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The penalty matrix:"</span>)
PenaltyMatrix
</pre>
</div>

<pre class="example">
 :: The penalty matrix:
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    1    2    3    4
[2,]    2    0    1    2    3
[3,]    4    2    0    1    2
[4,]    6    4    2    0    1
[5,]    8    6    4    2    0
</pre>

<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> According to the penalty matrix, some of the worst types of
errors are to not predict bucket 1 when the actual cost bucket is
bucket 1. Therefore, the model with the penalty matrix predicted
bucket 1 more frequently.</li>

<li class="off"><code>[&#xa0;]</code> According to the penalty matrix, some of the worst types of
errors are to predict bucket 1 when the actual cost bucket is
higher. Therefore, the model with the penalty matrix predicted
bucket 1 more frequently.</li>

<li class="off"><code>[&#xa0;]</code> According to the penalty matrix, some of the worst types of
errors are to not predict bucket 1 when the actual cost bucket is
bucket 1. Therefore, the model with the penalty matrix predicted
bucket 1 less frequently.</li>

<li class="on"><code>[X]</code> According to the penalty matrix, some of the worst types of
errors are to predict bucket 1 when the actual cost bucket is
higher. Therefore, the model with the penalty matrix predicted
bucket 1 less frequently.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
If you look at the classification matrix for the second CART model, we
predicted bucket 1 less frequently. This is because, according to the
penalty matrix, some of the worst types of errors are to predict
bucket 1 when the actual cost bucket is higher.
</p>
</div>
</div>

<div id="outline-container-orgheadline80" class="outline-3">
<h3 id="orgheadline80"><span class="section-number-3">2.16</span> Video 9: Results</h3>
<div class="outline-text-3" id="text-2-16">
<p>
We will discuss the results of the classification tree model. So we
first observe that the overall accuracy of the method regarding the
percentage that it accurately predicts is \(80\%\), compared to \(75\%\)
of the baseline.
</p>

<p>
But notice that this is done in an interesting way. For bucket one
patients, the two models are equivalent. But of course this suggests
the idea that healthy people stay healthy, which is the idea of the
baseline model.
</p>

<p>
The cost repeats is valid in the data.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Results.png" alt="D2HE-Results.png" />
</p>
</div>

<p>
But then for buckets two to five, notice that the accuracy increases
substantially from 31% to 60%&#x2013; it doubles&#x2013; from 21% to 53%&#x2013; more
than doubles&#x2013; and from 19% to 39%&#x2013; doubles.
</p>

<p>
There's an improvement from 23% to 30%, not as big as before, but
there is indeed an improvement for bucket five. But notice the
improvement on the penalty from 0.56 to 0.52 overall.
</p>

<p>
A small improvement in bucket one, but a significant improvement as we
increase on the buckets. For example, here for bucket five, the
penalty error decreases from 1.88 to 1.01, a substantial improvement.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Results02.png" alt="D2HE-Results02.png" />
</p>
</div>

<p>
So we observed that there's a substantial improvement over the
baseline, especially as we go down on buckets. It doubles the accuracy
over the baseline in some cases. And so we have seen there's a smaller
accuracy improvement in bucket five, but there's a much lower penalty
in the prediction for bucket five.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-Insights.png" alt="D2HE-Insights.png" />
</p>
</div>

<p>
So what is the edge of the analytics provided to D2Hawkeye?
</p>

<p>
First and foremost, there was a substantial improvement in the
company's ability to identify patients who need more
attention. Another advantage was related to the fact that the model
was in fact interpretable by physicians.
</p>

<p>
So the physicians were able to improve the model by identifying new
variables and refining existing variables. That really led to further
improvements. Finally, and quite importantly, the analytics gave the
company an edge over the competition using&#x2013; that the competition used
last century methods.
</p>

<p>
And the use of machine learning methods&#x2013; in this case, classification
trees&#x2013; provided an edge that also helped Hawkeye when it was sold to
Verisk Analytics in 2009.
</p>


<div class="figure">
<p><img src="../graphs/D2HE-AnalyticsEdge.png" alt="D2HE-AnalyticsEdge.png" />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline91" class="outline-2">
<h2 id="orgheadline91"><span class="section-number-2">3</span> Location, Location, Location: Regression Trees for Housing Data (Recitation)</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-orgheadline82" class="outline-3">
<h3 id="orgheadline82"><span class="section-number-3">3.1</span> Video 1: Boston Housing Data</h3>
<div class="outline-text-3" id="text-3-1">
<p>
In real estate, there is a famous saying that the most important thing
is location, location, location. In this recitation, we will be
looking at regression trees, and applying them to data related to
house prices and locations.
</p>

<p>
Boston is the capital of the state of Massachusetts, USA.
</p>


<div class="figure">
<p><img src="../graphs/HD-Location.png" alt="HD-Location.png" />
</p>
</div>

<p>
Some interesting data in the history of Boston.
</p>


<div class="figure">
<p><img src="../graphs/HD-Boston.png" alt="HD-Boston.png" />
</p>
</div>

<p>
Here is a shot of Boston from above. In the middle of the picture, we
have the Charles River. I'm talking to you from my office at MIT. My
office is here. This is MIT here. MIT lies in the city of Cambridge,
which is north of the river, and south of the river is Boston city,
itself.
</p>

<p>
In this recitation, we will be talking about Boston in a sense of the
greater Boston area.
</p>

<p>
However, if we look at the housing in Boston right now, we can see
that it is very dense. Over the greater Boston area, the nature of the
housing varies widely.
</p>


<div class="figure">
<p><img src="../graphs/HD-Boston02.png" alt="HD-Boston02.png" />
</p>
</div>

<p>
This data comes from a paper, "Hedonic Housing Prices and the Demand
for Clean Air," which has been cited more than 1,000 times.
</p>

<p>
This paper was written on a relationship between house prices and
clean air in the late 1970s by David Harrison of Harvard and Daniel
Rubinfeld of the University of Michigan.
</p>

<p>
The data set is widely used to evaluate algorithms of a nature we
discuss in this class.
</p>


<div class="figure">
<p><img src="../graphs/HD-HousingData.png" alt="HD-HousingData.png" />
</p>
</div>

<p>
We mostly discuss classification trees with the output as a factor or
a category. Trees can also be used for regression tasks. The output at
each leaf of a tree is no longer a category, but a number.
</p>

<p>
Just like classification trees, regression trees can capture
non-linearities that linear regression can't.
</p>


<div class="figure">
<p><img src="../graphs/RinCART.png" alt="RinCART.png" />
</p>
</div>

<p>
<b>So what does that mean?</b>
</p>

<p>
Well, with classification trees we report the average outcome at each
leaf of our tree. For example, if the outcome is true 15 times, and
false 5 times, the value at that leaf of a tree would be
</p>

<p>
\($
\frac{15}{(15 + 5)} = 0.75.
$\)
</p>

<p>
Now, if we use the default threshold of 0.5, we would say the value at
this leaf is <b>true</b>. With regression trees, we now have continuous
variables.
</p>

<p>
With regression trees, we now have continuous variables. So instead
of&#x2013; we report the average of the values at that leaf. So suppose we
had the values 3, 4, and 5 at one of the leaves of our trees.
</p>

<p>
Well, we just take the average of these numbers, which is 4, and that
is what we report.
</p>


<div class="figure">
<p><img src="../graphs/HD-RegressionTrees.png" alt="HD-RegressionTrees.png" />
</p>
</div>

<p>
That might be a bit confusing so let's look at a picture. Here is some
fake data that I made up in R. We see x on the x-axis and y on the
y-axis. y is our variable we are trying to predict using x. So if we
fit a linear regression to this data set, we obtain the following
line (red simple line).
</p>

<p>
As you can see, linear regression does not do very well on this data
set. However, we can notice that the data lies in three different
groups. If we draw these lines here, we see x is either less than 10,
between 10 and 20, or greater then 20, and there is very different
behavior in each group.
</p>

<p>
Regression trees can fit that kind of thing exactly. So the splits
would be x is less than or equal to 10, take the average of those
values. x is between 10 and 20, take the average of those values. x is
between 20 and 30, take the average of those values. We see that
regression trees can fit some kinds of data very well that linear
regression completely fails on.
</p>

<p>
Of course, in reality nothing is ever so nice and simple, but it gives
us some idea why we might be interested in regression trees.
</p>


<div class="figure">
<p><img src="../graphs/HD-Example.png" alt="HD-Example.png" />
</p>
</div>

<p>
We will explore the data set with the aid of trees. We will compare
linear regression with regression trees. We will discuss what the cp
parameter means that we brought up when we did cross-validation in the
lecture, and we will apply cross-validation to regression trees.
</p>


<div class="figure">
<p><img src="../graphs/HD-HousingData02.png" alt="HD-HousingData02.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline86" class="outline-3">
<h3 id="orgheadline86"><span class="section-number-3">3.2</span> Video 2: The Data</h3>
<div class="outline-text-3" id="text-3-2">
<p>
In this recitation, Iain will be using the dataset <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/boston.csv">boston.csv</a> to
predict housing prices in Boston. Please download this dataset to
follow along in this recitation. This data comes from the
<a href="http://archive.ics.uci.edu/ml/datasets/Housing">UCI Machine Learning Repository</a>.
</p>

<p>
An R script file with all of the R commands used in this recitation
can be downloaded <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/Unit4_Recitation.R">here</a>.
</p>

<p>
Before we jump into R, let's understand the data. Each entry of this
data set corresponds to a census tract, a statistical division of the
area that is used by researchers to break down towns and cities. As a
result, there will usually be multiple census tracts per town.
</p>


<div class="figure">
<p><img src="../graphs/HD-UnderstandingData.png" alt="HD-UnderstandingData.png" />
</p>
</div>

<p>
Next set of variables in the variable dictionary:
</p>


<div class="figure">
<p><img src="../graphs/HD-UnderstandingData02.png" alt="HD-UnderstandingData02.png" />
</p>
</div>

<p>
Some of the variables are demographic and other are around the
location it self.
</p>


<div class="figure">
<p><img src="../graphs/HD-UnderstandingData03.png" alt="HD-UnderstandingData03.png" />
</p>
</div>
</div>

<div id="outline-container-orgheadline83" class="outline-4">
<h4 id="orgheadline83"><span class="section-number-4">3.2.1</span> Download the data sets</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
In this part we can download the data
</p>

<div class="org-src-container">

<pre class="src src-R"><span style="color: #db7093;">library</span>(parallel)

<span style="color: #4682b4;">if</span>(!file.exists(<span style="color: #ff6a6a;">"../data"</span>)) {
        dir.create(<span style="color: #ff6a6a;">"../data"</span>)
}

fileUrl <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/boston.csv"</span>

fileName <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"boston.csv"</span>

dataPath <span style="color: #db7093;">&lt;-</span> <span style="color: #ff6a6a;">"../data"</span>

filePath <span style="color: #db7093;">&lt;-</span> paste(dataPath, fileName, sep = <span style="color: #ff6a6a;">"/"</span>)

<span style="color: #4682b4;">if</span>(!file.exists(filePath)) {
        download.file(fileUrl, destfile = filePath, method = <span style="color: #ff6a6a;">"curl"</span>)
}

list.files(<span style="color: #ff6a6a;">"../data"</span>)
</pre>
</div>

<pre class="example">
 [1] "AirlinesCluster.csv"       "AnonymityPoll.csv"
 [3] "baseball.csv"              "BoeingStock.csv"
 [5] "boston.csv"                "ClaimsData.csv"
 [7] "ClaimsData.csv.zip"        "climate_change.csv"
 [9] "clinical_trial.csv"        "ClusterMeans.ods"
[11] "CocaColaStock.csv"         "CountryCodes.csv"
[13] "CPSData.csv"               "dailykos.csv"
[15] "eBayAll.RData"             "eBayiPadTest.csv"
[17] "eBayiPadTrain.csv"         "edges.csv"
[19] "emails.csv"                "energy_bids.csv"
[21] "federalFundsRate.csv"      "finalExam-Households.csv"
[23] "flower.csv"                "FluTest.csv"
[25] "FluTrain.csv"              "framingham.csv"
[27] "gerber.csv"                "GEStock.csv"
[29] "healthy.csv"               "households.csv"
[31] "IBMStock.csv"              "intl.csv"
[33] "intlall.csv"               "loans_imputed.csv"
[35] "loans.csv"                 "MetroAreaCodes.csv"
[37] "movieLens.txt"             "MoviesP1Final.csv"
[39] "murders.csv"               "mvt.csv"
[41] "mvtWeek1.csv"              "NBA_test.csv"
[43] "NBA_train.csv"             "parole.csv"
[45] "pisa2009test.csv"          "pisa2009train.csv"
[47] "PollingData_Imputed.csv"   "PollingData.csv"
[49] "PollingImputed.csv"        "ProcterGambleStock.csv"
[51] "quality.csv"               "README.md"
[53] "SampleSubmission.csv"      "songs.csv"
[55] "stevens.csv"               "StocksCluster.csv"
[57] "stopwords.txt"             "SubmissionGBM1.csv"
[59] "SubmissionGBM2.csv"        "SubmissionLR2.csv"
[61] "SubmissionLR3.csv"         "SubmissionLR4.csv"
[63] "SubmissionLR5.csv"         "SubmissionLR8.csv"
[65] "SubmissionLR9.csv"         "SubmissionRF1.csv"
[67] "SubmissionSimpleLogV1.csv" "tumor.csv"
[69] "tweets.csv"                "tweetsU7.csv"
[71] "USDA.csv"                  "users.csv"
[73] "WHO_Europe.csv"            "WHO.csv"
[75] "WHOu7.csv"                 "wiki.csv"
[77] "wine_test.csv"             "wine.csv"
</pre>
</div>
</div>

<div id="outline-container-orgheadline84" class="outline-4">
<h4 id="orgheadline84"><span class="section-number-4">3.2.2</span> Load the data set</h4>
<div class="outline-text-4" id="text-3-2-2">
<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"    Loading data into their data frames."</span>)
boston <span style="color: #db7093;">&lt;-</span> read.table(<span style="color: #ff6a6a;">"../data/boston.csv"</span>, sep = <span style="color: #ff6a6a;">","</span>, header = <span style="color: #3cb371;">TRUE</span>)

str(boston)
summary(boston)
</pre>
</div>

<pre class="example">
    Loading data into their data frames.
'data.frame':	506 obs. of  16 variables:
 $ TOWN   : Factor w/ 92 levels "Arlington","Ashland",..: 54 77 77 46 46 46 69 69 69 69 ...
 $ TRACT  : int  2011 2021 2022 2031 2032 2033 2041 2042 2043 2044 ...
 $ LON    : num  -71 -71 -70.9 -70.9 -70.9 ...
 $ LAT    : num  42.3 42.3 42.3 42.3 42.3 ...
 $ MEDV   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 22.1 16.5 18.9 ...
 $ CRIM   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
 $ ZN     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
 $ INDUS  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
 $ CHAS   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ NOX    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
 $ RM     : num  6.58 6.42 7.18 7 7.15 ...
 $ AGE    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
 $ DIS    : num  4.09 4.97 4.97 6.06 6.06 ...
 $ RAD    : int  1 2 2 3 3 3 5 5 5 5 ...
 $ TAX    : int  296 242 242 222 222 222 311 311 311 311 ...
 $ PTRATIO: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
                TOWN         TRACT           LON              LAT
 Cambridge        : 30   Min.   :   1   Min.   :-71.29   Min.   :42.03
 Boston Savin Hill: 23   1st Qu.:1303   1st Qu.:-71.09   1st Qu.:42.18
 Lynn             : 22   Median :3394   Median :-71.05   Median :42.22
 Boston Roxbury   : 19   Mean   :2700   Mean   :-71.06   Mean   :42.22
 Newton           : 18   3rd Qu.:3740   3rd Qu.:-71.02   3rd Qu.:42.25
 Somerville       : 15   Max.   :5082   Max.   :-70.81   Max.   :42.38
 (Other)          :379
      MEDV            CRIM                ZN             INDUS
 Min.   : 5.00   Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46
 1st Qu.:17.02   1st Qu.: 0.08204   1st Qu.:  0.00   1st Qu.: 5.19
 Median :21.20   Median : 0.25651   Median :  0.00   Median : 9.69
 Mean   :22.53   Mean   : 3.61352   Mean   : 11.36   Mean   :11.14
 3rd Qu.:25.00   3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10
 Max.   :50.00   Max.   :88.97620   Max.   :100.00   Max.   :27.74

      CHAS              NOX               RM             AGE
 Min.   :0.00000   Min.   :0.3850   Min.   :3.561   Min.   :  2.90
 1st Qu.:0.00000   1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02
 Median :0.00000   Median :0.5380   Median :6.208   Median : 77.50
 Mean   :0.06917   Mean   :0.5547   Mean   :6.285   Mean   : 68.57
 3rd Qu.:0.00000   3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08
 Max.   :1.00000   Max.   :0.8710   Max.   :8.780   Max.   :100.00

      DIS              RAD              TAX           PTRATIO
 Min.   : 1.130   Min.   : 1.000   Min.   :187.0   Min.   :12.60
 1st Qu.: 2.100   1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40
 Median : 3.207   Median : 5.000   Median :330.0   Median :19.05
 Mean   : 3.795   Mean   : 9.549   Mean   :408.2   Mean   :18.46
 3rd Qu.: 5.188   3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20
 Max.   :12.127   Max.   :24.000   Max.   :711.0   Max.   :22.00
</pre>

<p>
If we look at the structure of the Boston data set, we can see all the
variables we talked about before. There are \(506\) observations
corresponding to \(506\) census tracts in the Greater Boston area.
</p>

<p>
We are interested in <b>building a model</b> initially of <b>how prices vary</b> by
<b>location across a region</b>. So let's first see how the points are laid
out. Using the plot commands, we can plot the latitude and longitude
of each of our census tracts.
</p>


<div id="orgparagraph7" class="figure">
<p><img src="../graphs/PositionsCensusTracts.png" alt="PositionsCensusTracts.png" />
</p>
<p><span class="figure-number">Figure 79:</span> Latitude and longitude of the census tracts.</p>
</div>

<p>
This picture might be a little bit meaningless to you if you're not
familiar with the Massachusetts-Boston area, but I can tell you that
the dense central core of points corresponds to Boston city, Cambridge
city, and other close urban cities.
</p>

<p>
Still, let's try and relate it back to that picture we saw in the
first video, where I showed you the river and where MIT was.
</p>

<p>
So we want to show all the points that lie along the <b>Charles River</b> in
a different color. We have a variable, <b>CHAS</b>, that tells us if a point
is on the Charles River or not.
</p>


<div id="orgparagraph8" class="figure">
<p><img src="../graphs/CHASRiverLocation.png" alt="CHASRiverLocation.png" />
</p>
<p><span class="figure-number">Figure 80:</span> Adding census tracts along Charles River</p>
</div>

<p>
But maybe it's still a little bit confusing, and you'd like to know
where MIT is in this picture. So we can do that too. I looked up which
census tract MIT is in, and it's census tract 3531.
</p>

<p>
So let's plot that. We add another point, the longitude of MIT, which
is in tract 3531, and the latitude of MIT, which is in census
tract 3531. I'm going to plot this one in red, so we can tell it apart
from the other Charles River dots.
</p>


<div id="orgparagraph9" class="figure">
<p><img src="../graphs/MITcensusLocation.png" alt="MITcensusLocation.png" />
</p>
<p><span class="figure-number">Figure 81:</span> Plotting the MIT census tract</p>
</div>

<p>
<b>What other things can we do?</b> Well, this data set was originally
constructed to investigate questions about how air pollution affects
prices. So the air pollution variable is this NOX variable.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Polution summary:"</span>)
summary(boston$NOX)
</pre>
</div>

<pre class="example">
:: Polution summary:
  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.3850  0.4490  0.5380  0.5547  0.6240  0.8710
</pre>

<p>
Let's have a look at a distribution of <b>NOX</b>. <code>boston$NOX</code>. So we see
that the minimum value is \(0.385\), the maximum value is \(0.87\) and the
median and the mean are about \(0.53\), \(0.55\). So let's just use the
value of \(0.55\), as it's kind of in the middle.
</p>

<p>
And we'll look at just the census tracts that have above-average
pollution.
</p>


<div id="orgparagraph10" class="figure">
<p><img src="../graphs/PollutionPlotBoston.png" alt="PollutionPlotBoston.png" />
</p>
<p><span class="figure-number">Figure 82:</span> Pollution in Boston city</p>
</div>

<p>
So those are all the points that have got above-average
pollution. Looks like my office is right in the middle. Now it kind of
makes sense, though, because that's the dense urban core of Boston. If
you think of anywhere where pollution would be, you'd think it'd be
where the most cars and the most people are. So that's kind of
interesting.
</p>

<p>
We should probably look at how prices vary over the area as well.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The Boston prices summary:"</span>)
summary(boston$MEDV)
</pre>
</div>

<pre class="example">
:: The Boston prices summary:
  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  5.00   17.02   21.20   22.53   25.00   50.00
</pre>

<p>
We see that the minimum price &#x2013; and remember the units are thousands
of dollars, so the median value of owner-occupied homes in thousands
of dollars &#x2013; so the minimum is around five, the maximum is
around \(50\).
</p>

<p>
So let's plot again only the above-average price points.
</p>


<div id="orgparagraph11" class="figure">
<p><img src="../graphs/BostonPricesLocations.png" alt="BostonPricesLocations.png" />
</p>
<p><span class="figure-number">Figure 83:</span> Locations in Boston respect to prices</p>
</div>

<p>
So what we see now are all the census tracts with above-average
housing prices. As you can see, it's definitely not simple. The census
tracts of above-average and below-average are mixed in between each
other.
</p>

<p>
But there are some patterns. For example, look at that dense black bit
in the middle. That corresponds to most of the city of Boston,
especially the southern parts of the city. Also, on the Cambridge side
of the river, there's a big chunk there of dots that are black, that
are not red, that are also presumably below average.
</p>

<p>
So there's definitely some structure to it, but it's certainly not
simple in relation to latitude and longitude at least.
</p>
</div>
</div>

<div id="outline-container-orgheadline85" class="outline-4">
<h4 id="orgheadline85"><span class="section-number-4">3.2.3</span> Video 3: Geographical Predictions</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
So, we saw in the previous video that the house prices were
distributed over the area in an interesting way, certainly not the
kind of linear way. And we wouldn't necessarily expect linear
regression to do very well at predicting house price, just given
latitude and longitude.
</p>

<p>
We can kind of develop that intuition more by plotting the
relationship between latitude and house prices&#x2013; which doesn't look
very linear&#x2013; or the longitude and the house prices, which also looks
pretty nonlinear. So, we'll try fitting a linear regression anyway.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Linear Regression using LAT and LON:"</span>)
latlonlm <span style="color: #db7093;">&lt;-</span> lm(MEDV ~ LAT + LON, data = boston)
summary(latlonlm)
</pre>
</div>

<pre class="example">
 :: Linear Regression using LAT and LON:

Call:
lm(formula = MEDV ~ LAT + LON, data = boston)

Residuals:
    Min      1Q  Median      3Q     Max
-16.460  -5.590  -1.299   3.695  28.129

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) -3178.472    484.937  -6.554 1.39e-10 ***
LAT             8.046      6.327   1.272    0.204
LON           -40.268      5.184  -7.768 4.50e-14 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 8.693 on 503 degrees of freedom
Multiple R-squared:  0.1072,	Adjusted R-squared:  0.1036
F-statistic: 30.19 on 2 and 503 DF,  p-value: 4.159e-13
</pre>

<p>
If we take a look at our linear regression, we see the R-squared is
around 0.1, which is not great. The latitude is not significant, which
means the north-south differences aren't going to be really used at
all.
</p>

<p>
Longitude is significant, and it's negative. Which we can interpret
as, as we go towards the ocean&#x2013; as we go towards the east&#x2013; house
prices decrease linearly.
</p>

<p>
This make sense because the poor correlation between the Latitude and
Longitude coordinates vs. price.
</p>


<div id="orgparagraph12" class="figure">
<p><img src="../graphs/LatitudeVsPricePlot.png" alt="LatitudeVsPricePlot.png" />
</p>
<p><span class="figure-number">Figure 84:</span> Latitude vs. Price plot.</p>
</div>

<p>
Now we can plot the Longitude vs. Price and see if we have any
relationship between these variables.
</p>


<div id="orgparagraph13" class="figure">
<p><img src="../graphs/LongitudeVsPricePlot.png" alt="LongitudeVsPricePlot.png" />
</p>
<p><span class="figure-number">Figure 85:</span> Longitude vs. Price correlation</p>
</div>

<p>
We can't see a clear relationship between these variables, and the
linear regression model is quite poor.
</p>

<p>
So let's see how this linear regression model looks on a plot. So
let's plot the census tracts again.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: The Longitude and Latitude fitted values are:"</span>)
summary(latlonlm$fitted.values)
</pre>
</div>

<pre class="example">
:: The Longitude and Latitude fitted values are:
  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 11.34   21.08   22.34   22.53   23.93   31.44
</pre>

<p>
What does the linear regression model think is above median.
</p>

<p>
We have <code>latlonlm$fitted.values</code> and this is what the linear regression
model predicts for each of the \(506\) census tracts.
</p>

<p>
we're interested in seeing how the linear regression matches up with
the truth. So it'd be ideal if we could plot the linear regression
blue dots on top of the red dots, in some way that we can still see
the red dots.
</p>


<div id="orgparagraph14" class="figure">
<p><img src="../graphs/PositionCoordinatesVsPriceModel.png" alt="PositionCoordinatesVsPriceModel.png" />
</p>
<p><span class="figure-number">Figure 86:</span> Position vs. Price in our linear model</p>
</div>

<p>
So, the linear regression model has plotted a dollar sign for every
time it thinks the census tract is above median value. And you can see
that, indeed, it's almost as&#x2013; you can see the sharp line that the
linear regression defines.
</p>

<p>
And how it's pretty much vertical, because remember before, the
latitude variable was not very significant in the regression.
</p>

<p>
So that's interesting and pretty wrong. One thing that really stands
out is how it says Boston is mostly above median. Even knowing&#x2013; we
saw it right from the start&#x2013; there's a big non-red spot, right in the
middle of Boston, where the house prices were below the median.
</p>

<p>
So the linear regression model isn't really doing a good job. And it's
completely ignored everything to the right side of the picture.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline87" class="outline-3">
<h3 id="orgheadline87"><span class="section-number-3">3.3</span> Video 4: Regression Trees</h3>
<div class="outline-text-3" id="text-3-3">
<p>
In this video, Iain shows a different way to plot a CART tree - by
using the plot and text functions instead of the prp function. This is
just another way to visualize the CART tree, and shows the tree in a
slightly different way. Both are valid options for plotting your CART
trees.
</p>

<p>
Let's see how regression trees do. We'll first load the rpart library
and also load the rpart plotting library. We build a regression tree
in the same way we would build a classification tree, using the rpart
command. We predict MEDV as a function of latitude and longitude,
using the boston dataset.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Load CART packages:"</span>)
<span style="color: #db7093;">library</span>(rpart)
<span style="color: #db7093;">library</span>(rpart.plot)

writeLines(<span style="color: #ff6a6a;">"\n :: CART model:"</span>)
latlontree <span style="color: #db7093;">&lt;-</span> rpart(MEDV ~ LAT + LON, data = boston)
</pre>
</div>

<pre class="example">
:: Load CART packages:

:: CART model:
</pre>

<p>
If we now plot the tree using the prp command, which is defined in
rpart.plot, we can see it makes a lot of splits and is a little bit
hard to interpret.
</p>


<div id="orgparagraph15" class="figure">
<p><img src="../graphs/CARTBostonLocationModel.png" alt="CARTBostonLocationModel.png" />
</p>
<p><span class="figure-number">Figure 87:</span> CART plot of the Boston prices vs. position.</p>
</div>

<p>
But the important thing is to look at the leaves. In a classification
tree, the leaves would be the classification we assign that these
splits would apply to.
</p>

<p>
But in regression trees, we instead predict the number. That number is
the average of the median house prices in that bucket or leaf.
</p>

<p>
So let's see what that means in practice. So we'll plot again the
latitude of the points. And we'll again plot the points with above
median prices.
</p>


<div id="orgparagraph16" class="figure">
<p><img src="../graphs/VisualizeOutput.png" alt="VisualizeOutput.png" />
</p>
<p><span class="figure-number">Figure 88:</span> Visualizing the output.</p>
</div>

<p>
Now we see that we've done a much better job than linear regression
was able to do. We've correctly left the low value area in Boston and
below out, and we've correctly managed to classify some of those
points in the bottom right and top right.
</p>

<p>
We're still making mistakes, but we're able to make a nonlinear
prediction on latitude and longitude. So that's interesting, but the
tree was very complicated. So maybe it's drastically overfitting.
</p>

<p>
<b>Can we get most of this effect with a much simpler tree?</b>
</p>

<p>
<i>We can. We would just change the minbucket size.</i>
</p>


<div id="orgparagraph17" class="figure">
<p><img src="../graphs/PriceVsPositionWIncreasedMinbucket.png" alt="PriceVsPositionWIncreasedMinbucket.png" />
</p>
<p><span class="figure-number">Figure 89:</span> Increasing minbucket to simplify the CART.</p>
</div>

<p>
Or using the <code>prp</code> commmand:
</p>


<div id="orgparagraph18" class="figure">
<p><img src="../graphs/PriceVsPositionWIncreasedMinbucket02.png" alt="PriceVsPositionWIncreasedMinbucket02.png" />
</p>
<p><span class="figure-number">Figure 90:</span> Same CART with increased minbucket and prp command.</p>
</div>

<p>
And we see we have far fewer splits, and it's far more
interpretable. The first split says if the longitude is greater than
or equal to negative 71.07&#x2013; so if you're on the right side of the
picture. So the left-hand branch is on the left-hand side of the
picture and the right-hand&#x2013; So the left-hand side of the tree
corresponds to the right-hand side of the map.
</p>

<p>
And the right side of the tree corresponds to the left side of the
map. That's a little bit of a mouthful. Let's see what it means
visually.
</p>


<div id="orgparagraph19" class="figure">
<p><img src="../graphs/CART2ModelBoston.png" alt="CART2ModelBoston.png" />
</p>
<p><span class="figure-number">Figure 91:</span> Price vs. position in the simple model</p>
</div>

<p>
We'll focus on the lowest price prediction, which is in the bottom
left corner of the tree, right down at the bottom left after all those
splits. So that's where we want to get to. So let's plot again the
points.
</p>

<p>
Plot a vertical line. The next split down towards that bottom left
corner was a horizontal line at \(42.21\). So I put that in. That's
interesting.
</p>

<p>
So that line corresponds pretty much to where the Charles River was
from before. The final split you need to get to that bottom left
corner I was pointing out is \(42.17\).
</p>

<p>
The final split you need to get to that bottom left corner I was
pointing out is 42.17. It was above this line. And now that's
interesting. If we look at the right side of the middle of the three
rectangles on the right side, that is the bucket we were predicting.
</p>

<p>
We've correctly shown how the regression tree carves out that
rectangle in the bottom of Boston and says that is a low value area.
</p>

<p>
It's shown us something that regression trees can do that we would
never expect linear regression to be able to do.
</p>

<p>
So the question we're going to answer in the next video is given that
regression trees can do these fancy things with latitude and
longitude, is it actually going to help us to be able to build a
predictive model, predicting house prices?
</p>
</div>
</div>

<div id="outline-container-orgheadline88" class="outline-3">
<h3 id="orgheadline88"><span class="section-number-3">3.4</span> Video 5: Putting it all Together</h3>
<div class="outline-text-3" id="text-3-4">
<p>
In the previous video, we got a feel for how regression trees can do
things linear regression cannot. But what really matters at the end of
the day is whether it can predict things better than linear
regression.
</p>

<p>
And so let's try that right now. We're going to try to predict house
prices using all the variables we have available to us.
</p>

<p>
So we'll load the caTools library. That will help us do a split on the
data. We'll set the seed so our results are reproducible. And we'll
say our split will be on the Boston house prices and we'll split it
70% training, 30% test.
</p>

<p>
So our training data is a subset of the boston data where the split is
TRUE. And the testing data is the subset of the boston data where the
split is FALSE.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Split the data..."</span>)
<span style="color: #db7093;">library</span>(caTools)
set.seed(123)
split <span style="color: #db7093;">&lt;-</span> sample.split(boston$MEDV, SplitRatio = 0.7)
train <span style="color: #db7093;">&lt;-</span> subset(boston, split==<span style="color: #3cb371;">TRUE</span>)
test <span style="color: #db7093;">&lt;-</span> subset(boston, split==<span style="color: #3cb371;">FALSE</span>)
</pre>
</div>

<pre class="example">
null device
         1
null device
         1
null device
         1
null device
         1
null device
         1

:: Split the data...
</pre>

<p>
OK, first of all, let's make a linear regression model, nice and
easy. It's a linear model and the variables are latitude, longitude,
crime, zoning, industry, whether it's on the Charles River or not, air
pollution, rooms, age, distance, another form of distance, tax rates,
and the pupil-teacher ratio.
</p>

<p>
The data is training data. OK, let's see what our linear regression
looks like.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Create linear regression"</span>)
linreg <span style="color: #db7093;">&lt;-</span> lm(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM +
                     AGE + DIS + RAD + TAX + PTRATIO, data = train)
summary(linreg)
</pre>
</div>

<pre class="example">
 :: Create linear regression

Call:
lm(formula = MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX +
    RM + AGE + DIS + RAD + TAX + PTRATIO, data = train)

Residuals:
    Min      1Q  Median      3Q     Max
-14.511  -2.712  -0.676   1.793  36.883

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) -2.523e+02  4.367e+02  -0.578   0.5638
LAT          1.544e+00  5.192e+00   0.297   0.7664
LON         -2.987e+00  4.786e+00  -0.624   0.5329
CRIM        -1.808e-01  4.390e-02  -4.118 4.77e-05 ***
ZN           3.250e-02  1.877e-02   1.731   0.0843 .
INDUS       -4.297e-02  8.473e-02  -0.507   0.6124
CHAS         2.904e+00  1.220e+00   2.380   0.0178 *
NOX         -2.161e+01  5.414e+00  -3.992 7.98e-05 ***
RM           6.284e+00  4.827e-01  13.019  &lt; 2e-16 ***
AGE         -4.430e-02  1.785e-02  -2.482   0.0135 *
DIS         -1.577e+00  2.842e-01  -5.551 5.63e-08 ***
RAD          2.451e-01  9.728e-02   2.519   0.0122 *
TAX         -1.112e-02  5.452e-03  -2.040   0.0421 *
PTRATIO     -9.835e-01  1.939e-01  -5.072 6.38e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.595 on 350 degrees of freedom
Multiple R-squared:  0.665,	Adjusted R-squared:  0.6525
F-statistic: 53.43 on 13 and 350 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
So we see that the latitude and longitude are not significant for the
linear regression, which is perhaps not surprising because linear
regression didn't seem to be able to take advantage of them.
</p>

<p>
Crime is very important. The residential zoning might be
important. Whether it's on the Charles River or not is a useful
factor. Air pollution does seem to matter&#x2013; the coefficient is
negative, as you'd expect.
</p>

<p>
The average number of rooms is significant. The age is somewhat
important. Distance to centers of employment (DIS), is very
important. Distance to highways and tax is somewhat important, and the
pupil-teacher ratio is also very significant.
</p>

<p>
Some of these might be correlated, so we can't put too much stock in
necessarily interpreting them directly, but it's interesting. The
adjusted R squared is 0.65, which is pretty good. So because it's kind
of hard to compare out of sample accuracy for regression, we need to
think of how we're going to do that.
</p>

<p>
With classification, we just say, this method got X% correct and this
method got Y% correct.
</p>

<p>
Well, since we're doing continuous variables, let's calculate the sum
of squared error, which we discussed in the original linear regression
video. So let's say the linear regression's predictions are
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions"</span>)
linreg.pred <span style="color: #db7093;">&lt;-</span> predict(linreg, newdata = test)
linreg.sse <span style="color: #db7093;">&lt;-</span> sum((linreg.pred - test$MEDV)^2)
linreg.sse
</pre>
</div>

<pre class="example">
 :: Make predictions
[1] 3037.088
</pre>

<p>
The linear regression sum of squared errors is simply the sum of the
predicted values versus the actual values squared.
</p>

<p>
So let's see what that number is&#x2013; 3,037.008.
</p>

<p>
OK, so you know what we're interested to see now is, can we beat this
using regression trees? So let's build a tree. The tree &#x2013; rpart
command again.
</p>

<p>
Actually to save myself from typing it all up again, I'm going to go
back to the regression command and just change "lm" to "rpart" and
change "linreg" to "tree"&#x2013; much easier. All right.
</p>

<p>
So we've built our tree&#x2013; let's have a look at it using the "prp"
command from <code>rpart.plot</code>. And here we go.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Create a CART model"</span>)
tree <span style="color: #db7093;">&lt;-</span> rpart(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM +
                      AGE + DIS + RAD + TAX + PTRATIO, data = train)
</pre>
</div>

<pre class="example">
:: Create a CART model
</pre>


<div id="orgparagraph20" class="figure">
<p><img src="../graphs/LocationCARTModel.png" alt="LocationCARTModel.png" />
</p>
<p><span class="figure-number">Figure 92:</span> Location CART Model</p>
</div>

<p>
So again, latitude and longitude aren't really important as far as the
tree's concerned. The rooms are the most important split. Pollution
appears in there twice, so it's, in some sense, nonlinear on the
amount of pollution&#x2013; if it's greater than a certain amount or less
than a certain amount, it does different things.
</p>

<p>
Crime is in there, age is in there. Room appears three times,
actually&#x2013; sorry. That's interesting. So it's very nonlinear on the
number of rooms. Things that were important for the linear regression
that don't appear in ours include pupil-teacher ratio. The DIS
variable doesn't appear in our regression tree at all, either.
</p>

<p>
So they're definitely doing different things, but how do they compare?
So we'll predict, again, from the tree.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions..."</span>)
tree.pred <span style="color: #db7093;">&lt;-</span> predict(tree, newdata = test)
tree.sse <span style="color: #db7093;">&lt;-</span> sum((tree.pred - test$MEDV)^2)
tree.sse
</pre>
</div>

<pre class="example">
 null device
          1

 :: Make predictions...
[1] 4328.988
</pre>

<p>
And then the moment of truth&#x2013; 4,328. So, simply put, regression trees
are not as good as linear regression for this problem.
</p>

<p>
What this says to us, given what we saw with the latitude and
longitude, is that latitude and longitude are nowhere near as useful
for predicting, apparently, as these other variables are. That's just
the way it goes, I guess.
</p>

<p>
It's always nice when a new method does better, but there's no
guarantee that's going to happen. We need a special structure to
really be useful. Let's stop here with the R and go back to the slides
and discuss how CP works and then we'll apply cross validation to our
tree.
</p>

<p>
And we'll see if maybe we can improve in our results.
</p>
</div>
</div>

<div id="outline-container-orgheadline89" class="outline-3">
<h3 id="orgheadline89"><span class="section-number-3">3.5</span> Video 6: The CP Parameter</h3>
<div class="outline-text-3" id="text-3-5">
<p>
The cp parameter&#x2013; cp stands for complexity parameter. Recall that the
first tree we made using latitude and longitude only had many splits,
but we were able to trim it without losing much accuracy.
</p>

<p>
The intuition we gain is, having too many splits is bad for
generalization&#x2013; that is, performance on the test set&#x2013; so we should
penalize the complexity.
</p>


<div class="figure">
<p><img src="../graphs/HD-CPparameter.png" alt="HD-CPparameter.png" />
</p>
</div>

<p>
Let us define RSS to be the residual sum of squares, also known as the
sum of square differences. Our goal when building the tree is to
minimize the RSS by making splits, but we want to penalize having too
many splits now.
</p>

<p>
Define S to be the number of splits, and lambda to be our penalty. Our
new goal is to find a tree that minimizes the sum of the RSS at each
leaf, plus lambda, times S, for the number of splits.
</p>


<div class="figure">
<p><img src="../graphs/HD-CPparameter02.png" alt="HD-CPparameter02.png" />
</p>
</div>

<p>
Let us consider the following example. Here we have set lambda to be
equal to 0.5. Initially, we have a tree with no splits. We simply take
the average of the data.
</p>

<p>
The RSS in this case is 5, thus our total penalty is also 5. If we
make one split, we now have two leaves. At each of these leaves, say,
we have an error, or RSS of 2. The total RSS error is then 2+2=4.
</p>

<p>
And the total penalty is 4+0.5*1, the number of splits. Our total
penalty in this case is 4.5. If we split again on one of our leaves,
we now have a total of three leaves for two splits.
</p>

<p>
The error at our left-most leaf is 1. The next leaf has an error of
0.8. And the next leaf has an error of 2, for a total error of
3.8. The total penalty is thus 3.8+0.5*2, for a total penalty of 4.8.
</p>


<div class="figure">
<p><img src="../graphs/HD-CPparameter03.png" alt="HD-CPparameter03.png" />
</p>
</div>

<p>
Notice that if we pick a large value of lambda, we won't make many
splits, because you pay a big price for every additional split that
will outweigh the decrease in error. If we pick a small, or 0 value of
lambda, it will make splits until it no longer decreases the error.
</p>


<div class="figure">
<p><img src="../graphs/HD-CPparameter04.png" alt="HD-CPparameter04.png" />
</p>
</div>

<p>
You may be wondering at this point, the definition of cp is what,
exactly? Well, it's very closely related to lambda.
</p>

<p>
Considering a tree with no splits, we simply take the average of the
data, calculate RSS for that so-called tree, and let us call that RSS
for no splits. Then we can define <code>cp = lambda / RSS</code> (no splits).
</p>


<div class="figure">
<p><img src="../graphs/HD-CPparameter05.png" alt="HD-CPparameter05.png" />
</p>
</div>

<p>
When you're actually using cp in your R code, you don't need to think
exactly what it means&#x2013; just that small numbers of cp encourage large
trees, and large values of cp encourage small trees.
</p>

<p>
Let's go back to R now, and apply cross-validation to our training
data.
</p>
</div>
</div>

<div id="outline-container-orgheadline90" class="outline-3">
<h3 id="orgheadline90"><span class="section-number-3">3.6</span> Video 7: Cross-Validation</h3>
<div class="outline-text-3" id="text-3-6">
<p>
<b>Syntax Information</b>
</p>

<p>
In this video, we use (0:10)*0.001 to define the cp values that we
want to test in our model. Alternatively, we could replace this with
the sequence function seq(0,0.01,0.001) which we learned in
Unit 1. For some people, the sequence function is more intuitive, and
you should use whichever syntax makes more sense to you personally.
</p>

<p>
Now we know what CP is, we can go ahead and build one last tree using
cross validation. So we need to make sure first we have the required
libraries installed and in use.
</p>

<p>
So the first package is the "caret" package. And the second one we
need is the "e1071" package.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Load libraries for cross-validation..."</span>)
<span style="color: #db7093;">library</span>(caret)
<span style="color: #db7093;">library</span>(e1071)
</pre>
</div>

<pre class="example">
:: Load libraries for cross-validation...
</pre>

<p>
OK.
</p>

<p>
So we need to tell the caret package how exactly we want to do our
parameter tuning. There are actually quite a few ways of doing it. But
we're going to restrict ourselves in this course to just 10-fold cross
validation, as was explained in the lecture.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Number of folds..."</span>)
tr.control <span style="color: #db7093;">&lt;-</span> trainControl(method = <span style="color: #ff6a6a;">"cv"</span>, number = 10)
</pre>
</div>

<pre class="example">
:: Number of folds...
</pre>

<p>
Now we need to tell caret which range of cp parameters to try out. Now
remember that cp varies between 0 and 1. It's likely for any given
problem that we don't need to explore the whole range.
</p>

<p>
I happen to know, by the fact that I made this presentation ahead of
time, that the value of cp we're going to pick is very small.
</p>

<p>
So what I want to do is make a grid of cp values to try. And it will
be over the range of 0 to 0.01.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: cp values..."</span>)
cp.grid <span style="color: #db7093;">&lt;-</span> expand.grid( .cp = (0:10)*0.001)
</pre>
</div>

<pre class="example">
:: cp values...
</pre>

<p>
OK, so how does what I wrote led to that?
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: What did we just do?"</span>)
1*0.001
10*0.001
0:10
0:10 * 0.001
</pre>
</div>

<pre class="example">
 :: What did we just do?
[1] 0.001
[1] 0.01
 [1]  0  1  2  3  4  5  6  7  8  9 10
 [1] 0.000 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.010
</pre>

<p>
So those are the values of cp that caret will try. So let's store the
results of the cross validation fitting in a variable called tr.
</p>

<p>
And we'll use the train function. Predicting MEDV based on LAT, LON,
CRIM, zoning, industry, Charles River, pollution, rooms, age,
distance, distance from highways, tax, and pupil-teacher ratio. OK,
we're using the train data set. We're using trees (rpart), our train
control is what we just made before, and our tuning grid is the other
thing we just made, which we called cp.grid.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Cross-validation..."</span>)
tr <span style="color: #db7093;">&lt;-</span> train(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM +
                    AGE + DIS + RAD + TAX + PTRATIO, data = train,
            method = <span style="color: #ff6a6a;">"rpart"</span>, trControl = tr.control, tuneGrid =
                                                              cp.grid)
</pre>
</div>

<pre class="example">
:: Cross-validation...
</pre>

<p>
And it whirrs away. And what its doing there is it's trying all the
different values of cp that we asked it to. So we can see what it's
done but typing tr. You can see it tried 11 different values of cp.
</p>

<p>
And it decided that cp equals 0.001 was the best because it had the
best RMSE&#x2013; Root Mean Square Error. And it was 5.03 for 0.001. You see
that it's pretty insensitive to a particular value of cp.
</p>

<p>
So it's maybe not too important.
</p>

<p>
It's interesting though that the numbers are so low. I tried it for a
much larger range of cp values, and the best solutions are always very
close to 0. So it wants us to build a very detail-rich tree. So let's
see what the tree that that value of cp corresponds to is.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Extract tree..."</span>)
best.tree <span style="color: #db7093;">&lt;-</span> tr$finalModel
</pre>
</div>

<pre class="example">
:: Extract tree...
</pre>

<p>
And we can plot that tree. So that's the model that corresponds to
0.001. Plot it.
</p>

<p>
Wow, OK, so that's a very detailed tree.
</p>


<div id="orgparagraph21" class="figure">
<p><img src="../graphs/LocationCART-CV.png" alt="LocationCART-CV.png" />
</p>
<p><span class="figure-number">Figure 98:</span> Cross validation CP selected value for CART location model</p>
</div>

<p>
You can see that it looks pretty much like the same tree we had
before, initially. But then it starts to get much more detailed at the
bottom.
</p>

<p>
And in fact if you can see close enough, there's actually latitude and
longitude in there right down at the bottom as well. So maybe the tree
is finally going to beat the linear regression model.
</p>

<p>
Well, we can test it out the same way as we did before.
</p>

<div class="org-src-container">

<pre class="src src-R">writeLines(<span style="color: #ff6a6a;">"\n :: Make predictions..."</span>)
best.tree.pred <span style="color: #db7093;">&lt;-</span> predict(best.tree, newdata=test)
best.tree.sse <span style="color: #db7093;">&lt;-</span> sum((best.tree.pred - test$MEDV)^2)
best.tree.sse
</pre>
</div>

<pre class="example">
 null device
          1

 :: Make predictions...
[1] 3675.766
</pre>

<p>
That number is 3,675. So if you can remember from the last video, the
tree from the previous video actually only got something in the
4,000 and little more.
</p>

<p>
So not very good. So we have actually improved. This tree is better on
the testing set than the original tree we created.
</p>

<p>
But, you may also remember that the linear regression model did
actually better than that still. The linear regression SSE was more
around 3,030. So the best tree is not as good as the linear regression
model.
</p>

<p>
But cross validation did improve performance. So the takeaway is, I
guess, that trees aren't always the best method you have available to
you. But you should always try cross validating them to get as much
performance out of them as you can.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 30/06/2015</p>
<p class="author">Author: Sergio-Feliciano Mendoza-Barrera</p>
<p class="date">Created: 2015-08-30 Sun 06:48</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
