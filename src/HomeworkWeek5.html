<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2015-08-31 Mon 07:19 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>Assignment 5. Unit 5. Text Analytics</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Sergio-Feliciano Mendoza-Barrera" />
<meta  name="description" content="Assignment 5, unit 5. Text Analytics"
 />
<meta  name="keywords" content="R, data science, emacs, ESS, org-mode, assignment, text analytics" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Assignment 5. Unit 5. Text Analytics</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline38">1. Detecting vandalism on Wikipedia <code>[0/14]</code></a>
<ul>
<li><a href="#orgheadline3">1.1. <span class="todo nilTODO">TODO</span> Problem 1.1 - Bags of Words (1/1 point)</a></li>
<li><a href="#orgheadline6">1.2. <span class="todo nilTODO">TODO</span> Problem 1.2 - Bags of Words (2/2 points)</a></li>
<li><a href="#orgheadline8">1.3. <span class="todo nilTODO">TODO</span> Problem 1.3 - Bags of Words (1/1 point)</a></li>
<li><a href="#orgheadline11">1.4. <span class="todo nilTODO">TODO</span> Problem 1.4 - Bags of Words (2/2 points)</a></li>
<li><a href="#orgheadline14">1.5. <span class="todo nilTODO">TODO</span> Problem 1.5 - Bags of Words (2/2 points)</a></li>
<li><a href="#orgheadline17">1.6. <span class="todo nilTODO">TODO</span> Problem 1.6 - Bags of Words (2/2 points)</a></li>
<li><a href="#orgheadline19">1.7. <span class="todo nilTODO">TODO</span> Problem 1.7 - Bags of Words (1/1 point)</a></li>
<li><a href="#orgheadline20">1.8. <span class="todo nilTODO">TODO</span> Problem 1.8 - Bags of Words (1/1 point)</a></li>
<li><a href="#orgheadline22">1.9. <span class="todo nilTODO">TODO</span> Problem 2.1 - Problem-specific Knowledge (1/1 point)</a></li>
<li><a href="#orgheadline25">1.10. <span class="todo nilTODO">TODO</span> Problem 2.2 - Problem-Specific Knowledge (2/2 points)</a></li>
<li><a href="#orgheadline28">1.11. <span class="todo nilTODO">TODO</span> Problem 2.3 - Problem-Specific Knowledge (1/1 point)</a></li>
<li><a href="#orgheadline31">1.12. <span class="todo nilTODO">TODO</span> Problem 2.4 - Problem-Specific Knowledge (2/2 points)</a></li>
<li><a href="#orgheadline34">1.13. <span class="todo nilTODO">TODO</span> Problem 3.1 - Using Non-Textual Data (2/2 points)</a></li>
<li><a href="#orgheadline37">1.14. <span class="todo nilTODO">TODO</span> Problem 3.2 - Using Non-Textual Data (1/1 point)</a></li>
</ul>
</li>
<li><a href="#orgheadline84">2. Automating reviews in medicine <code>[0/19]</code></a>
<ul>
<li><a href="#orgheadline40">2.1. <span class="todo nilTODO">TODO</span> Problem 1.1 - Loading the Data (1/1 point)</a></li>
<li><a href="#orgheadline42">2.2. <span class="todo nilTODO">TODO</span> Problem 1.2 - Loading the Data (1/1 point)</a></li>
<li><a href="#orgheadline43">2.3. <span class="todo nilTODO">TODO</span> Problem 1.3 - Loading the Data (1/1 point)</a></li>
<li><a href="#orgheadline44">2.4. Answer</a></li>
<li><a href="#orgheadline49">2.5. <span class="todo nilTODO">TODO</span> Problem 2.1 - Preparing the Corpus (4/4 points)</a></li>
<li><a href="#orgheadline50">2.6. <span class="todo nilTODO">TODO</span> Problem 2.2 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline52">2.7. <span class="todo nilTODO">TODO</span> Problem 2.3 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline55">2.8. <span class="todo nilTODO">TODO</span> Problem 3.1 - Building a model (1/1 point)</a></li>
<li><a href="#orgheadline57">2.9. <span class="todo nilTODO">TODO</span> Problem 3.2 - Building a Model (1/1 point)</a></li>
<li><a href="#orgheadline59">2.10. <span class="todo nilTODO">TODO</span> Problem 3.3 - Building a Model (1/1 point)</a></li>
<li><a href="#orgheadline61">2.11. <span class="todo nilTODO">TODO</span> Problem 3.4 - Building a Model (2/2 points)</a></li>
<li><a href="#orgheadline63">2.12. <span class="todo nilTODO">TODO</span> Problem 3.5 - Building a Model (1/1 point)</a></li>
<li><a href="#orgheadline64">2.13. <span class="todo nilTODO">TODO</span> Problem 3.6 - Building a Model (1 point possible)</a></li>
<li><a href="#orgheadline71">2.14. <span class="todo nilTODO">TODO</span> Problem 3.7 - Building a Model (3/3 points)</a></li>
<li><a href="#orgheadline74">2.15. <span class="todo nilTODO">TODO</span> Problem 4.1 - Evaluating the model on the testing set (2/2 points)</a></li>
<li><a href="#orgheadline76">2.16. <span class="todo nilTODO">TODO</span> Problem 4.2 - Evaluating the Model on the Testing Set (2/2 points)</a></li>
<li><a href="#orgheadline77">2.17. <span class="todo nilTODO">TODO</span> part 5: decision-maker tradeoffs</a></li>
<li><a href="#orgheadline79">2.18. <span class="todo nilTODO">TODO</span> Problem 5.1 - Decision-Maker Tradeoffs (1/1 point)</a></li>
<li><a href="#orgheadline81">2.19. <span class="todo nilTODO">TODO</span> Problem 5.2 - Decision-Maker Tradeoffs (1/1 point)</a></li>
<li><a href="#orgheadline83">2.20. <span class="todo nilTODO">TODO</span> Problem 5.3 - Decision-Maker Tradeoffs (1/1 point)</a></li>
</ul>
</li>
<li><a href="#orgheadline156">3. Separating spam from ham (Part 1) <code>[0/31]</code></a>
<ul>
<li><a href="#orgheadline85">3.1. Important Note</a></li>
<li><a href="#orgheadline88">3.2. <span class="todo nilTODO">TODO</span> Problem 1.1 - Loading the Dataset (1/1 point)</a></li>
<li><a href="#orgheadline91">3.3. <span class="todo nilTODO">TODO</span> Problem 1.2 - Loading the Dataset (1/1 point)</a></li>
<li><a href="#orgheadline93">3.4. <span class="todo nilTODO">TODO</span> Problem 1.3 - Loading the Dataset (1/1 point)</a></li>
<li><a href="#orgheadline94">3.5. <span class="todo nilTODO">TODO</span> Problem 1.4 - Loading the Dataset (1 point possible)</a></li>
<li><a href="#orgheadline96">3.6. <span class="todo nilTODO">TODO</span> Problem 1.5 - Loading the Dataset (1/1 point)</a></li>
<li><a href="#orgheadline98">3.7. <span class="todo nilTODO">TODO</span> Problem 1.6 - Loading the Dataset (1/1 point)</a></li>
<li><a href="#orgheadline100">3.8. <span class="todo nilTODO">TODO</span> Problem 2.1 - Preparing the Corpus (2/2 points)</a></li>
<li><a href="#orgheadline102">3.9. <span class="todo nilTODO">TODO</span> Problem 2.2 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline104">3.10. <span class="todo nilTODO">TODO</span> Problem 2.3 - Preparing the Corpus (2/2 points)</a></li>
<li><a href="#orgheadline106">3.11. <span class="todo nilTODO">TODO</span> Problem 2.4 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline108">3.12. <span class="todo nilTODO">TODO</span> Problem 2.5 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline110">3.13. <span class="todo nilTODO">TODO</span> Problem 2.6 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline112">3.14. <span class="todo nilTODO">TODO</span> Problem 2.7 - Preparing the Corpus (1/1 point)</a></li>
<li><a href="#orgheadline119">3.15. <span class="todo nilTODO">TODO</span> Problem 3.1 - Building machine learning models (3/3 points)</a></li>
<li><a href="#orgheadline121">3.16. <span class="todo nilTODO">TODO</span> Problem 3.2 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline123">3.17. <span class="todo nilTODO">TODO</span> Problem 3.3 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline125">3.18. <span class="todo nilTODO">TODO</span> Problem 3.4 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline127">3.19. <span class="todo nilTODO">TODO</span> Problem 3.5 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline129">3.20. <span class="todo nilTODO">TODO</span> Problem 3.6 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline131">3.21. <span class="todo nilTODO">TODO</span> Problem 3.7 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline133">3.22. <span class="todo nilTODO">TODO</span> Problem 3.8 - Building Machine Learning Models (1/1 point)</a></li>
<li><a href="#orgheadline135">3.23. <span class="todo nilTODO">TODO</span> Problem 3.9 - Building Machine Learning Models (2/2 points)</a></li>
<li><a href="#orgheadline137">3.24. <span class="todo nilTODO">TODO</span> Problem 3.10 - Building Machine Learning Models (1 point possible)</a></li>
<li><a href="#orgheadline140">3.25. <span class="todo nilTODO">TODO</span> Problem 4.1 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline142">3.26. <span class="todo nilTODO">TODO</span> Problem 4.2 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline144">3.27. <span class="todo nilTODO">TODO</span> Problem 4.3 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline146">3.28. <span class="todo nilTODO">TODO</span> Problem 4.4 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline148">3.29. <span class="todo nilTODO">TODO</span> Problem 4.5 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline150">3.30. <span class="todo nilTODO">TODO</span> Problem 4.6 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline152">3.31. <span class="todo nilTODO">TODO</span> Problem 4.7 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline154">3.32. <span class="todo nilTODO">TODO</span> Problem 4.8 - Evaluating on the Test Set (1/1 point)</a></li>
<li><a href="#orgheadline155">3.33. Important Note</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="ABSTRACT">
<p>
Assignment 5. Text Analytics.
</p>

</div>

<div id="outline-container-orgheadline38" class="outline-2">
<h2 id="orgheadline38"><span class="section-number-2">1</span> Detecting vandalism on Wikipedia <code>[0/14]</code></h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="http://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> is a free online encyclopedia that anyone can edit and
contribute to. It is available in many languages and is growing all
the time. On the English language version of Wikipedia:
</p>

<ul class="org-ul">
<li>There are currently <a href="http://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia">4.7 million pages</a>.</li>

<li>There have been a total over <a href="http://en.wikipedia.org/wiki/Wikipedia:Pruning_article_revisions">760 million edits</a> (also called
revisions) over its lifetime.</li>

<li>There are approximately <a href="http://en.wikipedia.org/wiki/Wikipedia:WikiProject_Editing_trends/Raw_data/Revisions_per_day">130,000 edits per day</a>.</li>
</ul>

<p>
One of the consequences of being editable by anyone is that some
people vandalize pages. This can take the form of removing content,
adding promotional or inappropriate content, or more subtle shifts
that change the meaning of the article. With this many articles and
edits per day it is difficult for humans to detect all instances of
vandalism and revert (undo) them. As a result, Wikipedia uses bots -
computer programs that automatically revert edits that look like
vandalism. In this assignment we will attempt to develop a vandalism
detector that uses machine learning to distinguish between a valid
edit and vandalism.
</p>

<p>
The data for this problem is based on the revision history of the page
<a href="http://en.wikipedia.org/wiki/Language">Language</a>. Wikipedia provides a history for each page that consists of
the state of the page at each revision. Rather than manually
considering each revision, a script was run that checked whether edits
stayed or were reverted. If a change was eventually reverted then that
revision is marked as vandalism. This may result in some
misclassifications, but the script performs well enough for our
needs.
</p>

<p>
As a result of this preprocessing, some common processing tasks have
already been done, including lower-casing and punctuation removal. The
columns in the dataset are:
</p>

<ul class="org-ul">
<li><b>Vandal</b> = 1 if this edit was vandalism, 0 if not.</li>

<li>*Minor = 1 if the user marked this edit as a "minor edit", 0 if not.</li>

<li><b>Loggedin</b> = 1 if the user made this edit while using a Wikipedia
account, 0 if they did not.</li>

<li><b>Added</b> = The unique words added.</li>

<li><b>Removed</b> = The unique words removed.</li>
</ul>

<p>
Notice the repeated use of unique. The data we have available is not
the traditional bag of words - rather it is the set of words that were
removed or added. For example, if a word was removed multiple times in
a revision it will only appear one time in the <code>Removed</code> column.
</p>
</div>

<div id="outline-container-orgheadline3" class="outline-3">
<h3 id="orgheadline3"><span class="section-number-3">1.1</span> <span class="todo TODO">TODO</span> Problem 1.1 - Bags of Words (1/1 point)</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Load the data <code>wiki.csv</code> with the option <code>stringsAsFactors = FALSE</code>, calling
the data frame <code>wiki</code>. Convert the <code>Vandal</code> column to a factor using
the command <code>wiki$Vandal = as.factor(wiki$Vandal)</code>.
</p>
</div>

<div id="outline-container-orgheadline2" class="outline-4">
<h4 id="orgheadline2"><span class="section-number-4">1.1.1</span> Question</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
How many cases of vandalism were detected in the history of this page?
</p>
</div>

<div id="outline-container-orgheadline1" class="outline-5">
<h5 id="orgheadline1"><span class="section-number-5">1.1.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-1-1-1">
<p>
1815 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can load the data using the command:
</p>

<p>
<code>wiki = read.csv("wiki.csv", stringsAsFactors=FALSE)</code>
</p>

<p>
And then convert Vandal to a factor with the command:
</p>

<p>
<code>wiki$Vandal = as.factor(wiki$Vandal)</code>
</p>

<p>
You can then use the table command to see how many cases of Vandalism
there are:
</p>

<p>
<code>table(wiki$Vandal)</code>
</p>

<p>
There are 1815 observations with value 1, which denotes vandalism.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline6" class="outline-3">
<h3 id="orgheadline6"><span class="section-number-3">1.2</span> <span class="todo TODO">TODO</span> Problem 1.2 - Bags of Words (2/2 points)</h3>
<div class="outline-text-3" id="text-1-2">
<p>
We will now use the bag of words approach to build a model. We have
two columns of textual data, with different meanings. For example,
adding rude words has a different meaning to removing rude
words. We'll start like we did in class by building a document term
matrix from the Added column. The text already is lowercase and
stripped of punctuation. So to pre-process the data, just complete the
following four steps:
</p>

<ol class="org-ol">
<li>Create the corpus for the Added column, and call it <code>corpusAdded</code>.</li>

<li>Remove the English-language stopwords.</li>

<li>Stem the words.</li>

<li>Build the <code>DocumentTermMatrix</code>, and call it <code>dtmAdded</code>.</li>
</ol>

<p>
If the code <code>length(stopwords("english"))</code> does not return 174 for you,
then please run the line of code in , which will store the
standard stop words in a variable called sw. When removing stop words,
use <code>tm_map(corpusAdded, removeWords, sw)</code> instead of
<code>tm_map(corpusAdded, removeWords, stopwords("english"))</code>.
</p>
</div>

<div id="outline-container-orgheadline5" class="outline-4">
<h4 id="orgheadline5"><span class="section-number-4">1.2.1</span> Question</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
How many terms appear in <code>dtmAdded</code>?
</p>
</div>

<div id="outline-container-orgheadline4" class="outline-5">
<h5 id="orgheadline4"><span class="section-number-5">1.2.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-2-1-1">
<p>
6675 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The following are the commands needed to execute these four steps:
</p>

<p>
<code>corpusAdded = Corpus(VectorSource(wiki$Added))</code>
</p>

<p>
<code>corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))</code>
</p>

<p>
<code>corpusAdded = tm_map(corpusAdded, stemDocument)</code>
</p>

<p>
<code>dtmAdded = DocumentTermMatrix(corpusAdded)</code>
</p>

<p>
If you type dtmAdded, you can see that there are 6675 terms.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline8" class="outline-3">
<h3 id="orgheadline8"><span class="section-number-3">1.3</span> <span class="todo TODO">TODO</span> Problem 1.3 - Bags of Words (1/1 point)</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Filter out sparse terms by keeping only terms that appear in 0.3% or
more of the revisions, and call the new matrix sparseAdded. How many
terms appear in <code>sparseAdded</code>?
</p>
</div>

<div id="outline-container-orgheadline7" class="outline-4">
<h4 id="orgheadline7"><span class="section-number-4">1.3.1</span> Answer</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
166 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can create the sparse matrix with the follow line:
</p>

<p>
<code>sparseAdded = removeSparseTerms(dtmAdded, 0.997)</code>
</p>

<p>
If you type sparseAdded, you can see that there are 166 terms.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline11" class="outline-3">
<h3 id="orgheadline11"><span class="section-number-3">1.4</span> <span class="todo TODO">TODO</span> Problem 1.4 - Bags of Words (2/2 points)</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Convert sparseAdded to a data frame called wordsAdded, and then
prepend all the words with the letter A, by using the command:
</p>

<p>
<code>colnames(wordsAdded) = paste("A", colnames(wordsAdded))</code>
</p>

<p>
<b>Explanation</b>
</p>

<p>
You need to type the following two commands:
</p>

<p>
<code>wordsAdded = as.data.frame(as.matrix(sparseAdded))</code>
</p>

<p>
<code>colnames(wordsAdded) = paste("A", colnames(wordsAdded))</code>
</p>

<p>
Now repeat all of the steps we've done so far (create a corpus, remove
stop words, stem the document, create a sparse document term matrix,
and convert it to a data frame) to create a Removed bag-of-words
dataframe, called wordsRemoved, except this time, prepend all of the
words with the letter R:
</p>

<p>
<code>colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))</code>
</p>
</div>

<div id="outline-container-orgheadline10" class="outline-4">
<h4 id="orgheadline10"><span class="section-number-4">1.4.1</span> Question</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
How many words are in the wordsRemoved data frame?
</p>
</div>

<div id="outline-container-orgheadline9" class="outline-5">
<h5 id="orgheadline9"><span class="section-number-5">1.4.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-4-1-1">
<p>
162 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
To repeat the steps for the Removed column, use the following
commands:
</p>

<p>
<code>corpusRemoved = Corpus(VectorSource(wiki$Removed))</code>
</p>

<p>
<code>corpusRemoved = tm_map(corpusRemoved, removeWords,
stopwords("english"))</code>
</p>

<p>
<code>corpusRemoved = tm_map(corpusRemoved, stemDocument)</code>
</p>

<p>
<code>dtmRemoved = DocumentTermMatrix(corpusRemoved)</code>
</p>

<p>
<code>sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)</code>
</p>

<p>
<code>wordsRemoved = as.data.frame(as.matrix(sparseRemoved))</code>
</p>

<p>
<code>colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))</code>
</p>

<p>
To see that there are 162 words in the wordsRemoved data frame, you
can type ncol(wordsRemoved) in your R console.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline14" class="outline-3">
<h3 id="orgheadline14"><span class="section-number-3">1.5</span> <span class="todo TODO">TODO</span> Problem 1.5 - Bags of Words (2/2 points)</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Combine the two data frames into a data frame called wikiWords with
the following line of code:
</p>

<p>
<code>wikiWords = cbind(wordsAdded, wordsRemoved)</code>
</p>

<p>
The cbind function combines two sets of variables for the same
observations into one data frame. Then add the Vandal column (HINT:
remember how we added the dependent variable back into our data frame
in the Twitter lecture). Set the random seed to 123 and then split the
data set using sample.split from the "caTools" package to put 70% in
the training set.
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can combine the two data frames by using the command:
</p>

<p>
<code>wikiWords = cbind(wordsAdded, wordsRemoved)</code>
</p>

<p>
And then add the Vandal variable by using the command:
</p>

<p>
<code>wikiWords$Vandal = wiki$Vandal</code>
</p>

<p>
To split the data, you can use the following commands:
</p>

<p>
<code>library(caTools)</code>
</p>

<p>
<code>set.seed(123)</code>
</p>

<p>
<code>spl = sample.split(wikiWords$Vandal, SplitRatio = 0.7)</code>
</p>

<p>
<code>wikiTrain = subset(wikiWords, spl==TRUE)</code>
</p>

<p>
<code>wikiTest = subset(wikiWords, spl==FALSE)</code>
</p>
</div>

<div id="outline-container-orgheadline13" class="outline-4">
<h4 id="orgheadline13"><span class="section-number-4">1.5.1</span> Question</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
What is the accuracy on the test set of a baseline method that always
predicts "not vandalism" (the most frequent outcome)?
</p>
</div>

<div id="outline-container-orgheadline12" class="outline-5">
<h5 id="orgheadline12"><span class="section-number-5">1.5.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-5-1-1">
<p>
0.5313844 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can compute this number using the table command:
</p>

<p>
<code>table(wikiTest$Vandal)</code>
</p>

<p>
It outputs that there are 618 observations with value 0, and 545
observations with value 1. The accuracy of the baseline method would
be <code>618/(618+545) = 0.531</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline17" class="outline-3">
<h3 id="orgheadline17"><span class="section-number-3">1.6</span> <span class="todo TODO">TODO</span> Problem 1.6 - Bags of Words (2/2 points)</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Build a CART model to predict Vandal, using all of the other variables
as independent variables. Use the training set to build the model and
the default parameters (don't set values for <code>minbucket</code> or <code>cp</code>).
</p>
</div>

<div id="outline-container-orgheadline16" class="outline-4">
<h4 id="orgheadline16"><span class="section-number-4">1.6.1</span> Question</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
What is the accuracy of the model on the test set, using a threshold
of 0.5? (Remember that if you add the argument ~type="class"~ when
making predictions, the output of predict will automatically use a
threshold of 0.5.)
</p>
</div>

<div id="outline-container-orgheadline15" class="outline-5">
<h5 id="orgheadline15"><span class="section-number-5">1.6.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-6-1-1">
<p>
0.5417025 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can build the CART model with the following command:
</p>

<p>
<code>wikiCART = rpart(Vandal ~ ., data=wikiTrain, method="class")</code>
</p>

<p>
And then make predictions on the test set:
</p>

<p>
<code>testPredictCART = predict(wikiCART, newdata=wikiTest, type="class")</code>
</p>

<p>
And compute the accuracy by comparing the actual values to the
predicted values:
</p>

<p>
<code>table(wikiTest$Vandal, testPredictCART)</code>
</p>

<p>
The accuracy is <code>(618+12)/(618+533+12) = 0.5417</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline19" class="outline-3">
<h3 id="orgheadline19"><span class="section-number-3">1.7</span> <span class="todo TODO">TODO</span> Problem 1.7 - Bags of Words (1/1 point)</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Plot the CART tree. How many word stems does the CART model use?
</p>
</div>

<div id="outline-container-orgheadline18" class="outline-4">
<h4 id="orgheadline18"><span class="section-number-4">1.7.1</span> Answer</h4>
<div class="outline-text-4" id="text-1-7-1">
<p>
2 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
If you plot the tree with prp(wikiCART), you can see that the tree
uses two words: "R arbitr" and "R thousa".
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline20" class="outline-3">
<h3 id="orgheadline20"><span class="section-number-3">1.8</span> <span class="todo TODO">TODO</span> Problem 1.8 - Bags of Words (1/1 point)</h3>
<div class="outline-text-3" id="text-1-8">
<p>
Given the performance of the CART model relative to the baseline, what
is the best explanation of these results?
</p>

<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> We have a bad testing/training split.</li>

<li class="off"><code>[&#xa0;]</code> The CART model overfits to the training set.</li>

<li class="on"><code>[X]</code> Although it beats the baseline, bag of words is not very
predictive for this problem. - correct</li>

<li class="off"><code>[&#xa0;]</code> We over-sparsified the document-term matrix.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
There is no reason to think there was anything wrong with the
split. CART did not overfit, which you can check by computing the
accuracy of the model on the training set. Over-sparsification is
plausible but unlikely, since we selected a very high sparsity
parameter. The only conclusion left is simply that bag of words didn't
work very well in this case.
</p>
</div>
</div>

<div id="outline-container-orgheadline22" class="outline-3">
<h3 id="orgheadline22"><span class="section-number-3">1.9</span> <span class="todo TODO">TODO</span> Problem 2.1 - Problem-specific Knowledge (1/1 point)</h3>
<div class="outline-text-3" id="text-1-9">
<p>
We weren't able to improve on the baseline using the raw textual
information. More specifically, the words themselves were not
useful. There are other options though, and in this section we will
try two techniques - identifying a key class of words, and counting
words.
</p>

<p>
The key class of words we will use are website addresses. "Website
addresses" (also known as URLs - Uniform Resource Locators) are
comprised of two main parts. An example would be
"<a href="http://www.google.com/">http://www.google.com/</a>". The first part is the protocol, which is
usually "http" (HyperText Transfer Protocol). The second part is the
address of the site, e.g. "www.google.com". We have stripped all
punctuation so links to websites appear in the data as one word,
e.g. "httpwwwgooglecom". We hypothesize that given that a lot of
vandalism seems to be adding links to promotional or irrelevant
websites, the presence of a web address is a sign of vandalism.
</p>

<p>
We can search for the presence of a web address in the words added by
searching for "http" in the Added column. The grepl function returns
TRUE if a string is found in another string, e.g.
</p>

<p>
<code>grepl("cat","dogs and cats",fixed=TRUE) # TRUE</code>
</p>

<p>
<code>grepl("cat","dogs and rats",fixed=TRUE) # FALSE</code>
</p>

<p>
Create a copy of your dataframe from the previous question:
</p>

<p>
<code>wikiWords2 = wikiWords</code>
</p>

<p>
Make a new column in wikiWords2 that is 1 if "http" was in Added:
</p>

<p>
<code>wikiWords2$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)</code>
</p>
</div>

<div id="outline-container-orgheadline21" class="outline-4">
<h4 id="orgheadline21"><span class="section-number-4">1.9.1</span> Question</h4>
<div class="outline-text-4" id="text-1-9-1">
<p>
Based on this new column, how many revisions added a link?
</p>

<p>
<b>*</b>
</p>

<p>
217 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can find this number by typing table(wikiWords2$HTTP), and seeing
that there are 217 observations with value 1.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline25" class="outline-3">
<h3 id="orgheadline25"><span class="section-number-3">1.10</span> <span class="todo TODO">TODO</span> Problem 2.2 - Problem-Specific Knowledge (2/2 points)</h3>
<div class="outline-text-3" id="text-1-10">
<p>
In problem 1.5, you computed a vector called "spl" that identified the
observations to put in the training and testing sets. Use that
variable (do not recompute it with sample.split) to make new training
and testing sets:
</p>

<p>
<code>wikiTrain2 = subset(wikiWords2, spl==TRUE)</code>
</p>

<p>
<code>wikiTest2 = subset(wikiWords2, spl==FALSE)</code>
</p>

<p>
Then create a new CART model using this new variable as one of the
independent variables.
</p>
</div>

<div id="outline-container-orgheadline24" class="outline-4">
<h4 id="orgheadline24"><span class="section-number-4">1.10.1</span> Question</h4>
<div class="outline-text-4" id="text-1-10-1">
<p>
What is the new accuracy of the CART model on the test set, using a
threshold of 0.5?
</p>
</div>

<div id="outline-container-orgheadline23" class="outline-5">
<h5 id="orgheadline23"><span class="section-number-5">1.10.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-10-1-1">
<p>
0.5726569 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can compute this by running the following commands:
</p>

<p>
<code>wikiCART2 = rpart(Vandal ~ ., data=wikiTrain2, method="class")</code>
</p>

<p>
<code>testPredictCART2 = predict(wikiCART2, newdata=wikiTest2,
type="class")</code>
</p>

<p>
<code>table(wikiTest2$Vandal, testPredictCART2)</code>
</p>

<p>
Then the accuracy is
</p>

<p>
<code>(609+57)/(609+9+488+57) = 0.5726569</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline28" class="outline-3">
<h3 id="orgheadline28"><span class="section-number-3">1.11</span> <span class="todo TODO">TODO</span> Problem 2.3 - Problem-Specific Knowledge (1/1 point)</h3>
<div class="outline-text-3" id="text-1-11">
<p>
Another possibility is that the number of words added and removed is
predictive, perhaps more so than the actual words themselves. We
already have a word count available in the form of the document-term
matrices (DTMs).
</p>

<p>
Sum the rows of <code>dtmAdded</code> and <code>dtmRemoved</code> and add them as new variables
in your data frame <code>wikiWords2</code> (called <code>NumWordsAdded</code> and
<code>NumWordsRemoved</code>) by using the following commands:
</p>

<p>
<code>wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))</code>
</p>

<p>
<code>wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))</code>
</p>
</div>

<div id="outline-container-orgheadline27" class="outline-4">
<h4 id="orgheadline27"><span class="section-number-4">1.11.1</span> Question</h4>
<div class="outline-text-4" id="text-1-11-1">
<p>
What is the average number of words added?
</p>
</div>

<div id="outline-container-orgheadline26" class="outline-5">
<h5 id="orgheadline26"><span class="section-number-5">1.11.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-11-1-1">
<p>
4.050052 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can get this answer with <code>mean(wikiWords2$NumWordsAdded)</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline31" class="outline-3">
<h3 id="orgheadline31"><span class="section-number-3">1.12</span> <span class="todo TODO">TODO</span> Problem 2.4 - Problem-Specific Knowledge (2/2 points)</h3>
<div class="outline-text-3" id="text-1-12">
<p>
In problem 1.5, you computed a vector called <code>spl</code> that identified the
observations to put in the training and testing sets. Use that
variable (do not recompute it with <code>sample.split</code>) to make new training
and testing sets with <code>wikiWords2</code>. Create the CART model again (using
the training set and the default parameters).
</p>
</div>

<div id="outline-container-orgheadline30" class="outline-4">
<h4 id="orgheadline30"><span class="section-number-4">1.12.1</span> Question</h4>
<div class="outline-text-4" id="text-1-12-1">
<p>
What is the new accuracy of the CART model on the test set?
</p>
</div>

<div id="outline-container-orgheadline29" class="outline-5">
<h5 id="orgheadline29"><span class="section-number-5">1.12.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-12-1-1">
<p>
0.6552021 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
To split the data again, use the following commands:
</p>

<p>
<code>wikiTrain3 = subset(wikiWords2, spl==TRUE)</code>
</p>

<p>
<code>wikiTest3 = subset(wikiWords2, spl==FALSE)</code>
</p>

<p>
You can compute the accuracy of the new CART model with the following
commands:
</p>

<p>
<code>wikiCART3 = rpart(Vandal ~ ., data=wikiTrain3, method="class")</code>
</p>

<p>
<code>testPredictCART3 = predict(wikiCART3, newdata=wikiTest3, type="class")</code>
</p>

<p>
<code>table(wikiTest3$Vandal, testPredictCART3)</code>
</p>

<p>
The accuracy is
~ (514+248)/(514+104+297+248) = 0.6552021~.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline34" class="outline-3">
<h3 id="orgheadline34"><span class="section-number-3">1.13</span> <span class="todo TODO">TODO</span> Problem 3.1 - Using Non-Textual Data (2/2 points)</h3>
<div class="outline-text-3" id="text-1-13">
<p>
We have two pieces of <b>metadata</b> (data about data) that we haven't yet
used. Make a copy of <code>wikiWords2</code>, and call it <code>wikiWords3</code>:
</p>

<p>
<code>wikiWords3 = wikiWords2</code>
</p>

<p>
Then add the two original variables Minor and Loggedin to this new
data frame:
</p>

<p>
<code>wikiWords3$Minor = wiki$Minor</code>
</p>

<p>
<code>wikiWords3$Loggedin = wiki$Loggedin</code>
</p>

<p>
In problem 1.5, you computed a vector called <code>spl</code> that identified the
observations to put in the training and testing sets. Use that
variable (do not recompute it with <code>sample.split</code>) to make new training
and testing sets with <code>wikiWords3</code>.
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be done with the following two commands:
</p>

<p>
<code>wikiTrain4 = subset(wikiWords3, spl==TRUE)</code>
</p>

<p>
<code>wikiTest4 = subset(wikiWords3, spl==FALSE)</code>
</p>
</div>

<div id="outline-container-orgheadline33" class="outline-4">
<h4 id="orgheadline33"><span class="section-number-4">1.13.1</span> Question</h4>
<div class="outline-text-4" id="text-1-13-1">
<p>
Build a CART model using all the training data. What is the accuracy
of the model on the test set?
</p>
</div>

<div id="outline-container-orgheadline32" class="outline-5">
<h5 id="orgheadline32"><span class="section-number-5">1.13.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-13-1-1">
<p>
0.7188306 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This model can be built and evaluated using the following commands:
</p>

<p>
<code>wikiCART4 = rpart(Vandal ~ ., data=wikiTrain4, method="class")</code>
</p>

<p>
<code>predictTestCART4 = predict(wikiCART4, newdata=wikiTest4,
type="class")</code>
</p>

<p>
<code>table(wikiTest4$Vandal, predictTestCART4)</code>
</p>

<p>
The accuracy of the model is
<code>(595+241)/(595+23+304+241) = 0.7188306</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline37" class="outline-3">
<h3 id="orgheadline37"><span class="section-number-3">1.14</span> <span class="todo TODO">TODO</span> Problem 3.2 - Using Non-Textual Data (1/1 point)</h3>
<div class="outline-text-3" id="text-1-14">
<p>
There is a substantial difference in the accuracy of the model using
the meta data. Is this because we made a more complicated model?
</p>
</div>

<div id="outline-container-orgheadline36" class="outline-4">
<h4 id="orgheadline36"><span class="section-number-4">1.14.1</span> Question</h4>
<div class="outline-text-4" id="text-1-14-1">
<p>
Plot the CART tree. How many splits are there in the tree?
</p>
</div>

<div id="outline-container-orgheadline35" class="outline-5">
<h5 id="orgheadline35"><span class="section-number-5">1.14.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-1-14-1-1">
<p>
3 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can plot the tree with <code>prp(wikiCART4)</code>. The first split is on the
variable <code>Loggedin</code>, the second split is on the number of words added,
and the third split is on the number of words removed.
</p>

<p>
By adding new independent variables, we were able to significantly
improve our accuracy without making the model more complicated!
</p>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline84" class="outline-2">
<h2 id="orgheadline84"><span class="section-number-2">2</span> Automating reviews in medicine <code>[0/19]</code></h2>
<div class="outline-text-2" id="text-2">
<p>
The medical literature is enormous. Pubmed, a database of medical
publications maintained by the U.S. National Library of Medicine, has
indexed over 23 million medical publications. Further, the rate of
medical publication has increased over time, and now there are nearly
1 million new publications in the field each year, or more than one
per minute.
</p>

<p>
The large size and fast-changing nature of the medical literature has
increased the need for reviews, which search databases like Pubmed for
papers on a particular topic and then report results from the papers
found. While such reviews are often performed manually, with multiple
people reviewing each search result, this is tedious and time
consuming. In this problem, we will see how text analytics can be used
to automate the process of information retrieval.
</p>

<p>
The dataset consists of the titles (variable title) and abstracts
(variable abstract) of papers retrieved in a <a href="http://www.ncbi.nlm.nih.gov/pubmed">Pubmed</a> search. Each
search result is labeled with whether the paper is a clinical trial
testing a drug therapy for cancer (variable <code>trial</code>). These labels were
obtained by two people reviewing each search result and accessing the
actual paper if necessary, as part of a literature review of clinical
trials testing drug therapies for advanced and metastatic breast
cancer.
</p>
</div>

<div id="outline-container-orgheadline40" class="outline-3">
<h3 id="orgheadline40"><span class="section-number-3">2.1</span> <span class="todo TODO">TODO</span> Problem 1.1 - Loading the Data (1/1 point)</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Load clinical_trial.csv into a data frame called trials (remembering
to add the argument <code>stringsAsFactors=FALSE</code>), and investigate the data
frame with <code>summary()</code> and <code>str()</code>.
</p>

<p>
IMPORTANT NOTE: Some students have been getting errors like "invalid
multibyte string" when performing certain parts of this homework
question. If this is happening to you, use the argument
<code>(fileEncoding="latin1")</code> when reading in the file with <code>read.csv</code>. This
should cause those errors to go away.
</p>

<p>
We can use R's string functions to learn more about the titles and
abstracts of the located papers. The <code>nchar()</code> function counts the
number of characters in a piece of text. Using the <code>nchar()</code> function on
the variables in the data frame, answer the following questions:
</p>

<p>
How many characters are there in the longest abstract? (Longest here
is defined as the abstract with the largest number of characters.)
</p>
</div>

<div id="outline-container-orgheadline39" class="outline-4">
<h4 id="orgheadline39"><span class="section-number-4">2.1.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
3708 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can load the data set into R with the following command:
</p>

<p>
<code>trials = read.csv("clinical_trial.csv", stringsAsFactors=FALSE)</code>
</p>

<p>
From <code>summary(nchar(trials$abstract))</code> or <code>max(nchar(trials$abstract))</code>,
we can read the maximum length.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline42" class="outline-3">
<h3 id="orgheadline42"><span class="section-number-3">2.2</span> <span class="todo TODO">TODO</span> Problem 1.2 - Loading the Data (1/1 point)</h3>
<div class="outline-text-3" id="text-2-2">
<p>
How many search results provided no abstract? (HINT: A search result
provided no abstract if the number of characters in the abstract field
is zero.)
</p>
</div>

<div id="outline-container-orgheadline41" class="outline-4">
<h4 id="orgheadline41"><span class="section-number-4">2.2.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
112 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
From <code>table(nchar(trials$abstract) == 0)</code> or
<code>sum(nchar(trials$abstract) == 0)</code>, we can find the number of missing
abstracts.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline43" class="outline-3">
<h3 id="orgheadline43"><span class="section-number-3">2.3</span> <span class="todo TODO">TODO</span> Problem 1.3 - Loading the Data (1/1 point)</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Find the observation with the minimum number of characters in the
title (the variable "title") out of all of the observations in this
dataset. What is the text of the title of this article? Include
capitalization and punctuation in your response, but don't include the
quotes.
</p>
</div>
</div>

<div id="outline-container-orgheadline44" class="outline-3">
<h3 id="orgheadline44"><span class="section-number-3">2.4</span> Answer</h3>
<div class="outline-text-3" id="text-2-4">
<p>
A decade of letrozole: FACE. - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
To identify which title is the shortest, we can use
</p>

<p>
<code>which.min(nchar(trials$title))</code>
</p>

<p>
From this, we know the 1258th title is the shortest. We can access
this title with <code>trials$title[1258]</code>.
</p>
</div>
</div>

<div id="outline-container-orgheadline49" class="outline-3">
<h3 id="orgheadline49"><span class="section-number-3">2.5</span> <span class="todo TODO">TODO</span> Problem 2.1 - Preparing the Corpus (4/4 points)</h3>
<div class="outline-text-3" id="text-2-5">
<p>
Because we have both title and abstract information for trials, we
need to build two corpera instead of one. Name them <code>corpusTitle</code> and
<code>corpusAbstract</code>.
</p>

<p>
Following the commands from lecture, perform the following tasks (you
might need to load the "tm" package first if it isn't already
loaded). Make sure to perform them in this order.
</p>

<ol class="org-ol">
<li>Convert the <code>title</code> variable to <code>corpusTitle</code> and the abstract
<code>variable</code> to <code>corpusAbstract</code>.</li>

<li>Convert <code>corpusTitle</code> and <code>corpusAbstract</code> to lowercase. After
performing this step, remember to run the lines:</li>
</ol>

<p>
<code>corpusTitle = tm_map(corpusTitle, PlainTextDocument)</code>
</p>

<p>
<code>corpusAbstract = tm_map(corpusAbstract, PlainTextDocument)</code>
</p>

<ol class="org-ol">
<li>Remove the punctuation in <code>corpusTitle</code> and <code>corpusAbstract</code>.</li>

<li>Remove the English language stop words from <code>corpusTitle</code> and <code>corpusAbstract</code>.</li>

<li>Stem the words in <code>corpusTitle</code> and <code>corpusAbstract</code> (each stemming
might take a few minutes).</li>

<li>Build a document term matrix called <code>dtmTitle</code> from <code>corpusTitle</code> and
<code>dtmAbstract</code> from <code>corpusAbstract</code>.</li>

<li>Limit <code>dtmTitle</code> and <code>dtmAbstract</code> to terms with sparseness of at most
95% (aka terms that appear in at least 5% of documents).</li>

<li>Convert <code>dtmTitle</code> and <code>dtmAbstract</code> to data frames (keep the names
<code>dtmTitle</code> and <code>dtmAbstract</code>).</li>
</ol>

<p>
If the code <code>length(stopwords("english"))</code> does not return 174 for
you, then please run the line of code in <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/stopwords.txt">this file</a>, which will store
the standard stop words in a variable called sw. When removing stop
words, use <code>tm_map(corpusTitle, removeWords, sw)</code> and
<code>tm_map(corpusAbstract, removeWords, sw)</code> instead of
<code>tm_map(corpusTitle, removeWords, stopwords("english"))</code> and
<code>tm_map(corpusAbstract, removeWords, stopwords("english"))</code>.
</p>

<p>
<b>Explanation</b>
</p>

<p>
Below we provide the code for <code>corpusTitle</code>; only minor modifications
are needed to build <code>corpusAbstract</code>.
</p>

<p>
<code>corpusTitle = Corpus(VectorSource(trials$title))</code>
</p>

<p>
<code>corpusTitle = tm_map(corpusTitle, tolower)</code>
</p>

<p>
<code>corpusTitle = tm_map(corpusTitle, PlainTextDocument)</code>
</p>

<p>
<code>corpusTitle = tm_map(corpusTitle, removePunctuation)</code>
</p>

<p>
<code>corpusTitle = tm_map(corpusTitle, removeWords, stopwords("english"))</code>
</p>

<p>
<code>corpusTitle = tm_map(corpusTitle, stemDocument)</code>
</p>

<p>
<code>dtmTitle = DocumentTermMatrix(corpusTitle)</code>
</p>

<p>
<code>dtmTitle = removeSparseTerms(dtmTitle, 0.95)</code>
</p>

<p>
<code>dtmTitle = as.data.frame(as.matrix(dtmTitle))</code>
</p>
</div>

<div id="outline-container-orgheadline46" class="outline-4">
<h4 id="orgheadline46"><span class="section-number-4">2.5.1</span> Question</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
How many terms remain in dtmTitle after removing sparse terms (aka how
many columns does it have)?
</p>
</div>

<div id="outline-container-orgheadline45" class="outline-5">
<h5 id="orgheadline45"><span class="section-number-5">2.5.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-5-1-1">
<p>
31 - correct
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline48" class="outline-4">
<h4 id="orgheadline48"><span class="section-number-4">2.5.2</span> Question</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
How many terms remain in dtmAbstract?
</p>
</div>

<div id="outline-container-orgheadline47" class="outline-5">
<h5 id="orgheadline47"><span class="section-number-5">2.5.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-5-2-1">
<p>
335 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
These can be read from <code>str(dtmTitle)</code> and <code>str(dtmAbstract)</code>. Other than
<code>str()</code>, the <code>dim()</code> or <code>ncol()</code> functions could have been used. If you used
<code>(fileEncoding="latin1")</code> when reading in the datafile, you'll have a few
extra terms in <code>dtmAbstract</code>, but you should get the answer correct.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline50" class="outline-3">
<h3 id="orgheadline50"><span class="section-number-3">2.6</span> <span class="todo TODO">TODO</span> Problem 2.2 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-2-6">
<p>
What is the most likely reason why <code>dtmAbstract</code> has so many more terms
than <code>dtmTitle</code>?
</p>

<ul class="org-ul">
<li class="on"><code>[X]</code> Abstracts tend to have many more words than titles - correct</li>

<li class="off"><code>[&#xa0;]</code> Abstracts tend to have a much wider vocabulary than titles</li>

<li class="off"><code>[&#xa0;]</code> More papers have abstracts than titles</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
Because titles are so short, a word needs to be very common to appear
in 5% of titles. Because abstracts have many more words, a word can be
much less common and still appear in 5% of abstracts.
</p>

<p>
While abstracts may have wider vocabulary, this is a secondary
effect. As we saw in the previous subsection, all papers have titles,
but not all have abstracts.
</p>
</div>
</div>

<div id="outline-container-orgheadline52" class="outline-3">
<h3 id="orgheadline52"><span class="section-number-3">2.7</span> <span class="todo TODO">TODO</span> Problem 2.3 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-2-7">
<p>
What is the most frequent word stem across all the abstracts? Hint:
you can use colSums() to compute the frequency of a word across all
the abstracts.
</p>
</div>

<div id="outline-container-orgheadline51" class="outline-4">
<h4 id="orgheadline51"><span class="section-number-4">2.7.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
patient - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
We can compute the column sums and then identify the most common one
with:
</p>

<p>
<code>csAbstract = colSums(dtmAbstract)</code>
</p>

<p>
<code>which.max(csAbstract)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline55" class="outline-3">
<h3 id="orgheadline55"><span class="section-number-3">2.8</span> <span class="todo TODO">TODO</span> Problem 3.1 - Building a model (1/1 point)</h3>
<div class="outline-text-3" id="text-2-8">
<p>
We want to combine dtmTitle and dtmAbstract into a single data frame
to make predictions. However, some of the variables in these data
frames have the same names. To fix this issue, run the following
commands:
</p>

<p>
<code>colnames(dtmTitle) = paste0("T", colnames(dtmTitle))</code>
</p>

<p>
<code>colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))</code>
</p>
</div>

<div id="outline-container-orgheadline54" class="outline-4">
<h4 id="orgheadline54"><span class="section-number-4">2.8.1</span> Question</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
What was the effect of these functions?
</p>
</div>

<div id="outline-container-orgheadline53" class="outline-5">
<h5 id="orgheadline53"><span class="section-number-5">2.8.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-8-1-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> Removing the words that are in common between the titles and the
abstracts.</li>

<li class="on"><code>[X]</code> Adding the letter T in front of all the title variable names and
adding the letter A in front of all the abstract variable
names. - correct</li>

<li class="off"><code>[&#xa0;]</code> Adding the letter T in front of all the title variable names
that also appear in the abstract data frame, and adding an A in
front of all the abstract variable names that appear in the title
data frame.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The first line pastes a T at the beginning of each column name for
<code>dtmTitle</code>, which are the variable names. The second line does something
similar for the Abstract variables - it pastes an A at the beginning
of each column name for dtmAbstract, which are the variable names.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline57" class="outline-3">
<h3 id="orgheadline57"><span class="section-number-3">2.9</span> <span class="todo TODO">TODO</span> Problem 3.2 - Building a Model (1/1 point)</h3>
<div class="outline-text-3" id="text-2-9">
<p>
Using <code>cbind()</code>, combine <code>dtmTitle</code> and <code>dtmAbstract</code> into a single
data frame called <code>dtm</code>:
</p>

<p>
<code>dtm = cbind(dtmTitle, dtmAbstract)</code>
</p>

<p>
As we did in class, add the dependent variable <code>trial</code> to <code>dtm</code>, copying
it from the original data frame called trials. How many columns are in
this combined data frame?
</p>
</div>

<div id="outline-container-orgheadline56" class="outline-4">
<h4 id="orgheadline56"><span class="section-number-4">2.9.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-9-1">
<p>
367 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The combination can be accomplished with:
</p>

<p>
<code>dtm = cbind(dtmTitle, dtmAbstract)</code>
</p>

<p>
<code>dtm$trial = trials$trial</code>
</p>

<p>
The number of variables in the combined data frame can be read from
<code>str(dtm)</code> or <code>ncol(dtm)</code>. If you used <code>(fileEncoding="latin1")</code> when reading
in the file, you should have 5 extra variables (but the answer should
be graded as correct).
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline59" class="outline-3">
<h3 id="orgheadline59"><span class="section-number-3">2.10</span> <span class="todo TODO">TODO</span> Problem 3.3 - Building a Model (1/1 point)</h3>
<div class="outline-text-3" id="text-2-10">
<p>
Now that we have prepared our data frame, it's time to split it into a
training and testing set and to build regression models. Set the
random seed to 144 and use the <code>sample.split</code> function from the <code>caTools</code>
package to split dtm into data frames named <code>train</code> and <code>test</code>,
putting 70% of the data in the training set.
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be accomplished with:
</p>

<p>
<code>set.seed(144)</code>
</p>

<p>
<code>spl = sample.split(dtm$trial, 0.7)</code>
</p>

<p>
<code>train = subset(dtm, spl == TRUE)</code>
</p>

<p>
<code>test = subset(dtm, spl == FALSE)</code>
</p>

<p>
What is the accuracy of the baseline model on the training set?
(Remember that the baseline model predicts the most frequent outcome
in the training set for all observations.)
</p>
</div>

<div id="outline-container-orgheadline58" class="outline-4">
<h4 id="orgheadline58"><span class="section-number-4">2.10.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-10-1">
<p>
0.5609319 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
Just as in any binary classification problem, the naive baseline
always predicts the most common class. From <code>table(train$trial)</code>, we see
730 training set results were not trials, and 572 were
trials. Therefore, the naive baseline always predicts a result is not
a trial, yielding accuracy of <code>730/(730+572)</code>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline61" class="outline-3">
<h3 id="orgheadline61"><span class="section-number-3">2.11</span> <span class="todo TODO">TODO</span> Problem 3.4 - Building a Model (2/2 points)</h3>
<div class="outline-text-3" id="text-2-11">
<p>
Build a CART model called <code>trialCART</code>, using all the independent
variables in the training set to train the model, and then plot the
CART model. Just use the default parameters to build the model (don't
add a minbucket or cp value). Remember to add the ~method="class"~
argument, since this is a classification problem.
</p>

<p>
What is the name of the first variable the model split on?
</p>
</div>

<div id="outline-container-orgheadline60" class="outline-4">
<h4 id="orgheadline60"><span class="section-number-4">2.11.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-11-1">
<p>
Tphase - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be accomplished with:
</p>

<p>
<code>trialCART = rpart(trial</code>., data=train, method="class")~
</p>

<p>
<code>prp(trialCART)</code>
</p>

<p>
The first split checks whether or not Tphase is less than 0.5
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline63" class="outline-3">
<h3 id="orgheadline63"><span class="section-number-3">2.12</span> <span class="todo TODO">TODO</span> Problem 3.5 - Building a Model (1/1 point)</h3>
<div class="outline-text-3" id="text-2-12">
<p>
Obtain the training set predictions for the model (do not yet predict
on the test set). Extract the predicted probability of a result being
a trial (recall that this involves not setting a type argument, and
keeping only the second column of the predict output). What is the
maximum predicted probability for any result?
</p>
</div>

<div id="outline-container-orgheadline62" class="outline-4">
<h4 id="orgheadline62"><span class="section-number-4">2.12.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-12-1">
<p>
0.8718861 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The training set predictions can be obtained and summarized with the
following commands:
</p>

<p>
<code>predTrain = predict(trialCart)[,2]</code>
</p>

<p>
<code>summary(predTrain)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline64" class="outline-3">
<h3 id="orgheadline64"><span class="section-number-3">2.13</span> <span class="todo TODO">TODO</span> Problem 3.6 - Building a Model (1 point possible)</h3>
<div class="outline-text-3" id="text-2-13">
<p>
Without running the analysis, how do you expect the maximum predicted
probability to differ in the testing set?
</p>

<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> The maximum predicted probability will likely be smaller in the
testing set.</li>

<li class="on"><code>[X]</code> The maximum predicted probability will likely be exactly the
same in the testing set.</li>

<li class="off"><code>[&#xa0;]</code> The maximum predicted probability will likely be larger in the
testing set.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
Because the CART tree assigns the same predicted probability to each
leaf node and there are a small number of leaf nodes compared to data
points, we expect exactly the same maximum predicted probability.
</p>
</div>
</div>

<div id="outline-container-orgheadline71" class="outline-3">
<h3 id="orgheadline71"><span class="section-number-3">2.14</span> <span class="todo TODO">TODO</span> Problem 3.7 - Building a Model (3/3 points)</h3>
<div class="outline-text-3" id="text-2-14">
<p>
For these questions, use a threshold probability of 0.5 to predict
that an observation is a clinical trial.
</p>
</div>

<div id="outline-container-orgheadline66" class="outline-4">
<h4 id="orgheadline66"><span class="section-number-4">2.14.1</span> Question</h4>
<div class="outline-text-4" id="text-2-14-1">
<p>
What is the training set accuracy of the CART model?
</p>
</div>

<div id="outline-container-orgheadline65" class="outline-5">
<h5 id="orgheadline65"><span class="section-number-5">2.14.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-14-1-1">
<p>
0.8233487 - correct
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline68" class="outline-4">
<h4 id="orgheadline68"><span class="section-number-4">2.14.2</span> Question</h4>
<div class="outline-text-4" id="text-2-14-2">
<p>
What is the training set sensitivity of the CART model?
</p>
</div>

<div id="outline-container-orgheadline67" class="outline-5">
<h5 id="orgheadline67"><span class="section-number-5">2.14.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-14-2-1">
<p>
0.770979 - correct
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline70" class="outline-4">
<h4 id="orgheadline70"><span class="section-number-4">2.14.3</span> Question</h4>
<div class="outline-text-4" id="text-2-14-3">
<p>
What is the training set specificity of the CART model?
</p>
</div>

<div id="outline-container-orgheadline69" class="outline-5">
<h5 id="orgheadline69"><span class="section-number-5">2.14.3.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-14-3-1">
<p>
0.8643836 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
We can compare the predictions with threshold 0.5 to the true results
in the training set with:
</p>

<p>
<code>table(train$trial, predTrain &gt;= 0.5)</code>
</p>

<p>
From this, we read the following confusion matrix (rows are true
outcome, columns are predicted outcomes):
</p>

<p>
FALSE TRUE
</p>

<p>
0 631 99
</p>

<p>
1 131 441
</p>

<p>
We conclude that the model has
</p>

<p>
training set accuracy <code>(631+441)/(631+441+99+131)</code>,
</p>

<p>
sensitivity <code>441/(441+131)</code> and
</p>

<p>
specificity <code>631/(631+99)</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline74" class="outline-3">
<h3 id="orgheadline74"><span class="section-number-3">2.15</span> <span class="todo TODO">TODO</span> Problem 4.1 - Evaluating the model on the testing set (2/2 points)</h3>
<div class="outline-text-3" id="text-2-15">
<p>
Evaluate the CART model on the testing set using the predict function
and creating a vector of predicted probabilities <code>predTest</code>.
</p>
</div>

<div id="outline-container-orgheadline73" class="outline-4">
<h4 id="orgheadline73"><span class="section-number-4">2.15.1</span> Question</h4>
<div class="outline-text-4" id="text-2-15-1">
<p>
What is the testing set accuracy, assuming a probability threshold of
0.5 for predicting that a result is a clinical trial?
</p>
</div>

<div id="outline-container-orgheadline72" class="outline-5">
<h5 id="orgheadline72"><span class="section-number-5">2.15.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-2-15-1-1">
<p>
0.7580645 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The testing set predictions can be obtained and compared to the true
outcomes with:
</p>

<p>
<code>predTest = predict(trialCART, newdata=test)[,2]</code>
</p>

<p>
<code>table(test$trial, predTest &gt;= 0.5)</code>
</p>

<p>
This yields the following confusion matrix:
</p>

<p>
FALSE TRUE
</p>

<p>
0 261 52
</p>

<p>
1 83 162
</p>

<p>
From this, we read that the testing set
</p>

<p>
accuracy is <code>(261+162)/(261+162+83+52)</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline76" class="outline-3">
<h3 id="orgheadline76"><span class="section-number-3">2.16</span> <span class="todo TODO">TODO</span> Problem 4.2 - Evaluating the Model on the Testing Set (2/2 points)</h3>
<div class="outline-text-3" id="text-2-16">
<p>
Using the ROCR package, what is the testing set AUC of the prediction
model?
</p>
</div>

<div id="outline-container-orgheadline75" class="outline-4">
<h4 id="orgheadline75"><span class="section-number-4">2.16.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-16-1">
<p>
0.8371063 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The AUC can be determined using the following code:
</p>

<p>
<code>library(ROCR)</code>
</p>

<p>
<code>pred = prediction(predTest, test$trial)</code>
</p>

<p>
<code>as.numeric(performance(pred, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline77" class="outline-3">
<h3 id="orgheadline77"><span class="section-number-3">2.17</span> <span class="todo TODO">TODO</span> part 5: decision-maker tradeoffs</h3>
<div class="outline-text-3" id="text-2-17">
<p>
The decision maker for this problem, a researcher performing a review
of the medical literature, would use a model (like the CART one we
built here) in the following workflow:
</p>

<ol class="org-ol">
<li>For all of the papers retrieved in the PubMed Search, predict which
papers are clinical trials using the model. This yields some
initial Set A of papers predicted to be trials, and some Set B of
papers predicted not to be trials. (See the figure below.)</li>

<li>Then, the decision maker manually reviews all papers in Set A,
verifying that each paper meets the study's detailed inclusion
criteria (for the purposes of this analysis, we assume this manual
review is 100% accurate at identifying whether a paper in Set A is
relevant to the study). This yields a more limited set of papers to
be included in the study, which would ideally be all papers in the
medical literature meeting the detailed inclusion criteria for the
study.</li>

<li>Perform the study-specific analysis, using data extracted from the
limited set of papers identified in step 2.</li>
</ol>

<p>
This process is shown in the figure below.
</p>


<div class="figure">
<p><img src="../graphs/InfoRetrievalFigure2.png.png" alt="InfoRetrievalFigure2.png.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline79" class="outline-3">
<h3 id="orgheadline79"><span class="section-number-3">2.18</span> <span class="todo TODO">TODO</span> Problem 5.1 - Decision-Maker Tradeoffs (1/1 point)</h3>
<div class="outline-text-3" id="text-2-18">
<p>
What is the cost associated with the model in Step 1 making a false
negative prediction?
</p>
</div>

<div id="outline-container-orgheadline78" class="outline-4">
<h4 id="orgheadline78"><span class="section-number-4">2.18.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-18-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> A paper will be mistakenly added to Set A, yielding additional
work in Step 2 of the process but not affecting the quality of the
results of Step 3.</li>

<li class="off"><code>[&#xa0;]</code> A paper will be mistakenly added to Set A, definitely affecting
the quality of the results of Step 3.</li>

<li class="on"><code>[X]</code> A paper that should have been included in Set A will be missed,
affecting the quality of the results of Step 3. - correct</li>

<li class="off"><code>[&#xa0;]</code> There is no cost associated with a false negative prediction.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
By definition, a false negative is a paper that should have been
included in Set A but was missed by the model. This means a study that
should have been included in Step 3 was missed, affecting the results.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline81" class="outline-3">
<h3 id="orgheadline81"><span class="section-number-3">2.19</span> <span class="todo TODO">TODO</span> Problem 5.2 - Decision-Maker Tradeoffs (1/1 point)</h3>
<div class="outline-text-3" id="text-2-19">
<p>
What is the cost associated with the model in Step 1 making a false
positive prediction?
</p>
</div>

<div id="outline-container-orgheadline80" class="outline-4">
<h4 id="orgheadline80"><span class="section-number-4">2.19.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-19-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> A paper will be mistakenly added to Set A, yielding additional
work in Step 2 of the process but not affecting the quality of the
results of Step 3. - correct</li>

<li class="off"><code>[&#xa0;]</code> A paper will be mistakenly added to Set A, definitely affecting
the quality of the results of Step 3.</li>

<li class="off"><code>[&#xa0;]</code> A paper that should have been included in Set A will be missed,
affecting the quality of the results of Step 3.</li>

<li class="off"><code>[&#xa0;]</code> There is no cost associated with a false positive prediction.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
By definition, a false positive is a paper that should not have been
included in Set A but that was actually included. However, because the
manual review in Step 2 is assumed to be 100% effective, this extra
paper will not make it into the more limited set of papers, and
therefore this mistake will not affect the analysis in Step 3.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline83" class="outline-3">
<h3 id="orgheadline83"><span class="section-number-3">2.20</span> <span class="todo TODO">TODO</span> Problem 5.3 - Decision-Maker Tradeoffs (1/1 point)</h3>
<div class="outline-text-3" id="text-2-20">
<p>
Given the costs associated with false positives and false negatives,
which of the following is most accurate?
</p>
</div>

<div id="outline-container-orgheadline82" class="outline-4">
<h4 id="orgheadline82"><span class="section-number-4">2.20.1</span> Answer</h4>
<div class="outline-text-4" id="text-2-20-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> A false positive is more costly than a false negative; the
decision maker should use a probability threshold greater than 0.5
for the machine learning model.</li>

<li class="off"><code>[&#xa0;]</code> A false positive is more costly than a false negative; the
decision maker should use a probability threshold less than 0.5 for
the machine learning model.</li>

<li class="off"><code>[&#xa0;]</code> A false negative is more costly than a false positive; the
decision maker should use a probability threshold greater than 0.5
for the machine learning model.</li>

<li class="on"><code>[X]</code> A false negative is more costly than a false positive; the
decision maker should use a probability threshold less than 0.5 for
the machine learning model. - correct</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
A false negative might negatively affect the results of the literature
review and analysis, while a false positive is a nuisance (one
additional paper that needs to be manually checked). As a result, the
cost of a false negative is much higher than the cost of a false
positive, so much so that many studies actually use no machine
learning (aka no Step 1) and have two people manually review each
search result in Step 2. As always, we prefer a lower threshold in
cases where false negatives are more costly than false positives,
since we will make fewer negative predictions.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline156" class="outline-2">
<h2 id="orgheadline156"><span class="section-number-2">3</span> Separating spam from ham (Part 1) <code>[0/31]</code></h2>
<div class="outline-text-2" id="text-3">
<p>
Nearly every email user has at some point encountered a "spam" email,
which is an unsolicited message often advertising a product,
containing links to malware, or attempting to scam the
recipient. Roughly 80-90% of more than 100 billion emails sent each
day are spam emails, most being sent from botnets of malware-infected
computers. The remainder of emails are called "ham" emails.
</p>

<p>
As a result of the huge number of spam emails being sent across the
Internet each day, most email providers offer a spam filter that
automatically flags likely spam messages and separates them from the
ham. Though these filters use a number of techniques (e.g. looking up
the sender in a so-called "Blackhole List" that contains IP addresses
of likely spammers), most rely heavily on the analysis of the contents
of an email via text analytics.
</p>

<p>
In this homework problem, we will build and evaluate a spam filter
using a publicly available dataset first described in the 2006
conference paper "Spam Filtering with Naive Bayes &#x2013; Which Naive
Bayes?" by V. Metsis, I. Androutsopoulos, and G. Paliouras. The "ham"
messages in this dataset come from the inbox of former Enron Managing
Director for Research Vincent Kaminski, one of the inboxes in the
Enron Corpus. One source of spam messages in this dataset is the
SpamAssassin corpus, which contains hand-labeled spam messages
contributed by Internet users. The remaining spam was collected by
Project Honey Pot, a project that collects spam messages and
identifies spammers by publishing email address that humans would know
not to contact but that bots might target with spam. The full dataset
we will use was constructed as roughly a 75/25 mix of the ham and spam
messages.
</p>

<p>
The dataset contains just two fields:
</p>

<ul class="org-ul">
<li><b>text</b>: The text of the email.</li>

<li><b>spam</b>: A binary variable indicating if the email was spam.</li>
</ul>
</div>

<div id="outline-container-orgheadline85" class="outline-3">
<h3 id="orgheadline85"><span class="section-number-3">3.1</span> Important Note</h3>
<div class="outline-text-3" id="text-3-1">
<p>
This problem (Separating Spam from Ham) continues on the next page
with additional exercises. The second page is optional, but if you
want to try it out, remember to save your work so you can start the
next page where you left off here.
</p>
</div>
</div>

<div id="outline-container-orgheadline88" class="outline-3">
<h3 id="orgheadline88"><span class="section-number-3">3.2</span> <span class="todo TODO">TODO</span> Problem 1.1 - Loading the Dataset (1/1 point)</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Begin by loading the dataset <a href="https://courses.edx.org/asset-v1:MITx+15.071x_2a+2T2015+type@asset+block/emails.csv">emails.csv</a> into a data frame called
emails. Remember to pass the stringsAsFactors=FALSE option when
loading the data.
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can load the dataset with:
</p>

<p>
<code>emails = read.csv("emails.csv", stringsAsFactors=FALSE)</code>
</p>
</div>

<div id="outline-container-orgheadline87" class="outline-4">
<h4 id="orgheadline87"><span class="section-number-4">3.2.1</span> Question</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
How many emails are in the dataset?
</p>
</div>

<div id="outline-container-orgheadline86" class="outline-5">
<h5 id="orgheadline86"><span class="section-number-5">3.2.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-2-1-1">
<p>
5728 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The number of emails can be read from <code>str(emails)</code> or
<code>nrow(emails)</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline91" class="outline-3">
<h3 id="orgheadline91"><span class="section-number-3">3.3</span> <span class="todo TODO">TODO</span> Problem 1.2 - Loading the Dataset (1/1 point)</h3>
<div class="outline-text-3" id="text-3-3">
</div><div id="outline-container-orgheadline90" class="outline-4">
<h4 id="orgheadline90"><span class="section-number-4">3.3.1</span> Question</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
How many of the emails are spam?
</p>
</div>

<div id="outline-container-orgheadline89" class="outline-5">
<h5 id="orgheadline89"><span class="section-number-5">3.3.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-3-1-1">
<p>
1368 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be read from <code>table(emails$spam)</code>.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline93" class="outline-3">
<h3 id="orgheadline93"><span class="section-number-3">3.4</span> <span class="todo TODO">TODO</span> Problem 1.3 - Loading the Dataset (1/1 point)</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Which word appears at the beginning of every email in the dataset?
Respond as a lower-case word with punctuation removed.
</p>
</div>

<div id="outline-container-orgheadline92" class="outline-4">
<h4 id="orgheadline92"><span class="section-number-4">3.4.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-4-1">
<p>
subject - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
You can review emails with, for instance, <code>emails$text[1]</code> or
<code>emails$text[1000]</code>. Every email begins with the word "Subject:".
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline94" class="outline-3">
<h3 id="orgheadline94"><span class="section-number-3">3.5</span> <span class="todo TODO">TODO</span> Problem 1.4 - Loading the Dataset (1 point possible)</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Could a spam classifier potentially benefit from including the
frequency of the word that appears in every email?
</p>

<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> No &#x2013; the word appears in every email so this variable would not
help us differentiate spam from ham.</li>

<li class="on"><code>[X]</code> Yes &#x2013; the number of times the word appears might help us
differentiate spam from ham.</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
We know that each email has the word "subject" appear at least once,
but the frequency with which it appears might help us differentiate
spam from ham. For instance, a long email chain would have the word
"subject" appear a number of times, and this higher frequency might be
indicative of a ham message.
</p>
</div>
</div>

<div id="outline-container-orgheadline96" class="outline-3">
<h3 id="orgheadline96"><span class="section-number-3">3.6</span> <span class="todo TODO">TODO</span> Problem 1.5 - Loading the Dataset (1/1 point)</h3>
<div class="outline-text-3" id="text-3-6">
<p>
The <code>nchar()</code> function counts the number of characters in a piece of
text. How many characters are in the longest email in the dataset
(where longest is measured in terms of the maximum number of
characters)?
</p>
</div>

<div id="outline-container-orgheadline95" class="outline-4">
<h4 id="orgheadline95"><span class="section-number-4">3.6.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-6-1">
<p>
43952 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The maximum length can be obtained with <code>max(nchar(emails$text))</code>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline98" class="outline-3">
<h3 id="orgheadline98"><span class="section-number-3">3.7</span> <span class="todo TODO">TODO</span> Problem 1.6 - Loading the Dataset (1/1 point)</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Which row contains the shortest email in the dataset? (Just like in
the previous problem, shortest is measured in terms of the fewest
number of characters.)
</p>
</div>

<div id="outline-container-orgheadline97" class="outline-4">
<h4 id="orgheadline97"><span class="section-number-4">3.7.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-7-1">
<p>
1992 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
The minimum length, 13 characters, can be determined with
<code>min(nchar(emails$text))</code>. We can see that this is achieved only in
email 1992 from <code>which(nchar(emails$text) == 13)</code>. An easier approach
would be <code>which.min(nchar(emails$text))</code>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline100" class="outline-3">
<h3 id="orgheadline100"><span class="section-number-3">3.8</span> <span class="todo TODO">TODO</span> Problem 2.1 - Preparing the Corpus (2/2 points)</h3>
<div class="outline-text-3" id="text-3-8">
<p>
Follow the standard steps to build and pre-process the corpus:
</p>

<ol class="org-ol">
<li>Build a new corpus variable called corpus.</li>

<li>Using <code>tm_map</code>, convert the text to lowercase.</li>

<li>Using <code>tm_map</code>, remove all punctuation from the corpus.</li>

<li>Using <code>tm_map</code>, remove all English stopwords from the corpus.</li>

<li>Using <code>tm_map</code>, stem the words in the corpus.</li>

<li>Build a document term matrix from the corpus, called <code>dtm</code>.</li>
</ol>

<p>
If the code <code>length(stopwords("english"))</code> does not return 174 for you,
then please run the line of code in this file, which will store the
standard stop words in a variable called sw. When removing stop words,
use <code>tm_map(corpus, removeWords, sw)</code> instead of
<code>tm_map(corpus, removeWords, stopwords("english"))</code>.
</p>

<p>
How many terms are in <code>dtm</code>?
</p>
</div>

<div id="outline-container-orgheadline99" class="outline-4">
<h4 id="orgheadline99"><span class="section-number-4">3.8.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-8-1">
<p>
28687 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
These steps can be accomplished by running:
</p>

<p>
<code>corpus = Corpus(VectorSource(emails$text))</code>
</p>

<p>
<code>corpus = tm_map(corpus, tolower)</code>
</p>

<p>
<code>corpus = tm_map(corpus, PlainTextDocument)</code>
</p>

<p>
<code>corpus = tm_map(corpus, removePunctuation)</code>
</p>

<p>
<code>corpus = tm_map(corpus, removeWords, stopwords("english"))</code>
</p>

<p>
<code>corpus = tm_map(corpus, stemDocument)</code>
</p>

<p>
<code>dtm = DocumentTermMatrix(corpus)</code>
</p>

<p>
<code>dtm</code>
</p>

<p>
From the dtm summary output, we can read that it contains 28687
terms.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline102" class="outline-3">
<h3 id="orgheadline102"><span class="section-number-3">3.9</span> <span class="todo TODO">TODO</span> Problem 2.2 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-3-9">
<p>
To obtain a more reasonable number of terms, limit <code>dtm</code> to contain
terms appearing in at least 5% of documents, and store this result as
<code>spdtm</code> (don't overwrite dtm, because we will use it in a later step of
this homework). How many terms are in <code>spdtm</code>?
</p>
</div>

<div id="outline-container-orgheadline101" class="outline-4">
<h4 id="orgheadline101"><span class="section-number-4">3.9.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-9-1">
<p>
330 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be accomplished with:
</p>

<p>
<code>spdtm = removeSparseTerms(dtm, 0.95)</code>
</p>

<p>
<code>spdtm</code>
</p>

<p>
From the <code>spdtm</code> summary output, it contains 330 terms.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline104" class="outline-3">
<h3 id="orgheadline104"><span class="section-number-3">3.10</span> <span class="todo TODO">TODO</span> Problem 2.3 - Preparing the Corpus (2/2 points)</h3>
<div class="outline-text-3" id="text-3-10">
<p>
Build a data frame called <code>emailsSparse</code> from <code>spdtm</code>, and use the
<code>make.names</code> function to make the variable names of <code>emailsSparse</code> valid.
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be accomplished with:
</p>

<p>
<code>emailsSparse = as.data.frame(as.matrix(spdtm))</code>
</p>

<p>
<code>colnames(emailsSparse) = make.names(colnames(emailsSparse))</code>
</p>

<p>
<code>colSums()</code> is an R function that returns the sum of values for each
variable in our data frame. Our data frame contains the number of
times each word stem (columns) appeared in each email
(rows). Therefore, <code>colSums(emailsSparse)</code> returns the number of times a
word stem appeared across all the emails in the dataset. What is the
word stem that shows up most frequently across all the emails in the
dataset? Hint: think about how you can use <code>sort()</code> or <code>which.max()</code> to
pick out the maximum frequency.
</p>
</div>

<div id="outline-container-orgheadline103" class="outline-4">
<h4 id="orgheadline103"><span class="section-number-4">3.10.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-10-1">
<p>
enron - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
<code>colSums(emailsSparse)</code> contains the sum of all the values for each
column in our data frame. Since the values in the data frame are the
frequencies of the stem in the column for the email in the row, these
column sums represent the frequencies of the stems across all emails.
</p>

<p>
We can either use <code>sort()</code> or <code>which.max()</code> to pick out the most
common word:
</p>

<p>
<code>sort(colSums(emailsSparse))</code>
</p>

<p>
<code>which.max(colSums(emailsSparse))</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline106" class="outline-3">
<h3 id="orgheadline106"><span class="section-number-3">3.11</span> <span class="todo TODO">TODO</span> Problem 2.4 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-3-11">
<p>
Add a variable called <code>spam</code> to emailsSparse containing the email spam
labels. You can do this by copying over the <code>spam</code> variable from the
original data frame (remember how we did this in the Twitter
lecture).
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be accomplished with:
</p>

<p>
<code>emailsSparse$spam = emails$spam</code>
</p>

<p>
How many word stems appear at least 5000 times in the ham emails in
the dataset? Hint: in this and the next question, remember not to
count the dependent variable we just added.
</p>
</div>

<div id="outline-container-orgheadline105" class="outline-4">
<h4 id="orgheadline105"><span class="section-number-4">3.11.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-11-1">
<p>
6 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
We can read the most frequent terms in the ham dataset with
<code>sort(colSums(subset(emailsSparse, spam == 0)))</code>. <code>enron</code>, <code>ect</code>,
<code>subject</code>, <code>vinc</code>, <code>will</code>, and <code>hou</code> appear at least 5000 times in the
ham dataset.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline108" class="outline-3">
<h3 id="orgheadline108"><span class="section-number-3">3.12</span> <span class="todo TODO">TODO</span> Problem 2.5 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-3-12">
<p>
How many word stems appear at least 1000 times in the spam emails in
the dataset?
</p>
</div>

<div id="outline-container-orgheadline107" class="outline-4">
<h4 id="orgheadline107"><span class="section-number-4">3.12.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-12-1">
<p>
3 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
We can limit the dataset to the spam emails with <code>subset(emailsSparse,
spam == 1)</code>. Therefore, we can read the most frequent terms with
<code>sort(colSums(subset(emailsSparse, spam == 1)))</code>. <code>subject</code>, <code>will</code>,
and <code>compani</code> are the three stems that appear at least 1000
times. Note that the variable <code>spam</code> is the dependent variable and is
not the frequency of a word stem.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline110" class="outline-3">
<h3 id="orgheadline110"><span class="section-number-3">3.13</span> <span class="todo TODO">TODO</span> Problem 2.6 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-3-13">
<p>
The lists of most common words are significantly different between the
spam and ham emails. What does this likely imply?
</p>
</div>

<div id="outline-container-orgheadline109" class="outline-4">
<h4 id="orgheadline109"><span class="section-number-4">3.13.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-13-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> The frequencies of these most common words are unlikely to help
differentiate between spam and ham.</li>

<li class="on"><code>[X]</code> The frequencies of these most common words are likely to help
differentiate between spam and ham. - correct</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
A word stem like <code>enron</code>, which is extremely common in the ham emails
but does not occur in any spam message, will help us correctly
identify a large number of ham messages.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline112" class="outline-3">
<h3 id="orgheadline112"><span class="section-number-3">3.14</span> <span class="todo TODO">TODO</span> Problem 2.7 - Preparing the Corpus (1/1 point)</h3>
<div class="outline-text-3" id="text-3-14">
<p>
Several of the most common word stems from the ham documents, such as
<code>enron</code>, <code>hou</code> (short for Houston), <code>vinc</code> (the word stem of <code>Vince</code>)
and <code>kaminski</code>, are likely specific to Vincent Kaminski's inbox. What
does this mean about the applicability of the text analytics models we
will train for the spam filtering problem?
</p>
</div>

<div id="outline-container-orgheadline111" class="outline-4">
<h4 id="orgheadline111"><span class="section-number-4">3.14.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-14-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> The models we build are still very general, and are likely to
perform well as a spam filter for nearly any other person.</li>

<li class="on"><code>[X]</code> The models we build are personalized, and would need to be
further tested before being used as a spam filter for another
person. - correct</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The ham dataset is certainly personalized to Vincent Kaminski, and
therefore it might not generalize well to a general email
user. Caution is definitely necessary before applying the filters
derived in this problem to other email users.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline119" class="outline-3">
<h3 id="orgheadline119"><span class="section-number-3">3.15</span> <span class="todo TODO">TODO</span> Problem 3.1 - Building machine learning models (3/3 points)</h3>
<div class="outline-text-3" id="text-3-15">
<p>
First, convert the dependent variable to a factor with
<code>emailsSparse$spam = as.factor(emailsSparse$spam)</code>.
</p>

<p>
Next, set the random seed to 123 and use the <code>sample.split</code> function
to split <code>emailsSparse</code> 70/30 into a training set called <code>train</code> and a
testing set called <code>test</code>. Make sure to perform this step on
<code>emailsSparse</code> instead of <code>emails</code>.
</p>

<p>
<b>Explanation</b>
</p>

<p>
These steps can be accomplished with:
</p>

<p>
<code>emailsSparse$spam = as.factor(emailsSparse$spam)</code>
</p>

<p>
<code>set.seed(123)</code>
</p>

<p>
<code>library(caTools)</code>
</p>

<p>
<code>spl = sample.split(emailsSparse$spam, 0.7)</code>
</p>

<p>
<code>train = subset(emailsSparse, spl == TRUE)</code>
</p>

<p>
<code>test = subset(emailsSparse, spl == FALSE)</code>
</p>

<p>
Using the training set, train the following three machine learning
models. The models should predict the dependent variable <code>spam</code>, using
all other available variables as independent variables. Please be
patient, as these models may take a few minutes to train.
</p>

<ol class="org-ol">
<li>A logistic regression model called <code>spamLog</code>. You may see a warning
message here - we'll discuss this more later.</li>

<li>A CART model called <code>spamCART</code>, using the default parameters to
train the model (don't worry about adding minbucket or
cp). Remember to add the argument <code>(method="class")</code> since this is a
binary classification problem.</li>

<li>A random forest model called <code>spamRF</code>, using the default parameters
to train the model (don't worry about specifying <code>ntree</code> or
<code>nodesize</code>). Directly before training the random forest model, set
the random seed to 123 (even though we've already done this earlier
in the problem, it's important to set the seed right before
training the model so we all obtain the same results. Keep in mind
though that on certain operating systems, your results might still
be slightly different).</li>
</ol>

<p>
<b>Explanation</b>
</p>

<p>
These models can be trained with the following code:
</p>

<p>
<code>spamLog = glm(spam</code>., data=train, family="binomial")~
</p>

<p>
<code>spamCART = rpart(spam</code>., data=train, method="class")~
</p>

<p>
<code>set.seed(123)</code>
</p>

<p>
<code>spamRF = randomForest(spam</code>., data=train)~
</p>

<p>
For each model, obtain the predicted spam probabilities for the
<b>training set</b>. Be careful to obtain probabilities instead of predicted
classes, because we will be using these values to compute training set
AUC values. Recall that you can obtain probabilities for CART models
by not passing any type parameter to the <code>predict()</code> function, and you
can obtain probabilities from a random forest by adding the argument
<code>(type="prob")</code>. For CART and random forest, you need to select the second
column of the output of the <code>predict()</code> function, corresponding to the
probability of a message being spam.
</p>

<p>
<b>Explanation</b>
</p>

<p>
These probabilities can be obtained with:
</p>

<p>
<code>predTrainLog = predict(spamLog, type="response")</code>
</p>

<p>
<code>predTrainCART = predict(spamCART)[,2]</code>
</p>

<p>
<code>predTrainRF = predict(spamRF, type="prob")[,2]</code>
</p>

<p>
You may have noticed that training the logistic regression model
yielded the messages <b>algorithm did not converge</b> and <b>fitted
probabilities numerically 0 or 1 occurred</b>. Both of these messages
often indicate overfitting and the first indicates particularly severe
overfitting, often to the point that the training set observations are
fit perfectly by the model. Let's investigate the predicted
probabilities from the logistic regression model.
</p>
</div>

<div id="outline-container-orgheadline114" class="outline-4">
<h4 id="orgheadline114"><span class="section-number-4">3.15.1</span> Question</h4>
<div class="outline-text-4" id="text-3-15-1">
<p>
How many of the training set predicted probabilities from spamLog are
less than 0.00001?
</p>
</div>

<div id="outline-container-orgheadline113" class="outline-5">
<h5 id="orgheadline113"><span class="section-number-5">3.15.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-15-1-1">
<p>
3046 - correct
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline116" class="outline-4">
<h4 id="orgheadline116"><span class="section-number-4">3.15.2</span> Question</h4>
<div class="outline-text-4" id="text-3-15-2">
<p>
How many of the training set predicted probabilities from spamLog are
more than 0.99999?
</p>
</div>

<div id="outline-container-orgheadline115" class="outline-5">
<h5 id="orgheadline115"><span class="section-number-5">3.15.2.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-15-2-1">
<p>
954 - correct
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline118" class="outline-4">
<h4 id="orgheadline118"><span class="section-number-4">3.15.3</span> Question</h4>
<div class="outline-text-4" id="text-3-15-3">
<p>
How many of the training set predicted probabilities from spamLog are
between 0.00001 and 0.99999?
</p>
</div>

<div id="outline-container-orgheadline117" class="outline-5">
<h5 id="orgheadline117"><span class="section-number-5">3.15.3.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-15-3-1">
<p>
10 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
To check the number of probabilities with these characteristics, we
can use:
</p>

<p>
<code>table(predTrainLog &lt; 0.00001)</code>
</p>

<p>
<code>table(predTrainLog &gt; 0.99999)</code>
</p>

<p>
<code>table(predTrainLog &gt;= 0.00001 &amp; predTrainLog &lt;= 0.99999)</code>
</p>

<p>
You might have gotten slightly different answers than the ones you see
here, because the <code>glm</code> function has a hard time converging with this
many independent variables. That's okay - your answers should still be
marked as correct.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline121" class="outline-3">
<h3 id="orgheadline121"><span class="section-number-3">3.16</span> <span class="todo TODO">TODO</span> Problem 3.2 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-16">
<p>
How many variables are labeled as significant (at the p=0.05 level) in
the logistic regression summary output?
</p>
</div>

<div id="outline-container-orgheadline120" class="outline-4">
<h4 id="orgheadline120"><span class="section-number-4">3.16.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-16-1">
<p>
0 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
From <code>summary(spamLog)</code>, we see that none of the variables are labeled
as significant (a symptom of the logistic regression algorithm not
converging).
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline123" class="outline-3">
<h3 id="orgheadline123"><span class="section-number-3">3.17</span> <span class="todo TODO">TODO</span> Problem 3.3 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-17">
<p>
How many of the word stems <code>enron</code>, <code>hou</code>, <code>vinc</code>, and <code>kaminski</code>
appear in the CART tree? Recall that we suspect these word stems are
specific to Vincent Kaminski and might affect the generalizability of
a spam filter built with his ham data.
</p>
</div>

<div id="outline-container-orgheadline122" class="outline-4">
<h4 id="orgheadline122"><span class="section-number-4">3.17.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-17-1">
<p>
2 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
From prp(spamCART), we see that <code>vinc</code> and <code>enron</code> appear in the CART
tree as the top two branches, but that <code>hou</code> and <code>kaminski</code> do not
appear.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline125" class="outline-3">
<h3 id="orgheadline125"><span class="section-number-3">3.18</span> <span class="todo TODO">TODO</span> Problem 3.4 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-18">
<p>
What is the training set accuracy of spamLog, using a threshold of 0.5
for predictions?
</p>
</div>

<div id="outline-container-orgheadline124" class="outline-4">
<h4 id="orgheadline124"><span class="section-number-4">3.18.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-18-1">
<p>
0.9990025 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(train$spam, predTrainLog &gt; 0.5)</code>
</p>

<p>
The accuracy is <code>(3052+954)/nrow(train)</code>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline127" class="outline-3">
<h3 id="orgheadline127"><span class="section-number-3">3.19</span> <span class="todo TODO">TODO</span> Problem 3.5 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-19">
<p>
What is the training set AUC of spamLog?
</p>
</div>

<div id="outline-container-orgheadline126" class="outline-4">
<h4 id="orgheadline126"><span class="section-number-4">3.19.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-19-1">
<p>
0.9999959 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTrainLog = prediction(predTrainLog, train$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTrainLog, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline129" class="outline-3">
<h3 id="orgheadline129"><span class="section-number-3">3.20</span> <span class="todo TODO">TODO</span> Problem 3.6 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-20">
<p>
What is the training set accuracy of spamCART, using a threshold of
0.5 for predictions? (Remember that if you used the type="class"
argument when making predictions, you automatically used a threshold
of 0.5. If you did not add in the type argument to the predict
function, the probabilities are in the second column of the predict
output.)
</p>
</div>

<div id="outline-container-orgheadline128" class="outline-4">
<h4 id="orgheadline128"><span class="section-number-4">3.20.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-20-1">
<p>
0.942394 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(train$spam, predTrainCART &gt; 0.5)</code>
</p>

<p>
Then the accuracy is <code>(2885+894)/nrow(train)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline131" class="outline-3">
<h3 id="orgheadline131"><span class="section-number-3">3.21</span> <span class="todo TODO">TODO</span> Problem 3.7 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-21">
<p>
What is the training set AUC of spamCART? (Remember that you have to
pass the prediction function predicted probabilities, so don't include
the type argument when making predictions for your CART model.)
</p>
</div>

<div id="outline-container-orgheadline130" class="outline-4">
<h4 id="orgheadline130"><span class="section-number-4">3.21.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-21-1">
<p>
0.9696044 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTrainCART = prediction(predTrainCART, train$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTrainCART, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline133" class="outline-3">
<h3 id="orgheadline133"><span class="section-number-3">3.22</span> <span class="todo TODO">TODO</span> Problem 3.8 - Building Machine Learning Models (1/1 point)</h3>
<div class="outline-text-3" id="text-3-22">
<p>
What is the training set accuracy of <code>spamRF</code>, using a threshold of 0.5
for predictions? (Remember that your answer might not match ours
exactly, due to random behavior in the random forest algorithm on
different operating systems.)
</p>
</div>

<div id="outline-container-orgheadline132" class="outline-4">
<h4 id="orgheadline132"><span class="section-number-4">3.22.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-22-1">
<p>
0.9985037 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(train$spam, predTrainRF &gt; 0.5)</code>
</p>

<p>
And then the accuracy is <code>(3013+914)/nrow(train)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline135" class="outline-3">
<h3 id="orgheadline135"><span class="section-number-3">3.23</span> <span class="todo TODO">TODO</span> Problem 3.9 - Building Machine Learning Models (2/2 points)</h3>
<div class="outline-text-3" id="text-3-23">
<p>
What is the training set AUC of spamRF? (Remember to pass the argument
type="prob" to the predict function to get predicted probabilities for
a random forest model. The probabilities will be the second column of
the output.)
</p>
</div>

<div id="outline-container-orgheadline134" class="outline-4">
<h4 id="orgheadline134"><span class="section-number-4">3.23.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-23-1">
<p>
0.9999959 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTrainRF = prediction(predTrainRF, train$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTrainRF, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline137" class="outline-3">
<h3 id="orgheadline137"><span class="section-number-3">3.24</span> <span class="todo TODO">TODO</span> Problem 3.10 - Building Machine Learning Models (1 point possible)</h3>
<div class="outline-text-3" id="text-3-24">
<p>
Which model had the best training set performance, in terms of
accuracy and AUC?
</p>
</div>

<div id="outline-container-orgheadline136" class="outline-4">
<h4 id="orgheadline136"><span class="section-number-4">3.24.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-24-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Logistic regression</li>
<li class="off"><code>[&#xa0;]</code> CART</li>
<li class="off"><code>[&#xa0;]</code> Random forest</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
In terms of both accuracy and AUC, logistic regression is nearly
perfect and outperforms the other two models.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline140" class="outline-3">
<h3 id="orgheadline140"><span class="section-number-3">3.25</span> <span class="todo TODO">TODO</span> Problem 4.1 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-25">
<p>
Obtain predicted probabilities for the testing set for each of the
models, again ensuring that probabilities instead of classes are
obtained.
</p>

<p>
<b>Explanation</b>
</p>

<p>
The predicted probabilities can be obtained with:
</p>

<p>
<code>predTestLog = predict(spamLog, newdata=test, type="response")</code>
</p>

<p>
<code>predTestCART = predict(spamCART, newdata=test)[,2]</code>
</p>

<p>
<code>predTestRF = predict(spamRF, newdata=test, type="prob")[,2]</code>
</p>
</div>

<div id="outline-container-orgheadline139" class="outline-4">
<h4 id="orgheadline139"><span class="section-number-4">3.25.1</span> Question</h4>
<div class="outline-text-4" id="text-3-25-1">
<p>
What is the testing set accuracy of spamLog, using a threshold of 0.5
for predictions?
</p>
</div>

<div id="outline-container-orgheadline138" class="outline-5">
<h5 id="orgheadline138"><span class="section-number-5">3.25.1.1</span> Answer</h5>
<div class="outline-text-5" id="text-3-25-1-1">
<p>
0.9505239 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(test$spam, predTestLog &gt; 0.5)</code>
</p>

<p>
Then the accuracy is <code>(1257+376)/nrow(test)</code>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline142" class="outline-3">
<h3 id="orgheadline142"><span class="section-number-3">3.26</span> <span class="todo TODO">TODO</span> Problem 4.2 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-26">
<p>
What is the testing set AUC of spamLog?
</p>
</div>

<div id="outline-container-orgheadline141" class="outline-4">
<h4 id="orgheadline141"><span class="section-number-4">3.26.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-26-1">
<p>
0.9627517 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTestLog = prediction(predTestLog, test$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTestLog, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline144" class="outline-3">
<h3 id="orgheadline144"><span class="section-number-3">3.27</span> <span class="todo TODO">TODO</span> Problem 4.3 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-27">
<p>
What is the testing set accuracy of spamCART, using a threshold of 0.5
for predictions?
</p>
</div>

<div id="outline-container-orgheadline143" class="outline-4">
<h4 id="orgheadline143"><span class="section-number-4">3.27.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-27-1">
<p>
0.9394645 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(test$spam, predTestCART &gt; 0.5)</code>
</p>

<p>
Then the accuracy is <code>(1228+386)/nrow(test)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline146" class="outline-3">
<h3 id="orgheadline146"><span class="section-number-3">3.28</span> <span class="todo TODO">TODO</span> Problem 4.4 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-28">
<p>
What is the testing set AUC of spamCART?
</p>
</div>

<div id="outline-container-orgheadline145" class="outline-4">
<h4 id="orgheadline145"><span class="section-number-4">3.28.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-28-1">
<p>
0.963176 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTestCART = prediction(predTestCART, test$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTestCART, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline148" class="outline-3">
<h3 id="orgheadline148"><span class="section-number-3">3.29</span> <span class="todo TODO">TODO</span> Problem 4.5 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-29">
<p>
What is the testing set accuracy of spamRF, using a threshold of 0.5
for predictions?
</p>
</div>

<div id="outline-container-orgheadline147" class="outline-4">
<h4 id="orgheadline147"><span class="section-number-4">3.29.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-29-1">
<p>
0.975553 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>table(test$spam, predTestRF &gt; 0.5)</code>
</p>

<p>
Then the accuracy is <code>(1290+385)/nrow(test)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline150" class="outline-3">
<h3 id="orgheadline150"><span class="section-number-3">3.30</span> <span class="todo TODO">TODO</span> Problem 4.6 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-30">
<p>
What is the testing set AUC of spamRF?
</p>
</div>

<div id="outline-container-orgheadline149" class="outline-4">
<h4 id="orgheadline149"><span class="section-number-4">3.30.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-30-1">
<p>
0.9975656 - correct
</p>

<p>
<b>Explanation</b>
</p>

<p>
This can be obtained with:
</p>

<p>
<code>predictionTestRF = prediction(predTestRF, test$spam)</code>
</p>

<p>
<code>as.numeric(performance(predictionTestRF, "auc")@y.values)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline152" class="outline-3">
<h3 id="orgheadline152"><span class="section-number-3">3.31</span> <span class="todo TODO">TODO</span> Problem 4.7 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-31">
<p>
Which model had the best testing set performance, in terms of accuracy
and AUC?
</p>
</div>

<div id="outline-container-orgheadline151" class="outline-4">
<h4 id="orgheadline151"><span class="section-number-4">3.31.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-31-1">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> Logistic regression</li>
<li class="off"><code>[&#xa0;]</code> CART</li>
<li class="on"><code>[X]</code> Random forest - correct</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
The random forest outperformed logistic regression and CART in both
measures, obtaining an impressive AUC of 0.997 on the test set.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline154" class="outline-3">
<h3 id="orgheadline154"><span class="section-number-3">3.32</span> <span class="todo TODO">TODO</span> Problem 4.8 - Evaluating on the Test Set (1/1 point)</h3>
<div class="outline-text-3" id="text-3-32">
<p>
Which model demonstrated the greatest degree of overfitting?
</p>
</div>

<div id="outline-container-orgheadline153" class="outline-4">
<h4 id="orgheadline153"><span class="section-number-4">3.32.1</span> Answer</h4>
<div class="outline-text-4" id="text-3-32-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> Logistic regression - correct</li>
<li class="off"><code>[&#xa0;]</code> CART</li>
<li class="off"><code>[&#xa0;]</code> Random forest</li>
</ul>

<p>
<b>Explanation</b>
</p>

<p>
Both CART and random forest had very similar accuracies on the
training and testing sets. However, logistic regression obtained
nearly perfect accuracy and AUC on the training set and had
far-from-perfect performance on the testing set. This is an indicator
of overfitting.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline155" class="outline-3">
<h3 id="orgheadline155"><span class="section-number-3">3.33</span> Important Note</h3>
<div class="outline-text-3" id="text-3-33">
<p>
The second part of this homework assignment is optional, and is on the
next page. If you want to complete the optional assignment, remember
to save your work so you can start the next page where you left off
here.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 30/08/2015</p>
<p class="author">Author: Sergio-Feliciano Mendoza-Barrera</p>
<p class="date">Created: 2015-08-31 Mon 07:19</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
